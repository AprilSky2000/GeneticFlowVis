[
    [
        "0.00 0.00 4057.96 2557.76",
        "scale(1 1) rotate(0) translate(4 2553.76)"
    ],
    [
        {
            "id": "1992",
            "cx": 34.45,
            "cy": -2522.89,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1992"
        },
        {
            "id": "1993",
            "cx": 34.45,
            "cy": -2433.15,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1993"
        },
        {
            "id": "1994",
            "cx": 34.45,
            "cy": -2352.28,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1994"
        },
        {
            "id": "1995",
            "cx": 34.45,
            "cy": -2271.41,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1995"
        },
        {
            "id": "1996",
            "cx": 34.45,
            "cy": -2190.54,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1996"
        },
        {
            "id": "1997",
            "cx": 34.45,
            "cy": -2118.54,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1997"
        },
        {
            "id": "1998",
            "cx": 34.45,
            "cy": -2046.54,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1998"
        },
        {
            "id": "1999",
            "cx": 34.45,
            "cy": -1965.67,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1999"
        },
        {
            "id": "2000",
            "cx": 34.45,
            "cy": -1875.93,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2000"
        },
        {
            "id": "2001",
            "cx": 34.45,
            "cy": -1786.19,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2001"
        },
        {
            "id": "2002",
            "cx": 34.45,
            "cy": -1696.45,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2002"
        },
        {
            "id": "2003",
            "cx": 34.45,
            "cy": -1606.71,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2003"
        },
        {
            "id": "2004",
            "cx": 34.45,
            "cy": -1516.97,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2004"
        },
        {
            "id": "2005",
            "cx": 34.45,
            "cy": -1427.23,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2005"
        },
        {
            "id": "2006",
            "cx": 34.45,
            "cy": -1337.49,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2006"
        },
        {
            "id": "2007",
            "cx": 34.45,
            "cy": -1247.75,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2007"
        },
        {
            "id": "2008",
            "cx": 34.45,
            "cy": -1158.01,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2008"
        },
        {
            "id": "2009",
            "cx": 34.45,
            "cy": -1068.27,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2009"
        },
        {
            "id": "2010",
            "cx": 34.45,
            "cy": -978.53,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2010"
        },
        {
            "id": "2011",
            "cx": 34.45,
            "cy": -888.79,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2011"
        },
        {
            "id": "2012",
            "cx": 34.45,
            "cy": -799.05,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2012"
        },
        {
            "id": "2013",
            "cx": 34.45,
            "cy": -709.31,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2013"
        },
        {
            "id": "2014",
            "cx": 34.45,
            "cy": -619.57,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2014"
        },
        {
            "id": "2015",
            "cx": 34.45,
            "cy": -529.83,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2015"
        },
        {
            "id": "2016",
            "cx": 34.45,
            "cy": -440.09,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2016"
        },
        {
            "id": "2017",
            "cx": 34.45,
            "cy": -350.35,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2017"
        },
        {
            "id": "2018",
            "cx": 34.45,
            "cy": -260.61,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2018"
        },
        {
            "id": "2019",
            "cx": 34.45,
            "cy": -179.74,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2019"
        },
        {
            "id": "2020",
            "cx": 34.45,
            "cy": -98.87,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2020"
        },
        {
            "id": "2021",
            "cx": 34.45,
            "cy": -18.0,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2021"
        }
    ],
    [
        {
            "id": "2160946550",
            "name": "Virtual Smoke an interactive 3D flow visualization technique",
            "year": 1992,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1992Virtual",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "This paper introduces a new technique for computer visualization of simultaneous three-dimensional vector and scalar fields such as velocity and temperature in reacting fluid flow fields. The technique, which we call Virtual Smoke, simulates the use of colored smoke for experimental gaseous fluid flow visualization. However, it is noninvasive and can animate, in particular, the dynamic behaviors of steady-state or instantaneous flow fields obtained from numerical simulations. Virtual Smoke is based on Volume Seeds and Volume Seedlings, which are direct volume visualization methods previously developed for highly interactive scalar volume data exploration. We use data from combustion simulations to demonstrate the effectiveness of Virtual Smoke.",
            "topic": 12,
            "cx": 171.45,
            "cy": -2522.89,
            "rx": 76.24,
            "ry": 26.74,
            "text1": "Liu1992Vir...",
            "text2": "28"
        },
        {
            "id": "2120835680",
            "name": "Cloud tracing in convection-diffusion systems",
            "year": 1993,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1993Cloud",
            "isKeyPaper": 1.0,
            "citationCount": 11,
            "abstract": "The paper describes a highly interactive method for computer visualization of simultaneous three-dimensional vector and scalar flow fields in convection-diffusion systems. This method allows a computational fluid dynamics user to visualize the basic physical process of dispersion and mixing rather than just the vector and scalar values computed by the simulation. It is based on transforming the vector field from a traditionally Eulerian reference frame into a Lagrangian reference frame. Fluid elements are traced through the vector field for the mean path as well as the statistical dispersion of the fluid elements about the mean position by using added scalar information about the root mean square value of the vector field and its Lagrangian time scale. In this way, clouds of fluid elements are traced not just mean paths. We have used this method to visualize the simulation of an industrial incinerator to help identify mechanisms for poor mixing. >",
            "topic": 12,
            "cx": 171.45,
            "cy": -2433.15,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Liu1993Clo...",
            "text2": "11"
        },
        {
            "id": "2118947032",
            "name": "Fast Algorithms for Visualizing Fluid Motion in Steady Flow on Unstructured Grids",
            "year": 1995,
            "firstName": "Shyh Kuang Ueng",
            "label": "Kuang1995Fast",
            "isKeyPaper": 1.0,
            "citationCount": 16,
            "abstract": "The plotting of streamlines is an effective way of visualizing fluid motion in steady flows. Additional information about the flowfield, such as local rotation and expansion, can be shown by drawing in the form of a ribbon or tube. In this paper, we present efficient algorithms for the construction of streamlines, streamribbons and streamtubes on unstructured grids. A specialized version of the Runge-Kutta method has been developed to speed up the integration of particle pathes. We have also derived close-form solutions for calculating angular rotation rate and radius to construct streamribbons and streamtubes, respectively. According to our analysis and test results, these formulations are two to four times better in performance than previous numerical methods. As a large number of traces are calculated, the improved performance could be significant.",
            "topic": 12,
            "cx": 171.45,
            "cy": -2271.41,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Kuang1995F...",
            "text2": "16"
        },
        {
            "id": "2018246367",
            "name": "Image graphs\u00e2\u20ac\u201da novel approach to visual data exploration",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Image",
            "isKeyPaper": 1.0,
            "citationCount": 72,
            "abstract": "For types of data visualization where the cost of producing images is high, and the relationship between the rendering parameters and the image produced is less than obvious, a visual representation of the exploration process can make the process more efficient and effective. Image graphs represent not only the results but also the process of data visualization. Each node in an image graph consists of an image and the corresponding visualization parameters used to produce it. Each edge in a graph shows the change in rendering parameters between the two nodes it connects. Image graphs are not just static representations: users can interact with a graph to review a previous visualization session or to perform new rendering. Operations which cause changes in rendering parameters can propagate through the graph. The user can take advantage of the information in image graphs to understand how certain parameter changes affect visualization results. Users can also share image graphs to streamline the process of collaborative visualization. We have implemented a volume visualization system using the image graph interface, and our examples in the paper come from this application.",
            "topic": 10,
            "cx": 254.45,
            "cy": -1965.67,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Liu1999Ima...",
            "text2": "72"
        },
        {
            "id": "1982953486",
            "name": "A spreadsheet interface for visualization exploration",
            "year": 2000,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2000A",
            "isKeyPaper": 1.0,
            "citationCount": 46,
            "abstract": "As the size and complexity of data sets continues to increase, the development of user interfaces and interaction techniques that expedite the process of exploring that data must receive new attention. Regardless of the speed of rendering, it is important to coherently organize the visual process of exploration: this information both grants insights about the data to a user and can be used by collaborators to understand the results. To fulfil these needs, we present a spreadsheet-like interface to data exploration. The interface displays a 2-dimensional window into visualization parameter space which users manipulate as they search for desired results. Through tabular organization and a clear correspondence between parameters and results, the interface eases the discovery, comparison and analysis of the underlying data. Users can utilize operators and the integrated interpreter to further explore and automate the visualization process; using a method introduced in this paper, these operations can be applied to cells in different stacks of the interface. Via illustrations using a variety of data sets, we demonstrate the efficacy of this novel interface.",
            "topic": 8,
            "cx": 161.45,
            "cy": -1875.93,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2000A",
            "text2": "46"
        },
        {
            "id": "2090746914",
            "name": "Visualizing visualizations User interfaces for managing and exploring scientific visualization data",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000Visualizing",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "The process of scientific visualization is inherently iterative. A good visualization comes from experimenting with visualization, rendering, and viewing parameters to bring out the most relevant information in the data. A good data visualization system thus lets scientists interactively explore the parameter space intuitively. The more efficient the system, the fewer the number of iterations needed for parameter selection. Over the past 10 years, significant efforts have gone into advancing visualization technology (such as real-time volume rendering and immersive environments), but little into coherently representing the process and results (images and insights) of visualization. This information about the data exploration should be shared and reused. In particular, for types of data visualization with a high cost of producing images and less than obvious relationship between the rendering parameters and the image produced, a visual representation of the exploration process can make the process more efficient and effective. This visual representation of data exploration process and results can be incorporated into and become a part of the user interface of a data exploration system. That is, we need to go beyond the traditional graphical user interface (GUI) design by coupling it with a mechanism that helps users keep track of their visualization experience, use it to generate new visualizations, and share it with others. Doing so can reduce the cost of visualization, particularly for routine analysis of large-scale data sets.",
            "topic": 53,
            "cx": 307.45,
            "cy": -1875.93,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2000Vis...",
            "text2": "22"
        },
        {
            "id": "2092430905",
            "name": "Parallel visualization of large-scale aerodynamics calculations a case study on the Cray T3E",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 21,
            "abstract": "This paper reports the performance of a parallel volume rendering algorithm for visualizing a large-scale unstructured-grid dataset produced by a three-dimensional aerodynamics simulation. This dataset, containing over 18 million tetrahedra, allows us to extend our performance results to a problem which is more than 30 times larger than the one we examined previously. This high resolution dataset also allows us to see fine, three-dimensional features in the flow field. All our tests were performed on the SGI/Cray T3E operated by NASA's Goddard Space Flight Center. Using 511 processors, a rendering rate of almost 9 million tetrahedra/second was achieved with a parallel overhead of 26%.",
            "topic": 19,
            "cx": 641.45,
            "cy": -1965.67,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu1999Par...",
            "text2": "21"
        },
        {
            "id": "2115314149",
            "name": "Visualizing Very Large-Scale Earthquake Simulations",
            "year": 2003,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2003Visualizing",
            "isKeyPaper": 1.0,
            "citationCount": 32,
            "abstract": "This paper presents a parallel adaptive rendering algorithm and its performance for visualizing time-varying unstructured volume data generated from large-scale earthquake simulations. The objective is to visualize 3D seismic wave propagation generated from a 0.5 Hz simulation of the Northridge earthquake, which is the highest resolution volume visualization of an earthquake simulation performed to date. This scalable high-fidelity visualization solution we provide to the scientists allows them to explore in the temporal, spatial, and visualization domain of their data at high resolution. This new high resolution explorability, likely not presently available to most computational science groups, will help lead to many new insights. The performance study we have conducted on a massively parallel computer operated at the Pittsburgh Supercomputing Center helps direct our design of a simulation-time visualization strategy for the higher-resolution, 1Hz and 2 Hz, simulations.",
            "topic": 66,
            "cx": 624.45,
            "cy": -1606.71,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2003Vis...",
            "text2": "32"
        },
        {
            "id": "2116283033",
            "name": "Parallel rendering of 3D AMR data on the SGI/Cray T3E",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 32,
            "abstract": "This paper describes work-in-progress on developing parallel visualization strategies for 3D Adaptive Mesh Refinement (AMR) data. AMR is a simple and powerful tool for modeling many important scientific and engineering problems. However visualization tools for 3D AMR data are not generally available. Converting AMR data onto a uniform mesh would result in high storage requirements, and rendering the uniform-mesh data on an average graphics workstation can be painfully slow if not impossible. The adaptive nature of the embedded mesh demands sophisticated visualization calculations. In this work, we compare the performance and storage requirements of a parallel volume renderer for regular-mesh data with a new parallel renderer based on adaptive sampling. While both renderers can achieve interactive visualization, the new approach offers significant performance gains, as indicated by our experiments on the SGI/Cray T3E.",
            "topic": 19,
            "cx": 466.45,
            "cy": -1965.67,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu1999Par...",
            "text2": "32"
        },
        {
            "id": "27528377",
            "name": "Compression and Accelerated Rendering of Time-Varying Volume Data",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000Compression",
            "isKeyPaper": 1.0,
            "citationCount": 39,
            "abstract": "Author(s): Ma, Kwan-Liu; Shen, H. | Abstract: Visualization of time-varying volumetric data sets, which may be obtained from numerical simulations or sensing instruments, provides scientists insights into the detailed dynamics of the phenomenon under study. This paper describes our study of a coherent solution based on quantization coupled with octree and difference encoding, and adaptive rendering for efficient visualization of timevarying volumetric data. Quantization is used to attain voxel-level compression and may have a significant influence on the performance of the subsequent encoding and visualization steps. Octree encoding is used for spatial domain compression, and difference encoding for temporal domain compression. In essence, neighboring voxels may be fused into macro voxels if they have similar values, and subtrees at consecutive time steps may be merged if they are identical. The software rendering process is tailored according to the tree structures and the volume visualization process. With the tree representation, selective rendering may be performed very efficiently. Additionally, the I/O costs are reduced. With these combined savings, a higher level of user interactivity is achieved. We have studied a variety of time-varying volume data sets, performed encoding based on data statistics, and optimized the rendering calculations wherever possible. Preliminary tests on workstations have shown in many cases tremendous reduction by as high as 90% in both storage space and inter-frame delay when compared to direct rendering of the raw data.",
            "topic": 7,
            "cx": 980.45,
            "cy": -1875.93,
            "rx": 85.62,
            "ry": 26.74,
            "text1": "Liu2000Com...",
            "text2": "39"
        },
        {
            "id": "2039138386",
            "name": "Texture hardware assisted rendering of time-varying volume data",
            "year": 2001,
            "firstName": "Eric B. Lum",
            "label": "B.2001Texture",
            "isKeyPaper": 1.0,
            "citationCount": 79,
            "abstract": "In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.",
            "topic": 7,
            "cx": 1018.45,
            "cy": -1786.19,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "B.2001Text...",
            "text2": "79"
        },
        {
            "id": "2154046714",
            "name": "Visualization exploration and encapsulation via a spreadsheet-like interface",
            "year": 2001,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2001Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 85,
            "abstract": "Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains.",
            "topic": 8,
            "cx": 161.45,
            "cy": -1786.19,
            "rx": 74.91,
            "ry": 26.74,
            "text1": "J.2001Visu...",
            "text2": "85"
        },
        {
            "id": "2166470747",
            "name": "High performance visualization of time-varying volume data over a wide-area network status",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000High",
            "isKeyPaper": 1.0,
            "citationCount": 92,
            "abstract": "This paper presents an end-to-end, low-cost solution for visualizing time-varying volume data rendered on a parallel computer located at a remote site. Pipelining and careful grouping of processors are used to hide I/O time and to maximize processors utilization. Compression is used to significantly cut down the cost of transferring output images from the parallel computer to a display device through a widearea network. This complete rendering pipeline makes possible highly efficient rendering and remote viewing of high resolution time-varying data sets in the absence of high-speed network and parallel I/O support. To study the performance of this rendering pipeline and to demonstrate high-performance remote visualization, tests were conducted on a PC cluster in Japan as well as an SGI Origin 2000 operated at the NASA Ames Research Center with the display located at UC Davis.",
            "topic": 19,
            "cx": 1164.45,
            "cy": -1875.93,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Liu2000Hig...",
            "text2": "92"
        },
        {
            "id": "2145293470",
            "name": "Visualization of multidimensional multivariate volume data using hardware-accelerated non-photorealistic rendering techniques",
            "year": 2002,
            "firstName": "Aleksander Stompel",
            "label": "Stompel2002Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 26,
            "abstract": "This paper presents a set of feature enhancement techniques. coupled with hardware-accelerated non-photorealistic rendering for generating more perceptually effective visualizations of multidimensional, multivariate volume data, such as those obtained from typical computational fluid dynamics simulations. For time-invariant data, one or more variables are used to either highlight important features in another variable, or add contextural information to the visualization. For time-varying data, rendering of each time step also takes into account the values at neighboring time steps to reinforce the perception of the changing features in the data over time. With hardware-accelerated rendering, interactive visualization becomes possible leading to increased explorability and comprehension of the data.",
            "topic": 7,
            "cx": 768.45,
            "cy": -1696.45,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Stompel200...",
            "text2": "26"
        },
        {
            "id": "2947284622",
            "name": "Feature-Enhanced Visualization of Multidimensional Multivariate Volume Data Using Non-photorealistic Rendering Techniques",
            "year": 2002,
            "firstName": "Eric B. Lum",
            "label": "B.2002Feature-Enhanced",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Author(s): Lum, Eric; Ma, Kwan-Liu | Abstract: This paper presents a set of feature enhancement techniques coupled with hardware-accelerated nonphotorealistic rendering for generating more perceptually effective visualization of multidimensional, multivariate volume data, such as those obtained from typical computational fluid dynamics simulations. For time-invariant data, one or more variables are used to either highlight important features in another variable, or add contextural information to the visualization. For time-varying data, rendering of each time step also takes into account the values at neighboring time steps to reinforce the perception of the changing features in the data over time. With hardware-accelerated rendering, interactive visualization becomes possible leading to increased explorability and comprehension of the data.",
            "topic": 7,
            "cx": 1164.45,
            "cy": -1696.45,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2002Feat...",
            "text2": "13"
        },
        {
            "id": "1556372880",
            "name": "I/O strategies for parallel rendering of large time-varying volume data",
            "year": 2004,
            "firstName": "Hongfeng Yu",
            "label": "Yu2004I/O",
            "isKeyPaper": 1.0,
            "citationCount": 15,
            "abstract": "This paper presents I/O solutions for the visualization of time-varying volume data in a parallel and distributed computing environment. Depending on the number of rendering processors used, our I/O strategies help signifi- cantly lower interframe delay by employing a set of I/O processors coupled with MPI parallel I/O support. The targeted application is earthquake modeling using a large 3D unstructured mesh consisting of one hundred millions cells. Our test results on the HP/Compaq AlphaServer operated at the Pittsburgh Supercomputing Center demonstrate that the I/O strategies effectively remove the I/O bottlenecks commonly present in time-varying data visualization. This high-performance visualization solution we provide to the scientists allows them to explore their data in the temporal, spatial, and visualization domains at high resolution. This new high-resolution explorability, likely not presently available to most computational science groups, will help lead to many new insights.",
            "topic": 7,
            "cx": 1272.45,
            "cy": -1516.97,
            "rx": 64.19,
            "ry": 26.74,
            "text1": "Yu2004I/O",
            "text2": "15"
        },
        {
            "id": "2114283921",
            "name": "Advanced Visualization Technology for Terascale Particle Accelerator Simulations",
            "year": 2002,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2002Advanced",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "This paper presents two new hardware-assisted rendering techniques developed for interactive visualization of the terascale data generated from numerical modeling of next-generation accelerator designs. The first technique, based on a hybrid rendering approach, makes possible interactive exploration of large-scale particle data from particle beam dynamics modeling. The second technique, based on a compact texture-enhanced representation, exploits the advanced features of commodity graphics cards to achieve perceptually effective visualization of the very dense and complex electromagnetic fields produced from the modeling of reflection and transmission properties of open structures in an accelerator design. Because of the collaborative nature of the overall accelerator modeling project, the visualization technology developed is for both desktop and remote visualization settings. We have tested the techniques using both time-varying particle data sets containing up to one billion particles per time step and electromagnetic field data sets with millions of mesh elements.",
            "topic": 75,
            "cx": 948.45,
            "cy": -1696.45,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu2002Adv...",
            "text2": "28"
        },
        {
            "id": "2103068632",
            "name": "Using motion to illustrate static 3D shape-kinetic visualization",
            "year": 2003,
            "firstName": "Eric B. Lum",
            "label": "B.2003Using",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "In this paper, we present a novel visualization technique-kinetic visualization-that uses motion along a surface to aid in the perception of 3D shape and structure of static objects. The method uses particle systems, with rules such that particles flow over the surface of an object to not only bring out, but also attract attention to information on a shape that might not be readily visible with a conventional rendering method which uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that, in many cases, the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. We also describe how, for both types of data, a texture-based representation of this motion can be used for interactive visualization using PC graphics hardware. Finally, the results of a user study that we have conducted are presented, which show evidence that the supplemental motion cues can be helpful.",
            "topic": 85,
            "cx": 1056.45,
            "cy": -1606.71,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "B.2003Usin...",
            "text2": "29"
        },
        {
            "id": "2143275883",
            "name": "A model for the visualization exploration process",
            "year": 2002,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2002A",
            "isKeyPaper": 1.0,
            "citationCount": 53,
            "abstract": "The current state of the art in visualization research places a strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process---the results, history, and relationships between those results---is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize the information within the visualization process to further data exploration.",
            "topic": 0,
            "cx": 161.45,
            "cy": -1696.45,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2002A",
            "text2": "53"
        },
        {
            "id": "2114265882",
            "name": "A Model and Framework for Visualization Exploration",
            "year": 2007,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2007A",
            "isKeyPaper": 0.989546,
            "citationCount": 118,
            "abstract": "Visualization exploration is the process of extracting insight from data via interaction with visual depictions of that data. Visualization exploration is more than presentation; the interaction with both the data and its depiction is as important as the data and depiction itself. Significant visualization research has focused on the generation of visualizations (the depiction); less effort has focused on the exploratory aspects of visualization (the process). However, without formal models of the process, visualization exploration sessions cannot be fully utilized to assist users and system designers. Toward this end, we introduce the P-Set model of visualization exploration for describing this process and a framework to encapsulate, share, and analyze visual explorations. In addition, systems utilizing the model and framework are more efficient as redundant exploration is avoided. Several examples drawn from visualization applications demonstrate these benefits. Taken together, the model and framework provide an effective means to exploit the information within the visual exploration process",
            "topic": 8,
            "cx": 161.45,
            "cy": -1247.75,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2007A",
            "text2": "118"
        },
        {
            "id": "2064959254",
            "name": "Recent advances in hardware-accelerated volume rendering",
            "year": 2003,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2003Recent",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Abstract The programmability and texture support of consumer graphics accelerators have drawn a lot of attention from visualization researchers, resulting in some very important advances in interactive volume data visualization. For many applications, scientists can now perform routine data visualization and analysis tasks on their desktop PC with a consumer graphics card that was designed mainly for playing video games. This paper presents several representative hardware-accelerated algorithms that have been introduced recently to address the problems of classification, illumination, non-photorealistic rendering, decoding, and image compositing in volume data visualization.",
            "topic": 7,
            "cx": 801.45,
            "cy": -1606.71,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Liu2003Rec...",
            "text2": "13"
        },
        {
            "id": "2146362647",
            "name": "RINGS A Technique for Visualizing Large Hierarchies",
            "year": 2002,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2002RINGS",
            "isKeyPaper": 1.0,
            "citationCount": 61,
            "abstract": "We present RINGS, a technique for visualizing large trees. We introduce a new ringed circular layout of nodes to make more efficient use of limited display space. RINGS provides the user with the means to specify areas of primary andsecond ary focus, andis able to show multiple foci without compromising understanding of the graph. The strength of RINGS is its ability to show more area in focus andmore contextual information than existing techniques. We demonstrate the effectiveness of RINGS by applying it to the visualization of a Unix file directory.",
            "topic": 25,
            "cx": 1383.45,
            "cy": -1696.45,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Tee2002RIN...",
            "text2": "61"
        },
        {
            "id": "2130218153",
            "name": "MoireGraphs radial focus+context visualization and interaction for graphs with visual nodes",
            "year": 2003,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2003MoireGraphs",
            "isKeyPaper": 1.0,
            "citationCount": 84,
            "abstract": "Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focuscontext radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.",
            "topic": 10,
            "cx": 1383.45,
            "cy": -1606.71,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "J.2003Moir...",
            "text2": "84"
        },
        {
            "id": "2162126826",
            "name": "A Parallel Visualization Pipeline for Terascale Earthquake Simulations",
            "year": 2004,
            "firstName": "Hongfeng Yu",
            "label": "Yu2004A",
            "isKeyPaper": 1.0,
            "citationCount": 45,
            "abstract": "This paper presents a parallel visualization pipeline implemented at the Pittsburgh Supercomputing Center (PSC) for studying the largest earthquake simulation ever performed. The simulation employs 100 million hexahedral cells to model 3D seismic wave propagation of the 1994 Northridge earthquake. The time-varying dataset produced by the simulation requires terabytes of storage space. Our solution for visualizing such terascale simulations is based on a parallel adaptive rendering algorithm coupled with a new parallel I/O strategy which effectively reduces interframe delay by dedicating some processors to I/O and preprocessing tasks. In addition, a 2D vector field visualization method and a 3D enhancement technique are incorporated into the parallel visualization framework to help scientists better understand the wave propagation both on and under the ground surface. Our test results on the HP/Compaq AlphaServer operated at the PSC show that we can completely remove the I/O bottlenecks commonly present in time-varying data visualization. The high-performance visualization solution we provide to the scientists allows them to explore their data in the temporal, spatial, and variable domains at high resolution. The new high-resolution explorability, likely not available to most computational science groups, will help lead to many new insights.",
            "topic": 66,
            "cx": 666.45,
            "cy": -1516.97,
            "rx": 56.64,
            "ry": 26.74,
            "text1": "Yu2004A",
            "text2": "45"
        },
        {
            "id": "2148775223",
            "name": "Intelligent Feature Extraction and Tracking for Visualizing Large-Scale 4D Flow Simulations",
            "year": 2005,
            "firstName": "Fan Yin Tzeng",
            "label": "Yin2005Intelligent",
            "isKeyPaper": 1.0,
            "citationCount": 47,
            "abstract": "Terascale simulations produce data that is vast in spatial, temporal, and variable domains, creating a formidable challenge for subsequent analysis. Feature extraction as a data reduction method offers a viable solution to this large data problem. This paper presents a new approach to the problem of extracting and visualizing 4D features within large volume data. Conventional methods requires either an analytical description of the feature of interest or tedious manual intervention throughout the feature extraction and tracking process. We show that it is possible for a visualization system to learn to extract and track features in complex 4D flow field according to their visual properties, location, shape, and size. The basic approach is to employ machine learning in the process of visualization. Such an intelligent system approach is powerful because it allows us to extract and track an feature of interest in a high-dimensional space without explicitly specifying the relations between those dimensions, resulting in a greatly simplified and intuitive visualization interface.",
            "topic": 60,
            "cx": 581.45,
            "cy": -1427.23,
            "rx": 77.15,
            "ry": 26.74,
            "text1": "Yin2005Int...",
            "text2": "47"
        },
        {
            "id": "2155542779",
            "name": "A visual exploration process for the analysis of Internet routing data",
            "year": 2003,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2003A",
            "isKeyPaper": 1.0,
            "citationCount": 41,
            "abstract": "The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.",
            "topic": 29,
            "cx": 1538.45,
            "cy": -1606.71,
            "rx": 61.54,
            "ry": 26.74,
            "text1": "Tee2003A",
            "text2": "41"
        },
        {
            "id": "2095627337",
            "name": "Detecting flaws and intruders with visual data analysis",
            "year": 2004,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2004Detecting",
            "isKeyPaper": 1.0,
            "citationCount": 59,
            "abstract": "The task of sifting through large amounts of data to find useful information spawned the field of data mining. Most data mining approaches are based on machine-learning techniques, numerical analysis, or statistical modeling. They use human interaction and visualization only minimally. Such automatic methods can miss some important features of the data. Incorporating human perception into the data mining process through interactive visualization can help us better understand the complex behaviors of computer network systems. This article describes visual-analytics-based solutions and outlines a visual exploration process for log analysis. Three log-file analysis applications demonstrate our approach's effectiveness in discovering flaws and intruders in network systems.",
            "topic": 33,
            "cx": 1538.45,
            "cy": -1516.97,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Tee2004Det...",
            "text2": "59"
        },
        {
            "id": "2054501662",
            "name": "A cluster-space visual interface for arbitrary dimensional classification of volume data",
            "year": 2004,
            "firstName": "Fan Yin Tzeng",
            "label": "Yin2004A",
            "isKeyPaper": 1.0,
            "citationCount": 60,
            "abstract": "In volume visualization, users typically specify transfer functions to classify the data and assign visual attributes to each material class. Higher-dimensional classification makes it easier to differentiate material classes since more data properties are considered. One of the difficulties in using higher-dimensional classification is the absence of appropriate user interfaces. We introduce an intuitive user interface that allows the user to work in the cluster space, which shows the material classes with a set of material widgets, rather than work in the transfer function space. This interface not only provides the user the capability to specify arbitrary-dimensional transfer functions, but also allows the user to operate directly on the classification and visualization results.",
            "topic": 81,
            "cx": 1698.45,
            "cy": -1516.97,
            "rx": 60.21,
            "ry": 26.74,
            "text1": "Yin2004A",
            "text2": "60"
        },
        {
            "id": "2127273065",
            "name": "Intelligent Focus+Context Volume Visualization",
            "year": 2008,
            "firstName": "Cheng Kai Chen",
            "label": "Kai2008Intelligent",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "Although graphics processing unit (GPU) acceleration makes possible interactive volume rendering, successful volume visualization relies on the ability to quickly and correctly classify the volume into different materials or features. Among various classification techniques, one very attractive and effective method is employing machine learning to classify the whole volume according to some minimum user input through an interactive brushing interface, where users paint directly on slices of the volume. For routine visualization tasks, we can thus reduce their cost if the visualization system can learn the tasks and apply the captured knowledge in future tasks. This paper presents an intelligent, interactive visualization system that supports FocusContext viewing of volume data. Features of interest should be the focal point of the visualization, and by applying appropriate rendering methods we are able to enhance these features and create more illustrative visualizations in a FocusContext style. We show with a set of case studies that it is possible to use machine learning to not only help classify volume but also better present the classified results. This new capability makes visualization a more usable tool.",
            "topic": 7,
            "cx": 1698.45,
            "cy": -1158.01,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2008Int...",
            "text2": "4"
        },
        {
            "id": "2170839387",
            "name": "Lighting Transfer Functions Using Gradient Aligned Sampling",
            "year": 2004,
            "firstName": "Eric B. Lum",
            "label": "B.2004Lighting",
            "isKeyPaper": 1.0,
            "citationCount": 78,
            "abstract": "An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.",
            "topic": 81,
            "cx": 1872.45,
            "cy": -1516.97,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2004Ligh...",
            "text2": "78"
        },
        {
            "id": "2131385811",
            "name": "Interactive multi-scale exploration for volume classification",
            "year": 2006,
            "firstName": "Eric B. Lum",
            "label": "B.2006Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 19,
            "abstract": "Filter banks are a class of signal processing techniques that can be used to reveal the local energy of a signal at multiple scales. Utilizing such filtering allows us to consider local texture and other data characteristics, and permits volume classification and visualization that cannot be accomplished easily using conventional, transfer function-based methods. Our filter bank approach increases the dimensionality, and thus, the complexity of the classification task. We have therefore developed an interactive user interface for specifying and visualizing these higher dimensional classifiers, which enables volume data exploration and visualization in a filter-bank space. We demonstrate that this technique is particularly effective for the classification of noisy data, and for classifying regions that are difficult to approach using conventional methods.",
            "topic": 7,
            "cx": 1872.45,
            "cy": -1337.49,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "B.2006Inte...",
            "text2": "19"
        },
        {
            "id": "2163363303",
            "name": "Size-based Transfer Functions A New Volume Exploration Technique",
            "year": 2008,
            "firstName": "Carlos D. Correa",
            "label": "D.2008Size-based",
            "isKeyPaper": 1.0,
            "citationCount": 135,
            "abstract": "The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.",
            "topic": 81,
            "cx": 1872.45,
            "cy": -1158.01,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "D.2008Size...",
            "text2": "135"
        },
        {
            "id": "2096945381",
            "name": "In-situ processing and visualization for ultrascale simulations",
            "year": 2007,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2007In-situ",
            "isKeyPaper": 1.0,
            "citationCount": 67,
            "abstract": "The growing power of parallel supercomputers gives scientists the ability to simulate more complex problems at higher fidelity, leading to many high-impact scientific advances. To maximize the utilization of the vast amount of data generated by these simulations, scientists also need scalable solutions for studying their data to different extents and at different abstraction levels. As we move into peta- and exa-scale computing, simply dumping as much raw simulation data as the storage capacity allows for post-processing analysis and visualization is no longer a viable approach. A common practice is to use a separate parallel computer to prepare data for subsequent analysis and visualization. A naive realization of this strategy not only limits the amount of data that can be saved, but also turns I/O into a performance bottleneck when using a large parallel system. We conjecture that the most plausible solution for the peta- and exa-scale data problem is to reduce or transform the data in-situ as it is being generated, so the amount of data that must be transferred over the network is kept to a minimum. In this paper, we discuss different approaches to in-situ processing and visualization as well as the results of our preliminary study using large-scale simulation codes on massively parallel supercomputers.",
            "topic": 47,
            "cx": 2415.45,
            "cy": -1247.75,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "Liu2007In-...",
            "text2": "67"
        },
        {
            "id": "2169175194",
            "name": "Visualization and parallel I/O at extreme scale",
            "year": 2008,
            "firstName": "Robert Ross",
            "label": "Ross2008Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 24,
            "abstract": "In our efforts to solve ever more challenging problems through computational techniques, the scale of our compute systems continues to grow. As we approach petascale, it becomes increasingly important that all the resources in the system be used as efficiently as possible, not just the floating-point units. Because of hardware, software, and usability challenges, storage resources are often one of the most poorly used and performing components of today's compute systems. This situation can be especially true in the case of the analysis phases of scientific workflows. In this paper we discuss the impact of large-scale data on visual analysis operations and examine a collection of approaches to I/O in the visual analysis process. First we examine the performance of volume rendering on a leadership-computing platform and assess the relative cost of I/O, rendering, and compositing operations. Next we analyze the performance implications of eliminating preprocessing from this example workflow. Then we describe a technique that uses data reorganization to improve access times for data-intensive volume rendering.",
            "topic": 47,
            "cx": 2415.45,
            "cy": -1158.01,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Ross2008Vi...",
            "text2": "24"
        },
        {
            "id": "2040195604",
            "name": "StarGate A Unified Interactive Visualization of Software Projects",
            "year": 2008,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2008StarGate",
            "isKeyPaper": 1.0,
            "citationCount": 33,
            "abstract": "With the success of open source software projects, such as Apache and Mozilla, comes the opportunity to study the development process. In this paper, we present StarGate: a novel system for visualizing software projects. Whereas previous software project visualizations concentrated mainly on the source code changes, we literally place the developers in the center of our design. Developers are grouped visually into clusters corresponding to the areas of the file repository they work on the most. Connections are drawn between people who communicate via email. The changes to the repository are also displayed. With StarGate, it is easy to look beyond the source code and see trends in developer activity. The system can be used by anyone interested in the project, but it especially benefits project managers, project novices and software engineering researchers.",
            "topic": 2,
            "cx": 2594.45,
            "cy": -1158.01,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu2008Sta...",
            "text2": "33"
        },
        {
            "id": "2099306854",
            "name": "Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing",
            "year": 2009,
            "firstName": "Christopher Wesley Muelder",
            "label": "Wesley2009Visual",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.",
            "topic": 19,
            "cx": 2594.45,
            "cy": -1068.27,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Wesley2009...",
            "text2": "20"
        },
        {
            "id": "2136730689",
            "name": "Parallel volume rendering on the IBM Blue Gene/P",
            "year": 2008,
            "firstName": "Tom Peterka",
            "label": "Peterka2008Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "Parallel volume rendering is implemented and tested on an IBM Blue Gene distributed-memory parallel architecture. The goal of studying the cost of parallel rendering on a new class of supercomputers such as the Blue Gene/P is not necessarily to achieve real-time rendering rates. It is to identify and understand the extent of bottlenecks and interactions between various components that affect the design of future visualization solutions on these machines, solutions that may offer alternatives to hardware-accelerated volume rendering, for example, when large volumes, large image sizes, and very high quality results are dictated by peta- and exascale data. As a step in that direction, this study presents data from experiments under a number of conditions, including dataset size, number of processors, low- and high-quality rendering, offline storage of results, and streaming of images for remote display. Performance is divided into three main sections of the algorithm: disk I/O, rendering, and compositing. The dynamic balance among these tasks varies with the number of processors and other conditions. Lessons learned from the work include understanding the balance between parallel I/O, computation, and communication within the context of visualization on supercomputers; recommendations for tuning and optimization; and opportunities for further scaling. Extrapolating these results to very large data and image sizes suggests that a distributed-memory high-performance computing architecture such as the Blue Gene is a viable platform for some types of visualization at very large scales.",
            "topic": 7,
            "cx": 2237.45,
            "cy": -1158.01,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Peterka200...",
            "text2": "29"
        },
        {
            "id": "2144823948",
            "name": "End-to-End Study of Parallel Volume Rendering on the IBM Blue Gene/P",
            "year": 2009,
            "firstName": "Tom Peterka",
            "label": "Peterka2009End-to-End",
            "isKeyPaper": 1.0,
            "citationCount": 40,
            "abstract": "In addition to their role as simulation engines, modern supercomputers can be harnessed for scientific visualization. Their extensive concurrency, parallel storage systems, and high-performance interconnects can mitigate the expanding size and complexity of scientific datasets and prepare for in situ visualization of these data. In ongoing research into testing parallel volume rendering on the IBM Blue Gene/P (BG/P), we measure performance of disk I/O, rendering, and compositing on large datasets, and evaluate bottlenecks with respect to system-specific I/O and communication patterns. To extend the scalability of the direct-send image compositing stage of the volume rendering algorithm, we limit the number of compositing cores when many small messages are exchanged. To improve the data-loading stage of the volume renderer, we study the I/O signatures of the algorithm in detail. The results of this research affirm that a distributed-memory computing architecture such as BG/P is a scalable platform for large visualization problems.",
            "topic": 7,
            "cx": 2237.45,
            "cy": -1068.27,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Peterka200...",
            "text2": "40"
        },
        {
            "id": "2011060348",
            "name": "The Occlusion Spectrum for Volume Classification and Visualization",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009The",
            "isKeyPaper": 1.0,
            "citationCount": 72,
            "abstract": "Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.",
            "topic": 7,
            "cx": 1825.45,
            "cy": -1068.27,
            "rx": 66.44,
            "ry": 26.74,
            "text1": "D.2009The",
            "text2": "72"
        },
        {
            "id": "2029393506",
            "name": "Visibility Histograms and Visibility-Driven Transfer Functions",
            "year": 2011,
            "firstName": "Carlos D. Correa",
            "label": "D.2011Visibility",
            "isKeyPaper": 1.0,
            "citationCount": 75,
            "abstract": "Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the general notion of visibility histograms, which are multidimensional graphical representations of the distribution of visibility in a volume-rendered image. In this paper, we explore the 1D and 2D transfer functions that result from intensity values and gradient magnitude. With the help of these histograms, users can manage a complex set of transfer function parameters that maximize the visibility of the intervals of interest and provide high quality images of volume data. We present a semiautomated method for generating transfer functions, which progressively explores the transfer function space toward the goal of maximizing visibility of important structures. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D and 2D opacity transfer functions based on scalar values, as well as with other more sophisticated rendering algorithms.",
            "topic": 81,
            "cx": 1950.45,
            "cy": -888.79,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "D.2011Visi...",
            "text2": "75"
        },
        {
            "id": "1611667971",
            "name": "Depicting Time Evolving Flow with Illustrative Visualization Techniques",
            "year": 2009,
            "firstName": "Wei Hsien Hsu",
            "label": "Hsien2009Depicting",
            "isKeyPaper": 1.0,
            "citationCount": 17,
            "abstract": "Visualization has become an indispensable tool for scientists to extract knowledge from large amounts of data and convey that knowledge to others. Visualization may be exploratory or illustrative. Exploratory visualization generally provides multiple views of the data at different levels of abstraction and should be highly interactive, whereas illustrative visualization is often made offline at high quality with sufficient knowledge about the data and features of interest. Techniques used by professional illustrators may be borrowed to enhance the clarity and aesthetics of the visualization. This paper presents a set of visualization techniques for presenting the evolution of 3D flow. While the spatial features of the data is rendered in 3D space, the temporal behaviors of the flow are depicted using image-based methods. We demonstrate visualization results generated using three data sets obtained from simulations.",
            "topic": 12,
            "cx": 2961.45,
            "cy": -1068.27,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Hsien2009D...",
            "text2": "17"
        },
        {
            "id": "2046832287",
            "name": "Visibility guided multimodal volume visualization",
            "year": 2013,
            "firstName": "Lin Zheng",
            "label": "Zheng2013Visibility",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "With the advances in dual medical imaging, the requirements for multimodal and multifield volume visualization begin to emerge. One of the challenges in multimodal visualization is how to simplify the process of generating informative pictures from complementary data. In this paper we present an automatic technique that makes use of dual modality information, such as CT and PET, to produce effective focuscontext volume visualization. With volume ray casting, per-ray visibility histograms summarize the contribution of samples along each ray to the final image. By quantifying visibility for the region of interest, indicated by the PET data, occluding tissues can be made just transparent enough to give a clear view of the features in that region while preserving some context. Unlike most previous methods relying on costly-preprocessing and tedious manual tuning, our technique achieves comparable and better results based on on-the-fly processing that still enables interactive visualization. Our work thus offers a powerful visualization technique for examining multimodal volume data. We demonstrate the technique with scenarios for the detection and diagnosis of cancer and other pathologies.",
            "topic": 7,
            "cx": 2174.45,
            "cy": -709.31,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Zheng2013V...",
            "text2": "1"
        },
        {
            "id": "2138396059",
            "name": "Visibility-driven transfer functions",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009Visibility-driven",
            "isKeyPaper": 1.0,
            "citationCount": 44,
            "abstract": "Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the notion of visibility-driven transfer functions, which are transfer functions that provide a good visibility of features of interest from a given viewpoint. To achieve this, we introduce visibility histograms. These histograms provide graphical cues that intuitively inform the user about the contribution of particular scalar values to the final image. By carefully manipulating the parameters of the opacity transfer function, users can now maximize the visibility of the intervals of interest in a volume data set. Based on this observation, we also propose a semi-automated method for generating transfer functions, which progressively improves a transfer function defined by the user, according to a certain importance metric. Now the user does not have to deal with the tedious task of making small changes to the transfer function parameters, but now he/she can rely on the system to perform these searches automatically. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D opacity transfer functions based on scalar values, as well as with multidimensional transfer functions and other more sophisticated rendering algorithms.",
            "topic": 81,
            "cx": 2064.45,
            "cy": -1068.27,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "D.2009Visi...",
            "text2": "44"
        },
        {
            "id": "2131433745",
            "name": "An exploratory technique for coherent visualization of time-varying volume data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010An",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "The selection of an appropriate global transfer function is essential for visualizing time-varying simulation data. This is especially challenging when the global data range is not known in advance, as is often the case in remote and in-situ visualization settings. Since the data range may vary dramatically as the simulation progresses, volume rendering using local transfer functions may not be coherent for all time steps. We present an exploratory technique that enables coherent classification of time-varying volume data. Unlike previous approaches, which require pre-processing of all time steps, our approach lets the user explore the transfer function space without accessing the original 3D data. This is useful for interactive visualization, and absolutely essential for in-situ visualization, where the entire simulation data range is not known in advance. Our approach generates a compact representation of each time step at rendering time in the form of ray attenuation functions, which are used for subsequent operations on the opacity and color mappings. The presented approach offers interactive exploration of time-varying simulation data that alleviates the cost associated with reloading and caching large data sets.",
            "topic": 15,
            "cx": 2064.45,
            "cy": -978.53,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "22"
        },
        {
            "id": "2138422603",
            "name": "Interactive feature extraction and tracking by utilizing region coherency",
            "year": 2009,
            "firstName": "Chris Muelder",
            "label": "Muelder2009Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 33,
            "abstract": "The ability to extract and follow time-varying flow features in volume data generated from large-scale numerical simulations enables scientists to effectively see and validate modeled phenomena and processes. Extracted features often take much less storage space and computing resources to visualize. Most feature extraction and tracking methods first identify features of interest in each time step independently, then correspond these features in consecutive time steps of the data. Since these methods handle each time step separately, they do not use the coherency of the feature along the time dimension in the extraction process. In this paper, we present a prediction-correction method that uses a prediction step to make the best guess of the feature region in the subsequent time step, followed by growing and shrinking the border of the predicted region to coherently extract the actual feature of interest. This method makes use of the temporal-space coherency of the data to accelerate the extraction process while implicitly solving the tedious correspondence problem that previous methods focus on. Our method is low cost with very little storage overhead, and thus facilitates interactive or runtime extraction and visualization, unlike previous methods which were largely suited for batch-mode processing due to high computational cost.",
            "topic": 61,
            "cx": 2777.45,
            "cy": -1068.27,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muelder200...",
            "text2": "33"
        },
        {
            "id": "1457609601",
            "name": "Scalable parallel feature extraction and tracking for large time-varying 3D volume data",
            "year": 2013,
            "firstName": "Yang Wang",
            "label": "Wang2013Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 9,
            "abstract": "Large-scale time-varying volume data sets can take terabytes to petabytes of storage space to store and process. One promising approach is to process the data in parallel, and then extract and analyze only features of interest, reducing required memory space by several orders of magnitude for following visualization tasks. However, extracting volume features in parallel is a non-trivial task as features might span over multiple processors, and local partial features are only visible within their own processors. In this paper, we discuss how to generate and maintain connectivity information of features across different processors. Based on the connectivity information, partial features can be integrated, which makes it possible to extract and track features for large data in parallel. We demonstrate the effectiveness and scalability of our approach using two data sets with up to 16384 processors.",
            "topic": 64,
            "cx": 2777.45,
            "cy": -709.31,
            "rx": 86.95,
            "ry": 26.74,
            "text1": "Wang2013Sc...",
            "text2": "9"
        },
        {
            "id": "2025518624",
            "name": "AniViz A Template-Based Animation Tool for Volume Visualization",
            "year": 2010,
            "firstName": "Hiroshi Akiba",
            "label": "Akiba2010AniViz",
            "isKeyPaper": 1.0,
            "citationCount": 14,
            "abstract": "Interactive visualization is the key to insightful exploration. Animation can effectively convey a complex process or structure. Deriving a sequence of desired keyframes is a painstaking process entailing much trial and error. To help alleviate this problem, we developed AniViz-a tool for making visualization animations of time-varying, multivariate volume data. AniViz is an animation tool following two principles. First, it's desirable to directly turn the results of data exploration and visualization into animation content. Second, users can create a complex animation sequence by combining several simple effects. Such effects, and operators to combine them, are fine-tuned via an intuitive user interface.",
            "topic": 65,
            "cx": 2950.45,
            "cy": -978.53,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Akiba2010A...",
            "text2": "14"
        },
        {
            "id": "2023029656",
            "name": "Scientific Storytelling Using Visualization",
            "year": 2012,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2012Scientific",
            "isKeyPaper": 1.0,
            "citationCount": 63,
            "abstract": "Scientists frequently tell stories using visualizations of scientific data, in the process of disseminating findings to peers and the general public. However, techniques and methods for effective scientific storytelling have received little attention so far. This article explores how literary and theatrical narrative conventions can inform the design and presentation of visualizations, and discusses the challenges of adapting scientific visualizations for broader audiences. It also summarizes recent workshops' findings on the role of storytelling in visualizations, and presents several examples of successful scientific-storytelling production teams. The conclusion is that scientific storytelling deserves greater support and recognition by the visualization community.",
            "topic": 53,
            "cx": 2883.45,
            "cy": -799.05,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2012Sci...",
            "text2": "63"
        },
        {
            "id": "2113470734",
            "name": "Storytelling via Navigation A Novel Approach to Animation for Scientific Visualization",
            "year": 2014,
            "firstName": "Isaac H. Liao",
            "label": "H.2014Storytelling",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "In scientific visualization, volume rendering is commonly used to show three-dimensional, time-varying data sets. To understand the spatial structure of volume data sets and how they change over time, animation is often necessary. Most current visualization tools use conventional keyframe-based interfaces to create animations, which can be tedious and time-consuming. We present a new, semi-automatic approach to creating animations of volume data based on a userxe2x80x99s interaction history as they navigate through a data set and adjust rendering parameters. Through a user study, we show that this new method requires significantly less time and perceived effort on the part of users compared to keyframe-based approaches, while still generating animations of comparable quality.",
            "topic": 65,
            "cx": 3040.45,
            "cy": -619.57,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "H.2014Stor...",
            "text2": "4"
        },
        {
            "id": "2070002217",
            "name": "A sketch-based interface for classifying and visualizing vector fields",
            "year": 2010,
            "firstName": "Jishang Wei",
            "label": "Wei2010A",
            "isKeyPaper": 1.0,
            "citationCount": 34,
            "abstract": "In flow visualization, field lines are often used to convey both global and local structure and movement of the flow. One challenge is to find and classify the representative field lines. Most existing solutions follow an automatic approach that generates field lines characterizing the flow and arranges these lines into a single picture. In our work, we advocate a user-centric approach to exploring 3D vector fields. Our method allows the user to sketch 2D curves for pattern matching in 2D and field lines clustering in 3D. Specifically, a 3D field line whose view-dependent 2D projection is most similar to the user drawing will be identified and utilized to extract all similar 3D field lines. Furthermore, we employ an automatic clustering method to generate field-line templates for the user to locate subfields of interest. This semi-automatic process leverages the user's knowledge about the flow field through intuitive user interaction, resulting in a promising alternative to existing flow visualization solutions. With our sketch-based interface, the user can effectively dissect the flow field and make more structured visualization for analysis or presentation.",
            "topic": 27,
            "cx": 3137.45,
            "cy": -978.53,
            "rx": 62.87,
            "ry": 26.74,
            "text1": "Wei2010A",
            "text2": "34"
        },
        {
            "id": "2077122434",
            "name": "Parallel clustering for visualizing large scientific line data",
            "year": 2011,
            "firstName": "Jishang Wei",
            "label": "Wei2011Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Scientists often need to extract, visualize and analyze lines from vast amounts of data to understand dynamic structures and interactions. The effectiveness of such a visual validation and analysis process mainly relies on a good strategy to categorize and visualize the lines. However, the sheer size of line data produced by state-of-the-art scientific simulations poses great challenges to preparing the data for visualization. In this paper, we present a parallelization design of regression model-based clustering to categorize large line data derived from detailed scientific simulations by leveraging the power of heterogeneous computers. This parallel clustering method employs the Expectation Maximization algorithm to iteratively approximate the optimal data partitioning. First, we use a sorted-balance algorithm to partition and distribute the lines with various lengths among multiple compute nodes. During the following iterative clustering process, regression model parameters are recovered based on the local lines on each individual node, with only a few inter-node message exchanges involved. Meanwhile, the workload of regression model computing is well balanced across the nodes. The experimental results demonstrate that our approach can effectively categorize large line data in a scalable manner to concisely convey dynamic structures and interactions, leading to a visualization that captures salient features and suppresses visual clutter to facilitate scientific exploration of large line data.",
            "topic": 53,
            "cx": 3137.45,
            "cy": -888.79,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Wei2011Par...",
            "text2": "13"
        },
        {
            "id": "2102136719",
            "name": "Explorable images for visualizing volume data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010Explorable",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "We present a technique which automatically converts a small number of single-view volume rendered images of the same 3D data set into a compact representation of that data set. This representation is a multi-layered image, or an explorable image, which enables interactive exploration of volume data in transfer function space without accessing the original data. We achieve this by automatically extracting layers depicted in composited images. The layers can then be recombined in different ways to simulate opacity changes and recoloring of individual features. Our results demonstrate that explorable images are especially useful when the volume data is too large for interactive exploration, takes too long to render due to the underlying mesh structure or desired shading effect, or if the original volume data is not available. Explorable images can offer real-time image-based interaction as a preview mechanism for remote visualization or visualization of large volume data on low-end hardware, within a mobile device, or a Web browser.",
            "topic": 7,
            "cx": 2240.45,
            "cy": -978.53,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "22"
        },
        {
            "id": "2151882909",
            "name": "Visualization by Proxy A Novel Framework for Deferred Interaction with Volume Data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 42,
            "abstract": "Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.",
            "topic": 7,
            "cx": 2416.45,
            "cy": -978.53,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "42"
        },
        {
            "id": "1996388339",
            "name": "A preview and exploratory technique for large-scale scientific simulations",
            "year": 2011,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2011A",
            "isKeyPaper": 1.0,
            "citationCount": 18,
            "abstract": "Successful in-situ and remote visualization solutions must have minimal storage requirements and account for only a small percentage of supercomputing time. One solution that meets these requirements is to store a compact intermediate representation of the data, instead of a 3D volume itself. Recent work explores the use of attenuation functions as a data representation that summarizes the distribution of attenuation along the rays. This representation goes beyond conventional static images and allows users to dynamically explore their data, for example, to change color and opacity parameters, without accessing the original 3D data. The computation and storage costs of this method may still be prohibitively expensive for large and time-varying data sets, thus limiting its applicability in the real-world scenarios. In this paper, we present an efficient algorithm for computing attenuation functions in parallel. We exploit the fact that the distribution of attenuation can be constructed recursively from a hierarchy of blocks or intervals of the data, which is a highly parallelizeable process. We have developed a library of routines that can be used in a distance visualization scenario or can be called directly from a simulation code to generate explorable images in-situ. Through a number of examples, we demonstrate the application of this work to large-scale scientific simulations in a real-world parallel environment with thousands of processors. We also explore various compression methods for reducing the size of the RAF. Finally, we present a method for computing an alternative RAF representation, which more closely encodes the actual distribution of samples along a ray, using kernel density estimation.",
            "topic": 47,
            "cx": 2178.45,
            "cy": -888.79,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "18"
        },
        {
            "id": "2020814412",
            "name": "Visual Analysis of Particle Behaviors to Understand Combustion Simulations",
            "year": 2012,
            "firstName": "Jishang Wei",
            "label": "Wei2012Visual",
            "isKeyPaper": 1.0,
            "citationCount": 11,
            "abstract": "Simulations of turbulent flames have used particles to capture the dynamic behavior of combustion in next-generation engines. Each particle includes a history of its movement positions and changing thermochemical states. Analyzing such a set of many millions of particles helps scientists understand turbulence. A dual-space method enables effective visual analysis of both the spatial movement and attribute evolution of particles. A cluster-label-classify strategy categorizes particles' attribute evolution curves. Intuitive tools integrate users' domain knowledge to steer the classification. The dual-space method has been used to analyze particle data in combustion simulations and can be applied to other scientific simulations involving particle-data analysis. This video shows an expository movie that combustion scientists have used when discussing their simulation results with colleagues. This simulation employs visual analysis in both the physical space and phase space, with categorization driven by supervised learning.",
            "topic": 75,
            "cx": 3137.45,
            "cy": -799.05,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Wei2012Vis...",
            "text2": "11"
        },
        {
            "id": "2007142861",
            "name": "Fast global illumination for interactive volume visualization",
            "year": 2013,
            "firstName": "Yubo Zhang",
            "label": "Zhang2013Fast",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "High quality global illumination can enhance the visual perception of depth cue and local thickness of volumetric data but it is seldom used in scientific visualization because of its high computational cost. This paper presents a novel grid-based illumination technique which is specially designed and optimized for volume visualization purpose. It supports common light sources and dynamic transfer function editing. Our method models light propagation, including both absorption and scattering, in a volume using a convection-diffusion equation that can be solved numerically. The main advantage of such technique is that the light modeling and simulation can be separated, where we can use a unified partial-differential equation to model various illumination effects, and adopt highly-parallelized grid-based numerical schemes to solve it. Results show that our method can achieve high quality volume illumination with dynamic color and opacity mapping and various light sources in real-time. The added illumination effects can greatly enhance the visual perception of spatial structures of volume data.",
            "topic": 7,
            "cx": 3302.45,
            "cy": -709.31,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Zhang2013F...",
            "text2": "20"
        },
        {
            "id": "2091956487",
            "name": "Using global illumination in volume visualization of rheumatoid arthritis CT data",
            "year": 2014,
            "firstName": "Lin Zheng",
            "label": "Zheng2014Using",
            "isKeyPaper": 1.0,
            "citationCount": 8,
            "abstract": "Proper lighting in rendering is essential for visualizing 3D objects, but most visualization software tools still employ simple lighting models. The advent of hardware-accelerated advanced lighting suggests that volume visualization can be truly usable for clinical work. Researchers studied how volume rendering incorporating global illumination impacted perception of bone surface features captured by x-ray computed-tomography scanners for clinical monitoring of rheumatoid arthritis patients. The results, evaluated by clinical researchers familiar with the disease and medical-image interpretation, indicate that interactive visualization with global illumination helped the researchers derive more accurate interpretations of the image data. With clinical needs and the recent advancement of volume visualization technology, this study is timely and points the way for further research.",
            "topic": 7,
            "cx": 3223.45,
            "cy": -619.57,
            "rx": 86.03,
            "ry": 26.74,
            "text1": "Zheng2014U...",
            "text2": "8"
        },
        {
            "id": "1601538659",
            "name": "Advanced lighting for unstructured-grid data visualization",
            "year": 2015,
            "firstName": "Min Shih",
            "label": "Shih2015Advanced",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "The benefits of using advanced illumination models in volume visualization have been demonstrated by many researchers. Interactive volume rendering incorporated with advanced lighting has been achieved with GPU acceleration for regular-grid volume data, making volume visualization even more appealing as a tool for 3D data exploration. This paper presents an interactive illumination strategy, which is specially designed and optimized for volume visualization of unstructured-grid data. The basis of the design is a partial differential equation based illumination model to simulate the light propagation, absorption, and scattering within the volumetric medium. In particular, a two-level scheme is introduced to overcome the challenges presented by unstructured grids. Test results show that the added illumination effects such as global shadowing and multiple scattering not only lead to more visually pleasing visualization, but also greatly enhance the perception of the depth information and complex spatial relationships for features of interest in the volume data. This volume visualization enhancement is introduced at a time when unstructured grids are becoming increasingly popular for a variety of scientific simulation applications.",
            "topic": 7,
            "cx": 3337.45,
            "cy": -529.83,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Shih2015Ad...",
            "text2": "1"
        },
        {
            "id": "2041380214",
            "name": "A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation",
            "year": 2013,
            "firstName": "Wei Hsien Hsu",
            "label": "Hsien2013A",
            "isKeyPaper": 1.0,
            "citationCount": 9,
            "abstract": "We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.",
            "topic": 7,
            "cx": 3091.45,
            "cy": -709.31,
            "rx": 73.58,
            "ry": 26.74,
            "text1": "Hsien2013A",
            "text2": "9"
        },
        {
            "id": "2187671748",
            "name": "Scalable visualization of discrete velocity decompositions using spatially organized histograms",
            "year": 2015,
            "firstName": "Tyson Neuroth",
            "label": "Neuroth2015Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "Visualizing the velocity decomposition of a group of objects has applications to many studied data types, such as Lagrangian-based flow data or geospatial movement data. Traditional visualization techniques are often subject to a trade-off between visual clutter and loss of detail, especially in a large scale setting. The use of 2D velocity histograms can alleviate these issues. While they have been used throughout domain specific areas on a basic level, there has been very little work in the visualization community on leveraging them to perform more advanced visualization tasks. In this work, we develop an interactive system which utilizes velocity histograms to visualize the velocity decomposition of a group of objects. In addition, we extend our tool to utilize two schemes for histogram generation: an on-the-fly sampling scheme as well as an in situ scheme to maintain interactivity in extreme scale applications.",
            "topic": 75,
            "cx": 3520.45,
            "cy": -529.83,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Neuroth201...",
            "text2": "6"
        },
        {
            "id": "2594098541",
            "name": "In situ generated probability distribution functions for interactive post hoc visualization and analysis",
            "year": 2016,
            "firstName": "Yucong Chris Ye",
            "label": "Chris2016In",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "The growing power and capacity of supercomputers enable scientific simulations at extreme scale, leading to not only more accurate modeling and greater predictive ability but also massive quantities of data to analyze. New approaches to data analysis and visualization are this needed to support interactive exploration through selective data access for gaining insights into terabytes and petabytes of data. In this paper, we present an in situ data processing method for both generating probability distribution functions (PDFs) from field data and reorganizing particle data using a single spatial organization scheme. This coupling between PDFs and particles allows for the interactive post hoc exploration of both data types simultaneously. Scientists can explore trends in large-scale data through the PDFs and subsequently extract desired particle subsets for further analysis. We evaluate the usability of our in situ method using a petascale combustion simulation and demonstrate the increases in task efficiency and accuracy that the resulting workflow provides to scientists.",
            "topic": 47,
            "cx": 3609.45,
            "cy": -440.09,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Chris2016I...",
            "text2": "7"
        },
        {
            "id": "2182470571",
            "name": "In situ depth maps based feature extraction and tracking",
            "year": 2015,
            "firstName": "Yucong Chris Ye",
            "label": "Chris2015In",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Parallel numerical simulation is a powerful tool used by scientists to study complex problems. It has been a common practice to save the simulation output to disk and then conduct post-hoc in-depth analyses of the saved data. System I/O capabilities have not kept pace as simulations have scaled up over time, so a common approach has been to output only subsets of the data to reduce I/O. However, as we are entering the era of peta- and exa-scale computing, this sub-sampling approach is no longer acceptable because too much valuable information is lost. In situ visualization has been shown a promising approach to the data problem at extreme-scale. We present a novel in situ solution using depth maps to enable post-hoc image-based visualization and feature extraction and tracking. An interactive interface is provided to allow for fine-tuning the generation of depth maps during the course of a simulation run to better capture the features of interest. We use several applications including one actual simulation run on a Cray XE6 supercomputer to demonstrate the effectiveness of our approach.",
            "topic": 47,
            "cx": 3698.45,
            "cy": -529.83,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Chris2015I...",
            "text2": "3"
        },
        {
            "id": "2558750989",
            "name": "Privacy preserving event sequence data visualization using a Sankey diagram-like representation",
            "year": 2016,
            "firstName": "Jia Kai Chou",
            "label": "Kai2016Privacy",
            "isKeyPaper": 1.0,
            "citationCount": 10,
            "abstract": "Given the growing rates and richness of data being collected nowadays, it is non-trivial for data owners to determine a single best publishing granularity that presents the most value of the data while preserving its privacy. There have been extensive studies on privacy preserving algorithms in the data mining community, but relatively few have been done to provide a supervised control over the anonymization process. We present the design and evaluation of a visual interface that assists users to employ commonly used data anonymization techniques for making privacy preserving visualizations of the data. We focus on event sequence data due to its vulnerability to privacy concerns. Our visual interface is designed for data owners to examine potential privacy issues, obfuscate information as suggested by the algorithm, and fine-tune the results per their requests. Case studies using multiple datasets under different scenarios demonstrate the effectiveness of our design. These studies show that using visualization as an interface can help identify potential privacy issues, reveal underlying anonymization processes, and allow users to balance between data utility and privacy.",
            "topic": 15,
            "cx": 3783.45,
            "cy": -440.09,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2016Pri...",
            "text2": "10"
        },
        {
            "id": "2754406527",
            "name": "Privacy preserving visualization for social network data with ontology information",
            "year": 2017,
            "firstName": "Jia Kai Chou",
            "label": "Kai2017Privacy",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "Analyzing social network data helps sociologists understand the behaviors of individuals and groups as well as the relationships between them. With additional ontology information, the semantics behind the network structure can be further explored. Unfortunately, creating network visualizations with these datasets for presentation can inadvertently expose the private and sensitive information of individuals that reside in the data. To deal with this problem, we generalize conventional data anonymization models (originally designed for relational data) and formally apply them in the context of privacy preserving ontological network visualization. We use these models to identify the privacy leaks that exist in a visualization, provide graph modification actions that remove and/or perceptually minimize the effect of the identified leaks, and discuss strategies for what types of privacy actions to choose depending on the context of the leaks. We implement an ontological visualization interface with associated privacy preserving operations, and demonstrate with two case studies using real-world datasets to show that our approach can identify and solve potential privacy issues while balancing overall graph readability and utility.",
            "topic": 58,
            "cx": 3783.45,
            "cy": -350.35,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2017Pri...",
            "text2": "7"
        },
        {
            "id": "2944385809",
            "name": "An Empirical Study on Perceptually Masking Privacy in Graph Visualizations",
            "year": 2018,
            "firstName": "Jia Kai Chou",
            "label": "Kai2018An",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "Researchers such as sociologists create visualizations of multivariate node-link diagrams to present findings about the relationships in communities. Unfortunately, such visualizations can inadvertently expose the ostensibly private identities of the persons that make up the dataset. By purposely violating graph readability metrics for a small region of the graph, we conjecture that local, exposed privacy leaks may be perceptually masked from easy recognition. In particular, we consider three commonly known metricsxe2x80x94edge crossing, node clustering, and node-edge overlappingxe2x80x94as a strategy to hide leaks. We evaluate the effectiveness of violating these metrics by conducting a user study that measures subject performance at visually searching for and identifying a privacy leak. Results show that when more masking operations are applied, participants needed more time to locate the privacy leak, though exhaustive, brute force search can eventually find it. We suggest future directions on how perceptual masking can be a viable strategy, primarily where modifying the underlying network structure is unfeasible.",
            "topic": 10,
            "cx": 3783.45,
            "cy": -260.61,
            "rx": 67.35,
            "ry": 26.74,
            "text1": "Kai2018An",
            "text2": "1"
        },
        {
            "id": "2751731070",
            "name": "What Would a Graph Look Like in this Layout A Machine Learning Approach to Large Graph Visualization",
            "year": 2018,
            "firstName": "Oh Hyun Kwon",
            "label": "Hyun2018What",
            "isKeyPaper": 1.0,
            "citationCount": 16,
            "abstract": "Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a xe2x80x9cgoodxe2x80x9d layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.",
            "topic": 10,
            "cx": 3959.45,
            "cy": -260.61,
            "rx": 90.52,
            "ry": 26.74,
            "text1": "Hyun2018Wh...",
            "text2": "16"
        },
        {
            "id": "2941265453",
            "name": "A Deep Generative Model for Graph Layout",
            "year": 2020,
            "firstName": "Oh Hyun Kwon",
            "label": "Hyun2020A",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Different layouts can characterize different aspects of the same graph. Finding a xe2x80x9cgoodxe2x80x9d layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.",
            "topic": 10,
            "cx": 3959.45,
            "cy": -98.87,
            "rx": 71.34,
            "ry": 26.74,
            "text1": "Hyun2020A",
            "text2": "3"
        }
    ],
    [
        {
            "source": "1992",
            "target": "1993",
            "d": "M34.45,-2504.56C34.45,-2489.2 34.45,-2466.88 34.45,-2451.51"
        },
        {
            "source": "2160946550",
            "target": "2120835680",
            "d": "M171.45,-2495.57C171.45,-2487.6 171.45,-2478.71 171.45,-2470.22",
            "citation_context": null
        },
        {
            "source": "1993",
            "target": "1994",
            "d": "M34.45,-2415.04C34.45,-2401.91 34.45,-2383.87 34.45,-2370.67"
        },
        {
            "source": "2120835680",
            "target": "2118947032",
            "d": "M171.45,-2406.13C171.45,-2379.68 171.45,-2338.47 171.45,-2308.79",
            "citation_context": "Darmofal and Hairnes [2], Ma and Smith [ 7 ], and Pargendarm [9] use one streamline and vectors normal to the local velocity to form a streamribbon.In [ 7 ], to visualize both flow convection and diffusion, stat,istical dispersion of the fluid element,s about a streamline is computed by using added scalar information about the root mea,n square value for the vector field and it,s Lara.ngian time scale."
        },
        {
            "source": "1994",
            "target": "1995",
            "d": "M34.45,-2334.17C34.45,-2321.04 34.45,-2303 34.45,-2289.8"
        },
        {
            "source": "1995",
            "target": "1996",
            "d": "M34.45,-2253.3C34.45,-2240.17 34.45,-2222.13 34.45,-2208.93"
        },
        {
            "source": "1996",
            "target": "1997",
            "d": "M34.45,-2172.24C34.45,-2161.47 34.45,-2147.68 34.45,-2136.9"
        },
        {
            "source": "1997",
            "target": "1998",
            "d": "M34.45,-2100.24C34.45,-2089.47 34.45,-2075.68 34.45,-2064.9"
        },
        {
            "source": "1998",
            "target": "1999",
            "d": "M34.45,-2028.43C34.45,-2015.3 34.45,-1997.26 34.45,-1984.06"
        },
        {
            "source": "1999",
            "target": "2000",
            "d": "M34.45,-1947.34C34.45,-1931.98 34.45,-1909.66 34.45,-1894.29"
        },
        {
            "source": "2018246367",
            "target": "1982953486",
            "d": "M228.05,-1939.76C217.22,-1929.56 204.61,-1917.65 193.28,-1906.97",
            "citation_context": "The image graph system [12] was designed with visualization data exploration in mind, and thus satisfies the criteria we presented."
        },
        {
            "source": "2018246367",
            "target": "2090746914",
            "d": "M270.06,-1938.82C275.34,-1930.09 281.31,-1920.2 286.91,-1910.93",
            "citation_context": null
        },
        {
            "source": "2092430905",
            "target": "2115314149",
            "d": "M640.21,-1938.71C637.23,-1876.15 629.64,-1716.86 626.2,-1644.49",
            "citation_context": "Ma and Crockett [16] demonstrate a highly efficient, cell-projection volume rendering algorithm using up to 512 T3E processors for rendering 18 millions tetrahedral elements from an aerodynamic flow simulation."
        },
        {
            "source": "2116283033",
            "target": "2115314149",
            "d": "M477.81,-1939C505.58,-1876.25 576.96,-1714.99 608.76,-1643.15",
            "citation_context": "A similar approach is also used for the rendering of AMR data [12]."
        },
        {
            "source": "2000",
            "target": "2001",
            "d": "M34.45,-1857.6C34.45,-1842.24 34.45,-1819.92 34.45,-1804.55"
        },
        {
            "source": "27528377",
            "target": "2039138386",
            "d": "M991.64,-1849.08C995.28,-1840.69 999.37,-1831.24 1003.25,-1822.29",
            "citation_context": "Ma and Shen [11] discuss how nonuniform quantization along with octree and difference encoding can be employed to speed up rendering of timevarying volume data."
        },
        {
            "source": "1982953486",
            "target": "2154046714",
            "d": "M161.45,-1848.61C161.45,-1840.64 161.45,-1831.75 161.45,-1823.26",
            "citation_context": "These issues were addressed by our spreadsheet-like interface described in [16]."
        },
        {
            "source": "2166470747",
            "target": "2039138386",
            "d": "M1126.47,-1852.11C1107.63,-1840.79 1084.71,-1827.01 1064.83,-1815.07",
            "citation_context": "Ma and Camp [10] developed a post-processing parallel visualization strategy based on pipelined rendering."
        },
        {
            "source": "2166470747",
            "target": "2145293470",
            "d": "M1105.65,-1857.49C1095.6,-1854.6 1085.24,-1851.7 1075.45,-1849.06 1011.33,-1831.79 990.76,-1840.84 930.45,-1813.06 882.91,-1791.17 834.92,-1754.71 803.64,-1728.59",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2166470747",
            "target": "2947284622",
            "d": "M1164.45,-1848.74C1164.45,-1818.25 1164.45,-1767.7 1164.45,-1733.5",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [ 18 ]."
        },
        {
            "source": "2166470747",
            "target": "1556372880",
            "d": "M1183.95,-1849.77C1205.11,-1820.98 1237.92,-1771.55 1253.45,-1723.32 1271.82,-1666.26 1274.29,-1596 1273.8,-1554.22",
            "citation_context": "Ma and Camp [ MC00 ] show that by properly grouping processors according to the rendering loads, compressing images before delivering, and completely overlapping uploading each time step of the data, rendering, and delivering the images, interframe delay can be kept to a minimum."
        },
        {
            "source": "2001",
            "target": "2002",
            "d": "M34.45,-1767.86C34.45,-1752.5 34.45,-1730.18 34.45,-1714.81"
        },
        {
            "source": "2039138386",
            "target": "2114283921",
            "d": "M998.2,-1759.81C990.94,-1750.72 982.65,-1740.33 974.95,-1730.67",
            "citation_context": "In addition to the large-data problem which is being addressed by high-performance computing [4, 5, 6, 9], two fundamental visualization problems must be solved."
        },
        {
            "source": "2039138386",
            "target": "2145293470",
            "d": "M964.82,-1766.37C926.16,-1752.8 873.82,-1734.43 832.89,-1720.07",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2039138386",
            "target": "2947284622",
            "d": "M1056.43,-1762.37C1075.27,-1751.05 1098.19,-1737.27 1118.06,-1725.33",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20,  15 ], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2039138386",
            "target": "2103068632",
            "d": "M1027.28,-1759.21C1030.79,-1748.23 1034.65,-1735.25 1037.45,-1723.32 1043.65,-1696.88 1048.55,-1666.56 1051.82,-1643.61",
            "citation_context": "capability of commodity PC graphics cards and the temporal compression technique described in [ 7 ] we achieve interactive texture-based volumetric kinetic visualization.We therefore apply the temporal compression technique described by Lum et al. [ 7 ] to compress these textures by up to a factor of eight."
        },
        {
            "source": "2154046714",
            "target": "2143275883",
            "d": "M161.45,-1758.87C161.45,-1750.9 161.45,-1742.01 161.45,-1733.52",
            "citation_context": "This behavior is not true of Jankun-Kelly and Maxe2x80x99s visualization exploration spreadsheet-like interface [16]."
        },
        {
            "source": "2002",
            "target": "2003",
            "d": "M34.45,-1678.12C34.45,-1662.76 34.45,-1640.44 34.45,-1625.07"
        },
        {
            "source": "2143275883",
            "target": "2114265882",
            "d": "M161.45,-1669.29C161.45,-1634.67 161.45,-1571.74 161.45,-1517.97 161.45,-1517.97 161.45,-1517.97 161.45,-1426.23 161.45,-1377.5 161.45,-1321.25 161.45,-1285.37",
            "citation_context": "work [1] based upon our experience applying them to"
        },
        {
            "source": "2145293470",
            "target": "2064959254",
            "d": "M778.17,-1669.6C781.3,-1661.29 784.82,-1651.93 788.16,-1643.05",
            "citation_context": null
        },
        {
            "source": "2145293470",
            "target": "2115314149",
            "d": "M730.61,-1672.4C712.26,-1661.22 690.05,-1647.68 670.69,-1635.89",
            "citation_context": "To complicate the problem further, it could be desirable to create a single visualization by making use of multiple variables and/or multiple time steps [22]."
        },
        {
            "source": "2146362647",
            "target": "2130218153",
            "d": "M1383.45,-1669.13C1383.45,-1661.16 1383.45,-1652.27 1383.45,-1643.78",
            "citation_context": null
        },
        {
            "source": "2003",
            "target": "2004",
            "d": "M34.45,-1588.38C34.45,-1573.02 34.45,-1550.7 34.45,-1535.33"
        },
        {
            "source": "2115314149",
            "target": "2162126826",
            "d": "M636.82,-1579.86C640.92,-1571.31 645.54,-1561.65 649.9,-1552.55",
            "citation_context": "In our previous work [16], a parallel volume renderer was developed for visualizing 3D unstructured volume data generated from the same, but smaller scale, earthquake simulation [24]."
        },
        {
            "source": "2115314149",
            "target": "2148775223",
            "d": "M613.07,-1579.92C608.6,-1568.97 603.75,-1555.96 600.45,-1543.84 593.29,-1517.64 588.43,-1487.31 585.42,-1464.29",
            "citation_context": "SC|05 November 12-18, 2005, Seattle, Washington, USA (c) 2005 ACM 1-59593-061-2/05/0011 $5.00 Several parallel visualization solutions are available for this large data problem [1, 12, 13,  14 , 28, 29]"
        },
        {
            "source": "2155542779",
            "target": "2095627337",
            "d": "M1538.45,-1579.39C1538.45,-1571.42 1538.45,-1562.53 1538.45,-1554.04",
            "citation_context": null
        },
        {
            "source": "2004",
            "target": "2005",
            "d": "M34.45,-1498.64C34.45,-1483.28 34.45,-1460.96 34.45,-1445.59"
        },
        {
            "source": "2054501662",
            "target": "2127273065",
            "d": "M1698.45,-1490.01C1698.45,-1427.45 1698.45,-1268.16 1698.45,-1195.79",
            "citation_context": "TzengandMa [ 22 ] introduced a cluster-space visual interface for arbitrary dimensional volume data visualization."
        },
        {
            "source": "2170839387",
            "target": "2131385811",
            "d": "M1872.45,-1489.78C1872.45,-1459.29 1872.45,-1408.74 1872.45,-1374.54",
            "citation_context": null
        },
        {
            "source": "2005",
            "target": "2006",
            "d": "M34.45,-1408.9C34.45,-1393.54 34.45,-1371.22 34.45,-1355.85"
        },
        {
            "source": "2006",
            "target": "2007",
            "d": "M34.45,-1319.16C34.45,-1303.8 34.45,-1281.48 34.45,-1266.11"
        },
        {
            "source": "2131385811",
            "target": "2163363303",
            "d": "M1872.45,-1310.3C1872.45,-1279.81 1872.45,-1229.25 1872.45,-1195.06",
            "citation_context": "Vincken et al. [29] and Lum et al. [ 18 ] use pyramid representations to improve volume classio cation.This result is representative of previous multi-scale classio cation methods, such as the one by Lum et al. [ 18 ]."
        },
        {
            "source": "2007",
            "target": "2008",
            "d": "M34.45,-1229.42C34.45,-1214.06 34.45,-1191.74 34.45,-1176.37"
        },
        {
            "source": "2096945381",
            "target": "2169175194",
            "d": "M2415.45,-1220.43C2415.45,-1212.46 2415.45,-1203.57 2415.45,-1195.08",
            "citation_context": "In situ processing is the reduction, transformation, analysis, or viewing of data as it is being computed, using the same architecture as the computation [ 19 ].The Institute has explored in situ processing previously [ 19 ], including a study of in situ visualization for steering of a massively parallel earthquake simulation [20]."
        },
        {
            "source": "2008",
            "target": "2009",
            "d": "M34.45,-1139.68C34.45,-1124.32 34.45,-1102 34.45,-1086.63"
        },
        {
            "source": "2040195604",
            "target": "2099306854",
            "d": "M2594.45,-1130.69C2594.45,-1122.72 2594.45,-1113.83 2594.45,-1105.34",
            "citation_context": "StarGate [17] is a tool that visualizes both the evolution of the software repository and the communication patterns of the developers involved."
        },
        {
            "source": "2136730689",
            "target": "2169175194",
            "d": "M2316.71,-1158.01C2319.21,-1158.01 2321.7,-1158.01 2324.2,-1158.01",
            "citation_context": "However, the expanding size and complexity of data shift the burden onto the I/O system, meaning this cost must be recognized and included in our analyses as an integral component of parallel visualization [5]."
        },
        {
            "source": "2136730689",
            "target": "2144823948",
            "d": "M2237.45,-1130.69C2237.45,-1122.72 2237.45,-1113.83 2237.45,-1105.34",
            "citation_context": "work, where we examine the use of large numbers of tightly connected processor nodes in the context of a parallel ray casting volume rendering algorithm implemented on the IBM Blue Gene/P (BG/P) system at Argonne National Laboratory [2]."
        },
        {
            "source": "2163363303",
            "target": "2011060348",
            "d": "M1858.6,-1131.16C1853.97,-1122.52 1848.73,-1112.74 1843.81,-1103.56",
            "citation_context": "Correa and Ma use size-based transfer functions to classify features based on their size [ 3 ]."
        },
        {
            "source": "2163363303",
            "target": "2029393506",
            "d": "M1885.4,-1131.26C1890.56,-1120.31 1896.26,-1107.29 1900.45,-1095.14 1920.45,-1037.1 1935.67,-967.21 1943.81,-925.75",
            "citation_context": null
        },
        {
            "source": "2009",
            "target": "2010",
            "d": "M34.45,-1049.94C34.45,-1034.58 34.45,-1012.26 34.45,-996.89"
        },
        {
            "source": "2011060348",
            "target": "2046832287",
            "d": "M1823.56,-1041.3C1821.88,-999.2 1824.48,-915.41 1865.45,-861.92 1922.18,-787.84 2024.67,-747.72 2095.99,-727.7",
            "citation_context": null
        },
        {
            "source": "2138396059",
            "target": "2131433745",
            "d": "M2064.45,-1040.95C2064.45,-1032.98 2064.45,-1024.09 2064.45,-1015.6",
            "citation_context": null
        },
        {
            "source": "2138396059",
            "target": "2029393506",
            "d": "M2021.46,-1045.95C2005.08,-1035.8 1987.66,-1022.17 1976.45,-1005.4 1960.7,-981.87 1954.37,-950.22 1951.88,-925.99",
            "citation_context": null
        },
        {
            "source": "2138396059",
            "target": "2046832287",
            "d": "M2118,-1049.25C2128.35,-1046.26 2139.16,-1043.47 2149.45,-1041.4 2227.19,-1025.78 2451.28,-1064.23 2504.45,-1005.4 2604.92,-894.23 2360.94,-781.23 2238.9,-733.67",
            "citation_context": "To this end, we exploit the notion of visibility histograms [22], which summarize the distribution of visibility of structure of interest from a given viewpoint."
        },
        {
            "source": "2138422603",
            "target": "1611667971",
            "d": "M2860.46,-1068.27C2862.9,-1068.27 2865.34,-1068.27 2867.78,-1068.27",
            "citation_context": "Muelder and Ma [12] introduced a prediction-correction method to make the best guess of the feature region in the subsequent time step to achieve a better tracking result."
        },
        {
            "source": "2138422603",
            "target": "1457609601",
            "d": "M2777.45,-1041.31C2777.45,-978.75 2777.45,-819.46 2777.45,-747.09",
            "citation_context": null
        },
        {
            "source": "2010",
            "target": "2011",
            "d": "M34.45,-960.2C34.45,-944.84 34.45,-922.52 34.45,-907.15"
        },
        {
            "source": "2025518624",
            "target": "2023029656",
            "d": "M2940.7,-951.72C2929.14,-921.1 2909.8,-869.87 2896.84,-835.53",
            "citation_context": "AniViz [7] realizes this concept by allowing the user of a visualization system to do exactly that, and to present the story as an animation."
        },
        {
            "source": "2025518624",
            "target": "2113470734",
            "d": "M2953.04,-951.63C2958.81,-899.47 2974.91,-778.57 3008.45,-682.44 3011.64,-673.3 3015.96,-663.83 3020.4,-655.12",
            "citation_context": null
        },
        {
            "source": "2070002217",
            "target": "2077122434",
            "d": "M3137.45,-951.21C3137.45,-943.24 3137.45,-934.35 3137.45,-925.86",
            "citation_context": null
        },
        {
            "source": "2102136719",
            "target": "2151882909",
            "d": "M2319.85,-978.53C2322.29,-978.53 2324.73,-978.53 2327.18,-978.53",
            "citation_context": "propose a method for changing the color and opacity mappings of volume rendered images, based on alpha estimation of a given set of layers [30]."
        },
        {
            "source": "2102136719",
            "target": "1996388339",
            "d": "M2222.51,-952.15C2216.15,-943.15 2208.89,-932.87 2202.12,-923.3",
            "citation_context": null
        },
        {
            "source": "2131433745",
            "target": "2151882909",
            "d": "M2104.6,-1001.86C2121.55,-1010.43 2141.88,-1019.09 2161.45,-1023.4 2230.03,-1038.49 2250.87,-1038.49 2319.45,-1023.4 2335.65,-1019.83 2352.38,-1013.28 2367.28,-1006.27",
            "citation_context": "In our previous work [31], we propose a similar method."
        },
        {
            "source": "2131433745",
            "target": "1996388339",
            "d": "M2095.6,-953.56C2109.04,-943.21 2124.93,-930.98 2139.17,-920.02",
            "citation_context": null
        },
        {
            "source": "2011",
            "target": "2012",
            "d": "M34.45,-870.46C34.45,-855.1 34.45,-832.78 34.45,-817.41"
        },
        {
            "source": "2077122434",
            "target": "2020814412",
            "d": "M3137.45,-861.47C3137.45,-853.5 3137.45,-844.61 3137.45,-836.12",
            "citation_context": null
        },
        {
            "source": "2012",
            "target": "2013",
            "d": "M34.45,-780.72C34.45,-765.36 34.45,-743.04 34.45,-727.67"
        },
        {
            "source": "2013",
            "target": "2014",
            "d": "M34.45,-690.98C34.45,-675.62 34.45,-653.3 34.45,-637.93"
        },
        {
            "source": "2007142861",
            "target": "2091956487",
            "d": "M3280.02,-683.4C3271.51,-673.96 3261.7,-663.06 3252.66,-653.01",
            "citation_context": null
        },
        {
            "source": "2007142861",
            "target": "1601538659",
            "d": "M3309.75,-682.24C3312.68,-671.25 3315.95,-658.27 3318.45,-646.44 3324.02,-620.03 3328.92,-589.95 3332.35,-567.08",
            "citation_context": "Several techniques to apply visually plausible global illumination effects to volume rendering at interactive speed have been introduced [2, 13, 15, 16, 20, 24, 29]."
        },
        {
            "source": "2041380214",
            "target": "2113470734",
            "d": "M3076.7,-682.93C3071.61,-674.19 3065.83,-664.24 3060.4,-654.9",
            "citation_context": null
        },
        {
            "source": "2014",
            "target": "2015",
            "d": "M34.45,-601.24C34.45,-585.88 34.45,-563.56 34.45,-548.19"
        },
        {
            "source": "2015",
            "target": "2016",
            "d": "M34.45,-511.5C34.45,-496.13 34.45,-473.82 34.45,-458.45"
        },
        {
            "source": "2187671748",
            "target": "2594098541",
            "d": "M3545.71,-503.92C3555.47,-494.3 3566.76,-483.17 3577.1,-472.98",
            "citation_context": null
        },
        {
            "source": "2182470571",
            "target": "2594098541",
            "d": "M3673.18,-503.92C3663.42,-494.3 3652.13,-483.17 3641.79,-472.98",
            "citation_context": null
        },
        {
            "source": "2016",
            "target": "2017",
            "d": "M34.45,-421.76C34.45,-406.39 34.45,-384.08 34.45,-368.71"
        },
        {
            "source": "2558750989",
            "target": "2754406527",
            "d": "M3783.45,-412.77C3783.45,-404.8 3783.45,-395.91 3783.45,-387.42",
            "citation_context": "Examples include applying kanonymity and l-diversity to parallel coordinates [7], investigating privacy issues in event sequence datasets [5], and discussing opportunities and challenges for privacy preserving visualization in the realm of electronic health record data [8]."
        },
        {
            "source": "2017",
            "target": "2018",
            "d": "M34.45,-332.02C34.45,-316.65 34.45,-294.34 34.45,-278.97"
        },
        {
            "source": "2754406527",
            "target": "2944385809",
            "d": "M3783.45,-323.03C3783.45,-315.06 3783.45,-306.17 3783.45,-297.68",
            "citation_context": "As stated by a sociologist, xe2x80x9cintroducing too much noise can take away the validity of our resultsxe2x80x9d [5]."
        },
        {
            "source": "2018",
            "target": "2019",
            "d": "M34.45,-242.5C34.45,-229.37 34.45,-211.33 34.45,-198.13"
        },
        {
            "source": "2751731070",
            "target": "2941265453",
            "d": "M3959.45,-233.59C3959.45,-207.13 3959.45,-165.92 3959.45,-136.24",
            "citation_context": "Recently, several machine learning approaches have been introduced to different tasks in graph visualization, such as previewing large graphs [60], exploring large graphs [11], and evaluating visualizations [38, 54]."
        },
        {
            "source": "2019",
            "target": "2020",
            "d": "M34.45,-161.63C34.45,-148.5 34.45,-130.46 34.45,-117.26"
        },
        {
            "source": "2020",
            "target": "2021",
            "d": "M34.45,-80.76C34.45,-67.63 34.45,-49.59 34.45,-36.39"
        }
    ],
    [
        "34.45,-2451.15 34.45,-2451.15 34.45,-2451.15 34.45,-2451.15",
        "174.95,-2470.16 171.45,-2460.16 167.95,-2470.16 174.95,-2470.16",
        "34.45,-2370.36 34.45,-2370.36 34.45,-2370.36 34.45,-2370.36",
        "174.95,-2308.42 171.45,-2298.42 167.95,-2308.42 174.95,-2308.42",
        "34.45,-2289.49 34.45,-2289.49 34.45,-2289.49 34.45,-2289.49",
        "34.45,-2208.62 34.45,-2208.62 34.45,-2208.62 34.45,-2208.62",
        "34.45,-2136.65 34.45,-2136.65 34.45,-2136.65 34.45,-2136.65",
        "34.45,-2064.65 34.45,-2064.65 34.45,-2064.65 34.45,-2064.65",
        "34.45,-1983.75 34.45,-1983.75 34.45,-1983.75 34.45,-1983.75",
        "34.45,-1893.93 34.45,-1893.93 34.45,-1893.93 34.45,-1893.93",
        "195.36,-1904.12 185.68,-1899.8 190.56,-1909.21 195.36,-1904.12",
        "289.95,-1912.66 292.13,-1902.3 283.96,-1909.05 289.95,-1912.66",
        "629.67,-1643.88 625.7,-1634.06 622.68,-1644.21 629.67,-1643.88",
        "612.13,-1644.19 612.97,-1633.63 605.73,-1641.36 612.13,-1644.19",
        "34.45,-1804.19 34.45,-1804.19 34.45,-1804.19 34.45,-1804.19",
        "1006.57,-1823.43 1007.33,-1812.86 1000.15,-1820.64 1006.57,-1823.43",
        "164.95,-1823.2 161.45,-1813.2 157.95,-1823.2 164.95,-1823.2",
        "1066.61,-1812.05 1056.24,-1809.9 1063,-1818.05 1066.61,-1812.05",
        "805.57,-1725.63 795.67,-1721.85 801.05,-1730.98 805.57,-1725.63",
        "1167.95,-1733.46 1164.45,-1723.46 1160.95,-1733.46 1167.95,-1733.46",
        "1277.29,-1553.91 1273.61,-1543.98 1270.29,-1554.04 1277.29,-1553.91",
        "34.45,-1714.45 34.45,-1714.45 34.45,-1714.45 34.45,-1714.45",
        "977.62,-1728.41 968.65,-1722.77 972.15,-1732.77 977.62,-1728.41",
        "833.88,-1716.71 823.29,-1716.7 831.56,-1723.31 833.88,-1716.71",
        "1119.89,-1728.31 1126.66,-1720.16 1116.28,-1722.31 1119.89,-1728.31",
        "1055.3,-1644.01 1053.21,-1633.62 1048.37,-1643.05 1055.3,-1644.01",
        "164.95,-1733.46 161.45,-1723.46 157.95,-1733.46 164.95,-1733.46",
        "34.45,-1624.71 34.45,-1624.71 34.45,-1624.71 34.45,-1624.71",
        "164.95,-1284.91 161.45,-1274.91 157.95,-1284.91 164.95,-1284.91",
        "791.44,-1644.27 791.68,-1633.68 784.88,-1641.81 791.44,-1644.27",
        "672.39,-1632.83 662.03,-1630.61 668.75,-1638.8 672.39,-1632.83",
        "1386.95,-1643.72 1383.45,-1633.72 1379.95,-1643.72 1386.95,-1643.72",
        "34.45,-1534.97 34.45,-1534.97 34.45,-1534.97 34.45,-1534.97",
        "653.15,-1553.87 654.31,-1543.34 646.83,-1550.84 653.15,-1553.87",
        "588.88,-1463.76 584.16,-1454.27 581.94,-1464.63 588.88,-1463.76",
        "1541.95,-1553.98 1538.45,-1543.98 1534.95,-1553.98 1541.95,-1553.98",
        "34.45,-1445.23 34.45,-1445.23 34.45,-1445.23 34.45,-1445.23",
        "1701.95,-1195.36 1698.45,-1185.36 1694.95,-1195.36 1701.95,-1195.36",
        "1875.95,-1374.5 1872.45,-1364.5 1868.95,-1374.5 1875.95,-1374.5",
        "34.45,-1355.49 34.45,-1355.49 34.45,-1355.49 34.45,-1355.49",
        "34.45,-1265.75 34.45,-1265.75 34.45,-1265.75 34.45,-1265.75",
        "1875.95,-1195.02 1872.45,-1185.02 1868.95,-1195.02 1875.95,-1195.02",
        "34.45,-1176.01 34.45,-1176.01 34.45,-1176.01 34.45,-1176.01",
        "2418.95,-1195.02 2415.45,-1185.02 2411.95,-1195.02 2418.95,-1195.02",
        "34.45,-1086.27 34.45,-1086.27 34.45,-1086.27 34.45,-1086.27",
        "2597.95,-1105.28 2594.45,-1095.28 2590.95,-1105.28 2597.95,-1105.28",
        "2324.45,-1161.51 2334.45,-1158.01 2324.45,-1154.51 2324.45,-1161.51",
        "2240.95,-1105.28 2237.45,-1095.28 2233.95,-1105.28 2240.95,-1105.28",
        "1846.84,-1101.8 1839.03,-1094.63 1840.67,-1105.1 1846.84,-1101.8",
        "1947.26,-926.33 1945.72,-915.85 1940.39,-925 1947.26,-926.33",
        "34.45,-996.53 34.45,-996.53 34.45,-996.53 34.45,-996.53",
        "2097.12,-731.02 2105.84,-725.01 2095.27,-724.27 2097.12,-731.02",
        "2067.95,-1015.54 2064.45,-1005.54 2060.95,-1015.54 2067.95,-1015.54",
        "1955.35,-925.44 1951.01,-915.77 1948.38,-926.03 1955.35,-925.44",
        "2239.85,-730.29 2229.26,-729.95 2237.33,-736.82 2239.85,-730.29",
        "2867.82,-1071.77 2877.82,-1068.27 2867.82,-1064.77 2867.82,-1071.77",
        "2780.95,-746.66 2777.45,-736.66 2773.95,-746.66 2780.95,-746.66",
        "34.45,-906.79 34.45,-906.79 34.45,-906.79 34.45,-906.79",
        "2900.01,-834.01 2893.2,-825.89 2893.46,-836.48 2900.01,-834.01",
        "3023.62,-656.51 3025.21,-646.03 3017.44,-653.23 3023.62,-656.51",
        "3140.95,-925.79 3137.45,-915.79 3133.95,-925.8 3140.95,-925.79",
        "2327.21,-982.03 2337.21,-978.53 2327.21,-975.03 2327.21,-982.03",
        "2204.97,-921.26 2196.34,-915.11 2199.25,-925.3 2204.97,-921.26",
        "2368.85,-1009.4 2376.3,-1001.86 2365.77,-1003.11 2368.85,-1009.4",
        "2141.54,-922.61 2147.33,-913.74 2137.27,-917.06 2141.54,-922.61",
        "34.45,-817.05 34.45,-817.05 34.45,-817.05 34.45,-817.05",
        "3140.95,-836.05 3137.45,-826.05 3133.95,-836.05 3140.95,-836.05",
        "34.45,-727.31 34.45,-727.31 34.45,-727.31 34.45,-727.31",
        "34.45,-637.57 34.45,-637.57 34.45,-637.57 34.45,-637.57",
        "3255.22,-650.63 3245.93,-645.54 3250.02,-655.31 3255.22,-650.63",
        "3335.82,-567.53 3333.82,-557.13 3328.89,-566.51 3335.82,-567.53",
        "3063.39,-653.08 3055.34,-646.2 3057.34,-656.6 3063.39,-653.08",
        "34.45,-547.83 34.45,-547.83 34.45,-547.83 34.45,-547.83",
        "34.45,-458.09 34.45,-458.09 34.45,-458.09 34.45,-458.09",
        "3579.76,-475.27 3584.43,-465.76 3574.85,-470.29 3579.76,-475.27",
        "3644.05,-470.29 3634.47,-465.76 3639.13,-475.27 3644.05,-470.29",
        "34.45,-368.35 34.45,-368.35 34.45,-368.35 34.45,-368.35",
        "3786.95,-387.35 3783.45,-377.35 3779.95,-387.35 3786.95,-387.35",
        "34.45,-278.61 34.45,-278.61 34.45,-278.61 34.45,-278.61",
        "3786.95,-297.61 3783.45,-287.61 3779.95,-297.61 3786.95,-297.61",
        "34.45,-197.82 34.45,-197.82 34.45,-197.82 34.45,-197.82",
        "3962.95,-135.88 3959.45,-125.88 3955.95,-135.88 3962.95,-135.88",
        "34.45,-116.95 34.45,-116.95 34.45,-116.95 34.45,-116.95",
        "34.45,-36.08 34.45,-36.08 34.45,-36.08 34.45,-36.08"
    ]
]