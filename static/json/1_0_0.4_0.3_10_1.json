[
    [
        "0.00 0.00 5425.96 2700.72",
        "scale(1 1) rotate(0) translate(4 2696.72)"
    ],
    [
        {
            "id": "1991",
            "cx": 34.45,
            "cy": -2665.85,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1991"
        },
        {
            "id": "1992",
            "cx": 34.45,
            "cy": -2576.11,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1992"
        },
        {
            "id": "1993",
            "cx": 34.45,
            "cy": -2486.37,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1993"
        },
        {
            "id": "1994",
            "cx": 34.45,
            "cy": -2405.5,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1994"
        },
        {
            "id": "1995",
            "cx": 34.45,
            "cy": -2324.63,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1995"
        },
        {
            "id": "1996",
            "cx": 34.45,
            "cy": -2234.89,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1996"
        },
        {
            "id": "1997",
            "cx": 34.45,
            "cy": -2145.15,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1997"
        },
        {
            "id": "1998",
            "cx": 34.45,
            "cy": -2064.28,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1998"
        },
        {
            "id": "1999",
            "cx": 34.45,
            "cy": -1983.41,
            "rx": 34.39,
            "ry": 18.0,
            "text": "1999"
        },
        {
            "id": "2000",
            "cx": 34.45,
            "cy": -1893.67,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2000"
        },
        {
            "id": "2001",
            "cx": 34.45,
            "cy": -1803.93,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2001"
        },
        {
            "id": "2002",
            "cx": 34.45,
            "cy": -1714.19,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2002"
        },
        {
            "id": "2003",
            "cx": 34.45,
            "cy": -1624.45,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2003"
        },
        {
            "id": "2004",
            "cx": 34.45,
            "cy": -1534.71,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2004"
        },
        {
            "id": "2005",
            "cx": 34.45,
            "cy": -1444.97,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2005"
        },
        {
            "id": "2006",
            "cx": 34.45,
            "cy": -1355.23,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2006"
        },
        {
            "id": "2007",
            "cx": 34.45,
            "cy": -1265.49,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2007"
        },
        {
            "id": "2008",
            "cx": 34.45,
            "cy": -1175.75,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2008"
        },
        {
            "id": "2009",
            "cx": 34.45,
            "cy": -1086.01,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2009"
        },
        {
            "id": "2010",
            "cx": 34.45,
            "cy": -996.27,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2010"
        },
        {
            "id": "2011",
            "cx": 34.45,
            "cy": -906.53,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2011"
        },
        {
            "id": "2012",
            "cx": 34.45,
            "cy": -816.79,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2012"
        },
        {
            "id": "2013",
            "cx": 34.45,
            "cy": -727.05,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2013"
        },
        {
            "id": "2014",
            "cx": 34.45,
            "cy": -637.31,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2014"
        },
        {
            "id": "2015",
            "cx": 34.45,
            "cy": -547.57,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2015"
        },
        {
            "id": "2016",
            "cx": 34.45,
            "cy": -457.83,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2016"
        },
        {
            "id": "2017",
            "cx": 34.45,
            "cy": -368.09,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2017"
        },
        {
            "id": "2018",
            "cx": 34.45,
            "cy": -278.35,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2018"
        },
        {
            "id": "2019",
            "cx": 34.45,
            "cy": -188.61,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2019"
        },
        {
            "id": "2020",
            "cx": 34.45,
            "cy": -98.87,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2020"
        },
        {
            "id": "2021",
            "cx": 34.45,
            "cy": -18.0,
            "rx": 34.39,
            "ry": 18.0,
            "text": "2021"
        }
    ],
    [
        {
            "id": "33641593",
            "name": "A Distributed Solution and Visualization for 3D Flow Simulation",
            "year": 1991,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1991A",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "",
            "topic": 43,
            "cx": 358.45,
            "cy": -2665.85,
            "rx": 60.21,
            "ry": 26.74,
            "text1": "Liu1991A",
            "text2": "1"
        },
        {
            "id": "2160946550",
            "name": "Virtual Smoke an interactive 3D flow visualization technique",
            "year": 1992,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1992Virtual",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "This paper introduces a new technique for computer visualization of simultaneous three-dimensional vector and scalar fields such as velocity and temperature in reacting fluid flow fields. The technique, which we call Virtual Smoke, simulates the use of colored smoke for experimental gaseous fluid flow visualization. However, it is noninvasive and can animate, in particular, the dynamic behaviors of steady-state or instantaneous flow fields obtained from numerical simulations. Virtual Smoke is based on Volume Seeds and Volume Seedlings, which are direct volume visualization methods previously developed for highly interactive scalar volume data exploration. We use data from combustion simulations to demonstrate the effectiveness of Virtual Smoke.",
            "topic": 12,
            "cx": 358.45,
            "cy": -2576.11,
            "rx": 76.24,
            "ry": 26.74,
            "text1": "Liu1992Vir...",
            "text2": "28"
        },
        {
            "id": "2138311740",
            "name": "Parallel volume visualization on workstations",
            "year": 1993,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1993Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 17,
            "abstract": "Abstract This paper discusses the use of general-purpose graphics workstations for interactive high-resolution volume visualization. We survey previous research results in parallel volume rendering as well as commercial products that take advantage of parallel processing to make volume rendering a practical visualization method. Our focus is on developing distributed computation methods that can distribute the memory and computational demands of volume visualization across a network of general purpose workstations. We describe three distributed computation strategies based on ray-casting volume rendering that can be implemented on either shared-memory multiprocessor workstations or on a network of ordinary workstations. Multiple views of real-time feature extraction give tremendous insight to the volume data. Multiple variable visualization helps scientists to capture the interaction between important variables in a simulation. Divide-and-conquer rendering allows interactive high-resolution volume visualization of large data sets on a network of midrange workstations, even when the data set is too large for available memory on any single workstation. Several examples in medical imaging and computational fluid dynamics are shown illustrating the practicality of these methods.",
            "topic": 7,
            "cx": 270.45,
            "cy": -2486.37,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu1993Par...",
            "text2": "17"
        },
        {
            "id": "2120835680",
            "name": "Cloud tracing in convection-diffusion systems",
            "year": 1993,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1993Cloud",
            "isKeyPaper": 1.0,
            "citationCount": 11,
            "abstract": "The paper describes a highly interactive method for computer visualization of simultaneous three-dimensional vector and scalar flow fields in convection-diffusion systems. This method allows a computational fluid dynamics user to visualize the basic physical process of dispersion and mixing rather than just the vector and scalar values computed by the simulation. It is based on transforming the vector field from a traditionally Eulerian reference frame into a Lagrangian reference frame. Fluid elements are traced through the vector field for the mean path as well as the statistical dispersion of the fluid elements about the mean position by using added scalar information about the root mean square value of the vector field and its Lagrangian time scale. In this way, clouds of fluid elements are traced not just mean paths. We have used this method to visualize the simulation of an industrial incinerator to help identify mechanisms for poor mixing. >",
            "topic": 12,
            "cx": 446.45,
            "cy": -2486.37,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Liu1993Clo...",
            "text2": "11"
        },
        {
            "id": "2118947032",
            "name": "Fast Algorithms for Visualizing Fluid Motion in Steady Flow on Unstructured Grids",
            "year": 1995,
            "firstName": "Shyh Kuang Ueng",
            "label": "Kuang1995Fast",
            "isKeyPaper": 1.0,
            "citationCount": 16,
            "abstract": "The plotting of streamlines is an effective way of visualizing fluid motion in steady flows. Additional information about the flowfield, such as local rotation and expansion, can be shown by drawing in the form of a ribbon or tube. In this paper, we present efficient algorithms for the construction of streamlines, streamribbons and streamtubes on unstructured grids. A specialized version of the Runge-Kutta method has been developed to speed up the integration of particle pathes. We have also derived close-form solutions for calculating angular rotation rate and radius to construct streamribbons and streamtubes, respectively. According to our analysis and test results, these formulations are two to four times better in performance than previous numerical methods. As a large number of traces are calculated, the improved performance could be significant.",
            "topic": 12,
            "cx": 446.45,
            "cy": -2324.63,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Kuang1995F...",
            "text2": "16"
        },
        {
            "id": "2040639571",
            "name": "Efficient streamline streamribbon and streamtube constructions on unstructured grids",
            "year": 1996,
            "firstName": "Shyh Kuang Ueng",
            "label": "Kuang1996Efficient",
            "isKeyPaper": 1.0,
            "citationCount": 54,
            "abstract": "Streamline construction is one of the most fundamental techniques for visualizing steady flow fields. Streamribbons and streamtubes are extensions for visualizing the rotation and the expansion of the flow. The paper presents efficient algorithms for constructing streamlines, streamribbons, and streamtubes on unstructured grids. A specialized Runge-Kutta method is developed to speed up the tracing of streamlines. Explicit solutions are derived for calculating the angular rotation rates of streamribbons and the radii of streamtubes. In order to simplify mathematical formulations and reduce computational costs, all calculations are carried out in the canonical coordinate system instead of the physical coordinate system. The resulting speed up in overall performance helps explore large flow fields.",
            "topic": 27,
            "cx": 389.45,
            "cy": -2234.89,
            "rx": 86.03,
            "ry": 26.74,
            "text1": "Kuang1996E...",
            "text2": "54"
        },
        {
            "id": "2138516914",
            "name": "An Illustrative Visualization Framework for 3D Vector Fields",
            "year": 2011,
            "firstName": "Cheng Kai Chen",
            "label": "Kai2011An",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "Most 3D vector field visualization techniques suffer from the problem of visual clutter, and it remains a challenging task to effectively convey both directional and structural information of 3D vector fields. In this paper, we present a novel visualization framework that combines the advantages of clustering methods and illustrative rendering techniques to generate a concise and informative depiction of complex flow structures. Given a 3D vector field, we first generate a number of streamlines covering the important regions based on an entropy measurement. Then we decompose the streamlines into different groups based on a categorization of vector information, wherein the streamline pattern in each group is ensured to be coherent or nearly coherent. For each group, we select a set of representative streamlines and render them in an illustrative fashion to enhance depth cues and succinctly show local flow characteristics. The results demonstrate that our approach can generate a visualization that is relatively free of visual clutter while facilitating perception of salient information of complex vector fields.",
            "topic": 27,
            "cx": 304.45,
            "cy": -906.53,
            "rx": 67.35,
            "ry": 26.74,
            "text1": "Kai2011An",
            "text2": "20"
        },
        {
            "id": "1567533377",
            "name": "Runtime volume visualization for parallel CFD",
            "year": 1996,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1996Runtime",
            "isKeyPaper": 1.0,
            "citationCount": 18,
            "abstract": "Publisher Summary This chapter describes the design of a parallel volume rendering (PVR) library which renders in-place distributed data on a rectilinear grid. There are special considerations for such design and implementation. It focuses on the PVR algorithm, and provides a thorough discussion on the library design of a parallel polygonrenderer. The chapter performs tests for runtime visualization of a three-dimensional Navier-Stokes solver, on the Intel Paragon XP/S using from 8 to 216 processors. Interactive visual responses reflecting simulation states and the physical phenomena modeled, allow better control of the simulation, and can offer additional insights into the physics behind the model. Performance studies show that the parallel rendering process is scalable with the size of the simulation as well as with the parallel computer. The chapter mentions that although the current implementation only handles data on a rectilinear grid, the design principles of the library can be generalized to handle unstructured or curvilinear grids as well.",
            "topic": 19,
            "cx": 2179.45,
            "cy": -2234.89,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Liu1996Run...",
            "text2": "18"
        },
        {
            "id": "2166470747",
            "name": "High performance visualization of time-varying volume data over a wide-area network status",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000High",
            "isKeyPaper": 1.0,
            "citationCount": 92,
            "abstract": "This paper presents an end-to-end, low-cost solution for visualizing time-varying volume data rendered on a parallel computer located at a remote site. Pipelining and careful grouping of processors are used to hide I/O time and to maximize processors utilization. Compression is used to significantly cut down the cost of transferring output images from the parallel computer to a display device through a widearea network. This complete rendering pipeline makes possible highly efficient rendering and remote viewing of high resolution time-varying data sets in the absence of high-speed network and parallel I/O support. To study the performance of this rendering pipeline and to demonstrate high-performance remote visualization, tests were conducted on a PC cluster in Japan as well as an SGI Origin 2000 operated at the NASA Ames Research Center with the display located at UC Davis.",
            "topic": 19,
            "cx": 1902.45,
            "cy": -1893.67,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Liu2000Hig...",
            "text2": "92"
        },
        {
            "id": "2039138386",
            "name": "Texture hardware assisted rendering of time-varying volume data",
            "year": 2001,
            "firstName": "Eric B. Lum",
            "label": "B.2001Texture",
            "isKeyPaper": 1.0,
            "citationCount": 79,
            "abstract": "In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.",
            "topic": 7,
            "cx": 2310.45,
            "cy": -1803.93,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "B.2001Text...",
            "text2": "79"
        },
        {
            "id": "2096945381",
            "name": "In-situ processing and visualization for ultrascale simulations",
            "year": 2007,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2007In-situ",
            "isKeyPaper": 1.0,
            "citationCount": 67,
            "abstract": "The growing power of parallel supercomputers gives scientists the ability to simulate more complex problems at higher fidelity, leading to many high-impact scientific advances. To maximize the utilization of the vast amount of data generated by these simulations, scientists also need scalable solutions for studying their data to different extents and at different abstraction levels. As we move into peta- and exa-scale computing, simply dumping as much raw simulation data as the storage capacity allows for post-processing analysis and visualization is no longer a viable approach. A common practice is to use a separate parallel computer to prepare data for subsequent analysis and visualization. A naive realization of this strategy not only limits the amount of data that can be saved, but also turns I/O into a performance bottleneck when using a large parallel system. We conjecture that the most plausible solution for the peta- and exa-scale data problem is to reduce or transform the data in-situ as it is being generated, so the amount of data that must be transferred over the network is kept to a minimum. In this paper, we discuss different approaches to in-situ processing and visualization as well as the results of our preliminary study using large-scale simulation codes on massively parallel supercomputers.",
            "topic": 47,
            "cx": 1748.45,
            "cy": -1265.49,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "Liu2007In-...",
            "text2": "67"
        },
        {
            "id": "2182470571",
            "name": "In situ depth maps based feature extraction and tracking",
            "year": 2015,
            "firstName": "Yucong Chris Ye",
            "label": "Chris2015In",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Parallel numerical simulation is a powerful tool used by scientists to study complex problems. It has been a common practice to save the simulation output to disk and then conduct post-hoc in-depth analyses of the saved data. System I/O capabilities have not kept pace as simulations have scaled up over time, so a common approach has been to output only subsets of the data to reduce I/O. However, as we are entering the era of peta- and exa-scale computing, this sub-sampling approach is no longer acceptable because too much valuable information is lost. In situ visualization has been shown a promising approach to the data problem at extreme-scale. We present a novel in situ solution using depth maps to enable post-hoc image-based visualization and feature extraction and tracking. An interactive interface is provided to allow for fine-tuning the generation of depth maps during the course of a simulation run to better capture the features of interest. We use several applications including one actual simulation run on a Cray XE6 supercomputer to demonstrate the effectiveness of our approach.",
            "topic": 47,
            "cx": 2573.45,
            "cy": -547.57,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Chris2015I...",
            "text2": "3"
        },
        {
            "id": "2136917153",
            "name": "Scalable self-orienting surfaces a compact texture-enhanced representation for interactive visualization of 3D vector fields",
            "year": 2002,
            "firstName": "G. Schussman",
            "label": "Schussman2002Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 18,
            "abstract": "This paper presents a study of field line visualization techniques. To address both the computational and perceptual issues in visualizing large scale, complex, dense field line data commonly found in many scientific applications, a new texture-based field line representation which we call self-orienting surfaces is introduced This scalable representation facilitates hardware-accelerated rendering and incorporation of various perceptually-effective techniques, resulting in intuitive visualization and interpretation of the data under study. An electromagnetic data set obtained from accelerator modeling and a fluid flow data set from aerodynamics modeling are used for evaluation and demonstration of the techniques.",
            "topic": 27,
            "cx": 445.45,
            "cy": -1714.19,
            "rx": 84.71,
            "ry": 26.74,
            "text1": "Schussman2...",
            "text2": "18"
        },
        {
            "id": "1991484114",
            "name": "Extracting feature lines from 3D unstructured grids",
            "year": 1997,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1997Extracting",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "The paper discusses techniques for extracting feature lines from three-dimensional unstructured grids. The twin objectives are to facilitate the interactive manipulation of these typically very large and dense meshes, and to clarify the visualization of the solution data that accompanies them. The authors describe the perceptual importance of specific viewpoint-dependent and view-independent features, discuss the relative advantages and disadvantages of several alternative algorithms for identifying these features (taking into consideration both local and global criteria), and demonstrate the results of these methods on a variety of different data sets.",
            "topic": 59,
            "cx": 918.45,
            "cy": -2145.15,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu1997Ext...",
            "text2": "28"
        },
        {
            "id": "2136730689",
            "name": "Parallel volume rendering on the IBM Blue Gene/P",
            "year": 2008,
            "firstName": "Tom Peterka",
            "label": "Peterka2008Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "Parallel volume rendering is implemented and tested on an IBM Blue Gene distributed-memory parallel architecture. The goal of studying the cost of parallel rendering on a new class of supercomputers such as the Blue Gene/P is not necessarily to achieve real-time rendering rates. It is to identify and understand the extent of bottlenecks and interactions between various components that affect the design of future visualization solutions on these machines, solutions that may offer alternatives to hardware-accelerated volume rendering, for example, when large volumes, large image sizes, and very high quality results are dictated by peta- and exascale data. As a step in that direction, this study presents data from experiments under a number of conditions, including dataset size, number of processors, low- and high-quality rendering, offline storage of results, and streaming of images for remote display. Performance is divided into three main sections of the algorithm: disk I/O, rendering, and compositing. The dynamic balance among these tasks varies with the number of processors and other conditions. Lessons learned from the work include understanding the balance between parallel I/O, computation, and communication within the context of visualization on supercomputers; recommendations for tuning and optimization; and opportunities for further scaling. Extrapolating these results to very large data and image sizes suggests that a distributed-memory high-performance computing architecture such as the Blue Gene is a viable platform for some types of visualization at very large scales.",
            "topic": 7,
            "cx": 1413.45,
            "cy": -1175.75,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Peterka200...",
            "text2": "29"
        },
        {
            "id": "2018246367",
            "name": "Image graphs\u00e2\u20ac\u201da novel approach to visual data exploration",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Image",
            "isKeyPaper": 1.0,
            "citationCount": 72,
            "abstract": "For types of data visualization where the cost of producing images is high, and the relationship between the rendering parameters and the image produced is less than obvious, a visual representation of the exploration process can make the process more efficient and effective. Image graphs represent not only the results but also the process of data visualization. Each node in an image graph consists of an image and the corresponding visualization parameters used to produce it. Each edge in a graph shows the change in rendering parameters between the two nodes it connects. Image graphs are not just static representations: users can interact with a graph to review a previous visualization session or to perform new rendering. Operations which cause changes in rendering parameters can propagate through the graph. The user can take advantage of the information in image graphs to understand how certain parameter changes affect visualization results. Users can also share image graphs to streamline the process of collaborative visualization. We have implemented a volume visualization system using the image graph interface, and our examples in the paper come from this application.",
            "topic": 10,
            "cx": 3272.45,
            "cy": -1983.41,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Liu1999Ima...",
            "text2": "72"
        },
        {
            "id": "1982953486",
            "name": "A spreadsheet interface for visualization exploration",
            "year": 2000,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2000A",
            "isKeyPaper": 1.0,
            "citationCount": 46,
            "abstract": "As the size and complexity of data sets continues to increase, the development of user interfaces and interaction techniques that expedite the process of exploring that data must receive new attention. Regardless of the speed of rendering, it is important to coherently organize the visual process of exploration: this information both grants insights about the data to a user and can be used by collaborators to understand the results. To fulfil these needs, we present a spreadsheet-like interface to data exploration. The interface displays a 2-dimensional window into visualization parameter space which users manipulate as they search for desired results. Through tabular organization and a clear correspondence between parameters and results, the interface eases the discovery, comparison and analysis of the underlying data. Users can utilize operators and the integrated interpreter to further explore and automate the visualization process; using a method introduced in this paper, these operations can be applied to cells in different stacks of the interface. Via illustrations using a variety of data sets, we demonstrate the efficacy of this novel interface.",
            "topic": 8,
            "cx": 3380.45,
            "cy": -1893.67,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2000A",
            "text2": "46"
        },
        {
            "id": "2090746914",
            "name": "Visualizing visualizations User interfaces for managing and exploring scientific visualization data",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000Visualizing",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "The process of scientific visualization is inherently iterative. A good visualization comes from experimenting with visualization, rendering, and viewing parameters to bring out the most relevant information in the data. A good data visualization system thus lets scientists interactively explore the parameter space intuitively. The more efficient the system, the fewer the number of iterations needed for parameter selection. Over the past 10 years, significant efforts have gone into advancing visualization technology (such as real-time volume rendering and immersive environments), but little into coherently representing the process and results (images and insights) of visualization. This information about the data exploration should be shared and reused. In particular, for types of data visualization with a high cost of producing images and less than obvious relationship between the rendering parameters and the image produced, a visual representation of the exploration process can make the process more efficient and effective. This visual representation of data exploration process and results can be incorporated into and become a part of the user interface of a data exploration system. That is, we need to go beyond the traditional graphical user interface (GUI) design by coupling it with a mechanism that helps users keep track of their visualization experience, use it to generate new visualizations, and share it with others. Doing so can reduce the cost of visualization, particularly for routine analysis of large-scale data sets.",
            "topic": 53,
            "cx": 3614.45,
            "cy": -1893.67,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2000Vis...",
            "text2": "22"
        },
        {
            "id": "2154046714",
            "name": "Visualization exploration and encapsulation via a spreadsheet-like interface",
            "year": 2001,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2001Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 85,
            "abstract": "Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains.",
            "topic": 8,
            "cx": 3272.45,
            "cy": -1803.93,
            "rx": 74.91,
            "ry": 26.74,
            "text1": "J.2001Visu...",
            "text2": "85"
        },
        {
            "id": "2143275883",
            "name": "A model for the visualization exploration process",
            "year": 2002,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2002A",
            "isKeyPaper": 1.0,
            "citationCount": 53,
            "abstract": "The current state of the art in visualization research places a strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process---the results, history, and relationships between those results---is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize the information within the visualization process to further data exploration.",
            "topic": 0,
            "cx": 2615.45,
            "cy": -1714.19,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2002A",
            "text2": "53"
        },
        {
            "id": "2114265882",
            "name": "A Model and Framework for Visualization Exploration",
            "year": 2007,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2007A",
            "isKeyPaper": 0.989546,
            "citationCount": 118,
            "abstract": "Visualization exploration is the process of extracting insight from data via interaction with visual depictions of that data. Visualization exploration is more than presentation; the interaction with both the data and its depiction is as important as the data and depiction itself. Significant visualization research has focused on the generation of visualizations (the depiction); less effort has focused on the exploratory aspects of visualization (the process). However, without formal models of the process, visualization exploration sessions cannot be fully utilized to assist users and system designers. Toward this end, we introduce the P-Set model of visualization exploration for describing this process and a framework to encapsulate, share, and analyze visual explorations. In addition, systems utilizing the model and framework are more efficient as redundant exploration is avoided. Several examples drawn from visualization applications demonstrate these benefits. Taken together, the model and framework provide an effective means to exploit the information within the visual exploration process",
            "topic": 8,
            "cx": 2632.45,
            "cy": -1265.49,
            "rx": 50.41,
            "ry": 26.74,
            "text1": "J.2007A",
            "text2": "118"
        },
        {
            "id": "2146955194",
            "name": "Social-aware collaborative visualization for large scientific projects",
            "year": 2008,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2008Social-aware",
            "isKeyPaper": 1.0,
            "citationCount": 5,
            "abstract": "This paper discusses how to better support collaborative work for large scientific projects using visualization. Particular considerations are given to knowledge sharing and the social aspect of collaboration. The goal is to provide a roadmap for creating next-generation collaborative technologies with visual and social augmentation.",
            "topic": 20,
            "cx": 3560.45,
            "cy": -1175.75,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Liu2008Soc...",
            "text2": "5"
        },
        {
            "id": "2150064314",
            "name": "An Interface Design for Future Cloud-Based Visualization Services",
            "year": 2010,
            "firstName": "Yuzuru Tanahashi",
            "label": "Tanahashi2010An",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "The pervasive concept of cloud computing suggests that visualization, which is both data and computing intensive, is a perfect cloud computing application. This paper presents a sketch of an interface design for an online visualization service. To make such a service attractive to a wider audience, its user interface must be simple and easy to use for both casual and expert users. We envision an interface that supports visualization processes mainly directed by browsing and assessing existing visualizations in terms of images and videos will be very appealing to, in particular, casual users. That is, the aim is to maximize the utilization of the rich visualization data on the web. Without losing generality, we consider volume data visualization applications for our interface design. We also discuss issues in organizing online visualization data, and constructing and managing a rendering cloud.",
            "topic": 73,
            "cx": 3413.45,
            "cy": -996.27,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Tanahashi2...",
            "text2": "6"
        },
        {
            "id": "2092430905",
            "name": "Parallel visualization of large-scale aerodynamics calculations a case study on the Cray T3E",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 21,
            "abstract": "This paper reports the performance of a parallel volume rendering algorithm for visualizing a large-scale unstructured-grid dataset produced by a three-dimensional aerodynamics simulation. This dataset, containing over 18 million tetrahedra, allows us to extend our performance results to a problem which is more than 30 times larger than the one we examined previously. This high resolution dataset also allows us to see fine, three-dimensional features in the flow field. All our tests were performed on the SGI/Cray T3E operated by NASA's Goddard Space Flight Center. Using 511 processors, a rendering rate of almost 9 million tetrahedra/second was achieved with a parallel overhead of 26%.",
            "topic": 19,
            "cx": 1322.45,
            "cy": -1983.41,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu1999Par...",
            "text2": "21"
        },
        {
            "id": "2115314149",
            "name": "Visualizing Very Large-Scale Earthquake Simulations",
            "year": 2003,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2003Visualizing",
            "isKeyPaper": 1.0,
            "citationCount": 32,
            "abstract": "This paper presents a parallel adaptive rendering algorithm and its performance for visualizing time-varying unstructured volume data generated from large-scale earthquake simulations. The objective is to visualize 3D seismic wave propagation generated from a 0.5 Hz simulation of the Northridge earthquake, which is the highest resolution volume visualization of an earthquake simulation performed to date. This scalable high-fidelity visualization solution we provide to the scientists allows them to explore in the temporal, spatial, and visualization domain of their data at high resolution. This new high resolution explorability, likely not presently available to most computational science groups, will help lead to many new insights. The performance study we have conducted on a massively parallel computer operated at the Pittsburgh Supercomputing Center helps direct our design of a simulation-time visualization strategy for the higher-resolution, 1Hz and 2 Hz, simulations.",
            "topic": 66,
            "cx": 1428.45,
            "cy": -1624.45,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2003Vis...",
            "text2": "32"
        },
        {
            "id": "115809921",
            "name": "A Study of I/O Techniques for Parallel Visualization",
            "year": 2004,
            "firstName": "Hongfeng Yu",
            "label": "Yu2004A",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "This paper presents two parallel I/O methods for the visualization of time-varying volume data in a high-performance computing environment. We discuss the interplay between the parallel renderer, I/O strategy, and file system, and show the results of our study on the performance of the I/O strategies with and without MPI parallel I/O support. The targeted application is earthquake modeling using a large 3D unstructured mesh consisting of one hundred millions cells. Our test results on the HP/Compaq AlphaServer operated at the Pittsburgh Supercomputing Center demonstrate that the I/O methods effectively remove the I/O bottlenecks commonly present in time-varying data visualization, and therefore help significantly lower interframe delay. This high-performance visualization solution allows scientists to explore their data in the temporal, spatial, and visualization domains at high resolution. Such new explorability, likely not presently available to most computational science groups, will help lead to many new insights.",
            "topic": 19,
            "cx": 1088.45,
            "cy": -1534.71,
            "rx": 56.64,
            "ry": 26.74,
            "text1": "Yu2004A",
            "text2": "7"
        },
        {
            "id": "1556372880",
            "name": "I/O strategies for parallel rendering of large time-varying volume data",
            "year": 2004,
            "firstName": "Hongfeng Yu",
            "label": "Yu2004I/O",
            "isKeyPaper": 1.0,
            "citationCount": 15,
            "abstract": "This paper presents I/O solutions for the visualization of time-varying volume data in a parallel and distributed computing environment. Depending on the number of rendering processors used, our I/O strategies help signifi- cantly lower interframe delay by employing a set of I/O processors coupled with MPI parallel I/O support. The targeted application is earthquake modeling using a large 3D unstructured mesh consisting of one hundred millions cells. Our test results on the HP/Compaq AlphaServer operated at the Pittsburgh Supercomputing Center demonstrate that the I/O strategies effectively remove the I/O bottlenecks commonly present in time-varying data visualization. This high-performance visualization solution we provide to the scientists allows them to explore their data in the temporal, spatial, and visualization domains at high resolution. This new high-resolution explorability, likely not presently available to most computational science groups, will help lead to many new insights.",
            "topic": 7,
            "cx": 1379.45,
            "cy": -1534.71,
            "rx": 64.19,
            "ry": 26.74,
            "text1": "Yu2004I/O",
            "text2": "15"
        },
        {
            "id": "2162126826",
            "name": "A Parallel Visualization Pipeline for Terascale Earthquake Simulations",
            "year": 2004,
            "firstName": "Hongfeng Yu",
            "label": "Yu2004A",
            "isKeyPaper": 1.0,
            "citationCount": 45,
            "abstract": "This paper presents a parallel visualization pipeline implemented at the Pittsburgh Supercomputing Center (PSC) for studying the largest earthquake simulation ever performed. The simulation employs 100 million hexahedral cells to model 3D seismic wave propagation of the 1994 Northridge earthquake. The time-varying dataset produced by the simulation requires terabytes of storage space. Our solution for visualizing such terascale simulations is based on a parallel adaptive rendering algorithm coupled with a new parallel I/O strategy which effectively reduces interframe delay by dedicating some processors to I/O and preprocessing tasks. In addition, a 2D vector field visualization method and a 3D enhancement technique are incorporated into the parallel visualization framework to help scientists better understand the wave propagation both on and under the ground surface. Our test results on the HP/Compaq AlphaServer operated at the PSC show that we can completely remove the I/O bottlenecks commonly present in time-varying data visualization. The high-performance visualization solution we provide to the scientists allows them to explore their data in the temporal, spatial, and variable domains at high resolution. The new high-resolution explorability, likely not available to most computational science groups, will help lead to many new insights.",
            "topic": 66,
            "cx": 1556.45,
            "cy": -1534.71,
            "rx": 56.64,
            "ry": 26.74,
            "text1": "Yu2004A",
            "text2": "45"
        },
        {
            "id": "2010314815",
            "name": "A study of I/O methods for parallel visualization of large-scale data",
            "year": 2005,
            "firstName": "Hongfeng Yu",
            "label": "Yu2005A",
            "isKeyPaper": 1.0,
            "citationCount": 21,
            "abstract": "This paper presents two parallel I/O methods for the visualization of time-varying volume data in a high-performance computing environment. We discuss the interplay between the parallel renderer, I/O strategy, and file system, and show the results of our study on the performance of the I/O strategies with and without MPI parallel I/O support. The targeted application is earthquake modeling using a large 3D unstructured mesh consisting of one hundred millions cells. Our test results on the HP/Compaq AlphaServer operated at the Pittsburgh Supercomputing Center demonstrate that the I/O methods effectively remove the I/O bottlenecks commonly present in time-varying data visualization, and therefore help significantly lower interframe delay. This high-performance visualization solution allows scientists to explore their data in the temporal, spatial, and visualization domains at high resolution. Such new explorability, likely not presently available to most computational science groups, will help lead to many new insights into the modeled physical and chemical processes.",
            "topic": 19,
            "cx": 1251.45,
            "cy": -1444.97,
            "rx": 56.64,
            "ry": 26.74,
            "text1": "Yu2005A",
            "text2": "21"
        },
        {
            "id": "2148775223",
            "name": "Intelligent Feature Extraction and Tracking for Visualizing Large-Scale 4D Flow Simulations",
            "year": 2005,
            "firstName": "Fan Yin Tzeng",
            "label": "Yin2005Intelligent",
            "isKeyPaper": 1.0,
            "citationCount": 47,
            "abstract": "Terascale simulations produce data that is vast in spatial, temporal, and variable domains, creating a formidable challenge for subsequent analysis. Feature extraction as a data reduction method offers a viable solution to this large data problem. This paper presents a new approach to the problem of extracting and visualizing 4D features within large volume data. Conventional methods requires either an analytical description of the feature of interest or tedious manual intervention throughout the feature extraction and tracking process. We show that it is possible for a visualization system to learn to extract and track features in complex 4D flow field according to their visual properties, location, shape, and size. The basic approach is to employ machine learning in the process of visualization. Such an intelligent system approach is powerful because it allows us to extract and track an feature of interest in a high-dimensional space without explicitly specifying the relations between those dimensions, resulting in a greatly simplified and intuitive visualization interface.",
            "topic": 60,
            "cx": 1767.45,
            "cy": -1444.97,
            "rx": 77.15,
            "ry": 26.74,
            "text1": "Yin2005Int...",
            "text2": "47"
        },
        {
            "id": "2188498653",
            "name": "Ultra-Scale Visualization",
            "year": 2006,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2006Ultra-Scale",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "Modern parallel supercomputing systems give scientists the power to model and visualize physical phenomena and chemical processes at a stunning degree of precision and sophistication leading to profound levels of insight and understanding. This paper samples new techniques and concepts promising scientists to visualize and explore large-scale data to its full extent, and show the impact of these new technologies on a wide range of science endeavors",
            "topic": 72,
            "cx": 1556.45,
            "cy": -1355.23,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu2006Ult...",
            "text2": "2"
        },
        {
            "id": "2116283033",
            "name": "Parallel rendering of 3D AMR data on the SGI/Cray T3E",
            "year": 1999,
            "firstName": "Kwan Liu Ma",
            "label": "Liu1999Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 32,
            "abstract": "This paper describes work-in-progress on developing parallel visualization strategies for 3D Adaptive Mesh Refinement (AMR) data. AMR is a simple and powerful tool for modeling many important scientific and engineering problems. However visualization tools for 3D AMR data are not generally available. Converting AMR data onto a uniform mesh would result in high storage requirements, and rendering the uniform-mesh data on an average graphics workstation can be painfully slow if not impossible. The adaptive nature of the embedded mesh demands sophisticated visualization calculations. In this work, we compare the performance and storage requirements of a parallel volume renderer for regular-mesh data with a new parallel renderer based on adaptive sampling. While both renderers can achieve interactive visualization, the new approach offers significant performance gains, as indicated by our experiments on the SGI/Cray T3E.",
            "topic": 19,
            "cx": 1059.45,
            "cy": -1983.41,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu1999Par...",
            "text2": "32"
        },
        {
            "id": "27528377",
            "name": "Compression and Accelerated Rendering of Time-Varying Volume Data",
            "year": 2000,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2000Compression",
            "isKeyPaper": 1.0,
            "citationCount": 39,
            "abstract": "Author(s): Ma, Kwan-Liu; Shen, H. | Abstract: Visualization of time-varying volumetric data sets, which may be obtained from numerical simulations or sensing instruments, provides scientists insights into the detailed dynamics of the phenomenon under study. This paper describes our study of a coherent solution based on quantization coupled with octree and difference encoding, and adaptive rendering for efficient visualization of timevarying volumetric data. Quantization is used to attain voxel-level compression and may have a significant influence on the performance of the subsequent encoding and visualization steps. Octree encoding is used for spatial domain compression, and difference encoding for temporal domain compression. In essence, neighboring voxels may be fused into macro voxels if they have similar values, and subtrees at consecutive time steps may be merged if they are identical. The software rendering process is tailored according to the tree structures and the volume visualization process. With the tree representation, selective rendering may be performed very efficiently. Additionally, the I/O costs are reduced. With these combined savings, a higher level of user interactivity is achieved. We have studied a variety of time-varying volume data sets, performed encoding based on data statistics, and optimized the rendering calculations wherever possible. Preliminary tests on workstations have shown in many cases tremendous reduction by as high as 90% in both storage space and inter-frame delay when compared to direct rendering of the raw data.",
            "topic": 7,
            "cx": 2312.45,
            "cy": -1893.67,
            "rx": 85.62,
            "ry": 26.74,
            "text1": "Liu2000Com...",
            "text2": "39"
        },
        {
            "id": "1981608001",
            "name": "Large-scale data visualization",
            "year": 2001,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2001Large-scale",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "",
            "topic": 63,
            "cx": 3633.45,
            "cy": -1803.93,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu2001Lar...",
            "text2": "7"
        },
        {
            "id": "2009776702",
            "name": "Ultra-Scale Visualization Research and Education",
            "year": 2007,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2007Ultra-Scale",
            "isKeyPaper": 1.0,
            "citationCount": 5,
            "abstract": "Understanding the science behind large-scale simulations and high-throughput experiments requires extracting meaning from data sets of hundreds of terabytes or more. Visualization is the most intuitive means for scientists to understand data at this scale, and the most effective way to communicate their findings with others. Even though visualization technology has matured over the past twenty years, it is still limited by the extent and scale of the data that it can be applied to, and also by the functionalities that were mostly designed for single-user, single-variable, and single-space investigation. The Institute for Ultra-Scale Visualization (IUSV), funded by the DOE SciDAC-2 program, has the mission to advance visualization technologies to enable knowledge discovery and dissemination for peta-scale applications. By working with the SciDAC application projects, Centers for Enabling Technology, and other Institutes, IUSV aims to lead the research innovation that can create new visualization capabilities needed for gleaning insights from data at petascale and beyond to solve forefront scientific problems. This paper outlines what we see as some of the biggest research challenges facing the visualization community, and how we can approach education and outreach to put successful research in the hands of scientists.",
            "topic": 72,
            "cx": 3950.45,
            "cy": -1265.49,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Liu2007Ult...",
            "text2": "5"
        },
        {
            "id": "2154789475",
            "name": "Machine Learning to Boost the Next Generation of Visualization Technology",
            "year": 2007,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2007Machine",
            "isKeyPaper": 1.0,
            "citationCount": 30,
            "abstract": "Visualization has become an indispensable tool in many areas of science and engineering. In particular, the advances made in the field of visualization over the past 20 years have turned visualization from a presentation tool to a discovery tool. Machine learning has received great success in both data mining and computer graphics; surprisingly, the study of systematic ways to employ machine learning in making visualization is meager. Like human learning, we can make a computer program learn from previous input data to optimize its performance on processing new data. In the context of visualization, the use of machine learning can potentially free us from manually sifting through all the data. This paper describes intelligent visualization designs for three different applications: (1) volume classification and visualization, (2) 4D flow feature extraction and tracking, (3) network scan characterization.",
            "topic": 3,
            "cx": 4168.45,
            "cy": -1265.49,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Liu2007Mac...",
            "text2": "30"
        },
        {
            "id": "2114283921",
            "name": "Advanced Visualization Technology for Terascale Particle Accelerator Simulations",
            "year": 2002,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2002Advanced",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "This paper presents two new hardware-assisted rendering techniques developed for interactive visualization of the terascale data generated from numerical modeling of next-generation accelerator designs. The first technique, based on a hybrid rendering approach, makes possible interactive exploration of large-scale particle data from particle beam dynamics modeling. The second technique, based on a compact texture-enhanced representation, exploits the advanced features of commodity graphics cards to achieve perceptually effective visualization of the very dense and complex electromagnetic fields produced from the modeling of reflection and transmission properties of open structures in an accelerator design. Because of the collaborative nature of the overall accelerator modeling project, the visualization technology developed is for both desktop and remote visualization settings. We have tested the techniques using both time-varying particle data sets containing up to one billion particles per time step and electromagnetic field data sets with millions of mesh elements.",
            "topic": 75,
            "cx": 1794.45,
            "cy": -1714.19,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu2002Adv...",
            "text2": "28"
        },
        {
            "id": "2145293470",
            "name": "Visualization of multidimensional multivariate volume data using hardware-accelerated non-photorealistic rendering techniques",
            "year": 2002,
            "firstName": "Aleksander Stompel",
            "label": "Stompel2002Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 26,
            "abstract": "This paper presents a set of feature enhancement techniques. coupled with hardware-accelerated non-photorealistic rendering for generating more perceptually effective visualizations of multidimensional, multivariate volume data, such as those obtained from typical computational fluid dynamics simulations. For time-invariant data, one or more variables are used to either highlight important features in another variable, or add contextural information to the visualization. For time-varying data, rendering of each time step also takes into account the values at neighboring time steps to reinforce the perception of the changing features in the data over time. With hardware-accelerated rendering, interactive visualization becomes possible leading to increased explorability and comprehension of the data.",
            "topic": 7,
            "cx": 2012.45,
            "cy": -1714.19,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Stompel200...",
            "text2": "26"
        },
        {
            "id": "2947284622",
            "name": "Feature-Enhanced Visualization of Multidimensional Multivariate Volume Data Using Non-photorealistic Rendering Techniques",
            "year": 2002,
            "firstName": "Eric B. Lum",
            "label": "B.2002Feature-Enhanced",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Author(s): Lum, Eric; Ma, Kwan-Liu | Abstract: This paper presents a set of feature enhancement techniques coupled with hardware-accelerated nonphotorealistic rendering for generating more perceptually effective visualization of multidimensional, multivariate volume data, such as those obtained from typical computational fluid dynamics simulations. For time-invariant data, one or more variables are used to either highlight important features in another variable, or add contextural information to the visualization. For time-varying data, rendering of each time step also takes into account the values at neighboring time steps to reinforce the perception of the changing features in the data over time. With hardware-accelerated rendering, interactive visualization becomes possible leading to increased explorability and comprehension of the data.",
            "topic": 7,
            "cx": 2268.45,
            "cy": -1714.19,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2002Feat...",
            "text2": "13"
        },
        {
            "id": "2103068632",
            "name": "Using motion to illustrate static 3D shape-kinetic visualization",
            "year": 2003,
            "firstName": "Eric B. Lum",
            "label": "B.2003Using",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "In this paper, we present a novel visualization technique-kinetic visualization-that uses motion along a surface to aid in the perception of 3D shape and structure of static objects. The method uses particle systems, with rules such that particles flow over the surface of an object to not only bring out, but also attract attention to information on a shape that might not be readily visible with a conventional rendering method which uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that, in many cases, the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. We also describe how, for both types of data, a texture-based representation of this motion can be used for interactive visualization using PC graphics hardware. Finally, the results of a user study that we have conducted are presented, which show evidence that the supplemental motion cues can be helpful.",
            "topic": 85,
            "cx": 2976.45,
            "cy": -1624.45,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "B.2003Usin...",
            "text2": "29"
        },
        {
            "id": "2096608735",
            "name": "Visualizing field-measured seismic data",
            "year": 2010,
            "firstName": "Tung Ju Hsieh",
            "label": "Ju2010Visualizing",
            "isKeyPaper": 0.769231,
            "citationCount": 10,
            "abstract": "This paper presents visualization of field-measured, time-varying multidimensional earthquake accelerograph readings. Direct volume rendering is used to depict the space-time relationships of seismic readings collected from sensor stations in an intuitive way such that the progress of seismic wave propagation of an earthquake event can be directly observed. The resulting visualization reveals the sequence of seismic wave initiation, propagation, attenuation over time, and energy releasing events. We provide a case study on the magnitude scale M w 7.6 Chi-Chi earthquake in Taiwan, which is the most thoroughly recorded earthquake event ever in the history. More than 400 stations recorded this event, and the readings from this event increased global strong-motion records five folds. Each station measured east-west, north-south, and vertical component of acceleration for approximately 90 seconds. The sensor network released the initial raw data within minutes after the Chi-Chi mainshock. It is essential to have a visualization system for fast data exploring and analyzing, offering crucial visual analytical information for scientists to make quick judgments. Raw data requires preprocessing before it can be rendered. We generated a sequence of ground-motion wave-field maps of 350 xc3x97 200 regular grid covers the entire Taiwan island from the sensor network readings. The result is a total of 1000 ground-motion wave-field maps with 0.1 second interval, forming a 1000 xc3x97 350 xc3x97 200 volume data set. We show that visualizing the time-varying component of the data spatially uncovers the changing features hidden in the data.",
            "topic": 66,
            "cx": 2043.45,
            "cy": -996.27,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Ju2010Visu...",
            "text2": "10"
        },
        {
            "id": "2133015261",
            "name": "Application-Driven Compression for Visualizing Large-Scale Time-Varying Data",
            "year": 2010,
            "firstName": "Chaoli Wang",
            "label": "Wang2010Application-Driven",
            "isKeyPaper": 1.0,
            "citationCount": 28,
            "abstract": "We advocate an application-driven approach to compressing and rendering large-scale time-varying scientific-simulation data. Scientists often have specific visualization tasks in mind based on certain domain knowledge. For example, in the context of time-varying, multivariate volume-data visualization, a scientist's domain knowledge might include the salient isosurface of interest for some variable. Given this knowledge, the scientist might want to observe spatiotemporal relationships among other variables in the neighborhood of that isosurface. We've tried to directly incorporate such knowledge and tasks into data reduction, compression, and rendering. Here, we present our solution andexperimental results for two largescale time-varying, multivariate scientific data sets.",
            "topic": 15,
            "cx": 2228.45,
            "cy": -996.27,
            "rx": 88.28,
            "ry": 26.74,
            "text1": "Wang2010Ap...",
            "text2": "28"
        },
        {
            "id": "2131433745",
            "name": "An exploratory technique for coherent visualization of time-varying volume data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010An",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "The selection of an appropriate global transfer function is essential for visualizing time-varying simulation data. This is especially challenging when the global data range is not known in advance, as is often the case in remote and in-situ visualization settings. Since the data range may vary dramatically as the simulation progresses, volume rendering using local transfer functions may not be coherent for all time steps. We present an exploratory technique that enables coherent classification of time-varying volume data. Unlike previous approaches, which require pre-processing of all time steps, our approach lets the user explore the transfer function space without accessing the original 3D data. This is useful for interactive visualization, and absolutely essential for in-situ visualization, where the entire simulation data range is not known in advance. Our approach generates a compact representation of each time step at rendering time in the form of ray attenuation functions, which are used for subsequent operations on the opacity and color mappings. The presented approach offers interactive exploration of time-varying simulation data that alleviates the cost associated with reloading and caching large data sets.",
            "topic": 15,
            "cx": 2489.45,
            "cy": -996.27,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "22"
        },
        {
            "id": "2133638798",
            "name": "Next-Generation Visual Supercomputing Using PC Clusters with Volume Graphics Hardware Devices",
            "year": 2001,
            "firstName": "Shigeru Muraki",
            "label": "Muraki2001Next-Generation",
            "isKeyPaper": 1.0,
            "citationCount": 38,
            "abstract": "To seek a low-cost, extensible solution for the large-scale data visualization problem, a visual computing system is designed as a result of a collaboration between industry and government research laboratories in Japan, also with participation by researchers in U.S. This scalable system is a commodity PC cluster equipped with the VolumePro 500 volume graphics cards and a specially designed image compositing hardware. Our performance study shows such a system is capable of interactive rendering 5123 and 10243 volume data and highly scalable. In particular, with such a system, simulation and visualization can be performed concurrently which allows scientists to monitor and tune their simulations on the fly. In this paper, both the system and hardware designs are presented.",
            "topic": 7,
            "cx": 807.45,
            "cy": -1803.93,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muraki2001...",
            "text2": "38"
        },
        {
            "id": "1725558581",
            "name": "A PC cluster system for simultaneous interactive volumetric modeling and visualization",
            "year": 2003,
            "firstName": "Shigeru Muraki",
            "label": "Muraki2003A",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "A number of problems are well suited for volumetric representation for both simulation and storage, however, the large amount of data that needs to be processed and rendered with these volumes makes interactive manipulation extremely challenging. We present a scalable PC cluster system (VG cluster) designed specifically to enable simultaneous volumetric computation and visualization, using compositing hardware devices and the latest PC graphics accelerators. We demonstrate the flexibility and performance of this system with several different applications that include reaction-diffusion simulation, volumetric image processing, and vector field visualization. We also discuss how to improve the visual computing performance of this system with some load balancing techniques.",
            "topic": 82,
            "cx": 807.45,
            "cy": -1624.45,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muraki2003...",
            "text2": "29"
        },
        {
            "id": "2091518855",
            "name": "VisSheet redux redesigning a visualization exploration spreadsheet for the web",
            "year": 2002,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2002VisSheet",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "The exploration of complex data sets requires interfaces to present and navigate through the visualization of the data. In recent work [Jankun-Kelly and Ma 2001], we produced a visualization exploration spreadsheet to address this issue. The developed application, however, was implemented for off-line use only. For data sets on remote sites, this approach is not appropriate. Thus, a web-based version of the visualization exploration spreadsheet is needed. This abstract discusses the process of transforming the interface from an off-line to an on-line design.",
            "topic": 8,
            "cx": 3272.45,
            "cy": -1714.19,
            "rx": 74.91,
            "ry": 26.74,
            "text1": "J.2002VisS...",
            "text2": "0"
        },
        {
            "id": "2167688344",
            "name": "Deploying Web-based visual exploration tools on the grid",
            "year": 2003,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2003Deploying",
            "isKeyPaper": 1.0,
            "citationCount": 38,
            "abstract": "Grid-based computing facilitates access to different resources. But management in a grid-based environment isn't centralized. To use grid resources effectively, researchers need a central access point to manage the resources, provide a visual means to explore the data, and record these explorations for further investigation and dissemination. This article describes such a system that's being developed jointly by the University of California, Davis, and the Lawrence Berkeley National Laboratory (LBNL). The centralized system acts as a portal into grid-enabled visualization systems. Scientists using the portal can focus on the important task of extracting insights from their data through visualization instead of having to worry about process management. Because scientists at LBNL and their collaborators require access to the portal from around the world, the portal's interface is entirely Web-based. Authenticated users only need a standards-compliant Web browser to explore their data from anywhere in the world. The portal provides a Web-based interface not just for exploring but also for encapsulating visualization data. Encapsulating the process lets users reproduce the visualization results for validation or extend those results by continuing data exploration. We discuss the integration of our grid-enabled visualization server, the visualization Web application that performs the visualization session management, and the Web-based interface.",
            "topic": 46,
            "cx": 2632.45,
            "cy": -1624.45,
            "rx": 76.24,
            "ry": 26.74,
            "text1": "J.2003Depl...",
            "text2": "38"
        },
        {
            "id": "2293301496",
            "name": "Relation-aware spreadsheets for multimodal volume segmentation and visualization",
            "year": 2010,
            "firstName": "Lin Zheng",
            "label": "Zheng2010Relation-aware",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "Multimodal volume data commonly found in medical imaging applications present both opportunities and challenges to segmentation and visualization tasks. This paper presents a user directed volume segmentation system. Through a spreadsheets interface, the user can interactively examine and refine segmentation results obtained from automatic clustering. In addition, the user can isolate or highlight a feature of interest in a volume based on different modalities, and see the corresponding segmented results. Our system is easy to use since the preliminary segmentation results are organized and presented to the user in a relation-aware fashion based on the spatial relations between the segmented regions. We demonstrate this system using two multimodal datasets.",
            "topic": 7,
            "cx": 3734.45,
            "cy": -996.27,
            "rx": 86.03,
            "ry": 26.74,
            "text1": "Zheng2010R...",
            "text2": "1"
        },
        {
            "id": "42438372",
            "name": "47 \u00e2\u20ac\u201c Visualization for Computational Accelerator Physics",
            "year": 2005,
            "firstName": "Kwan Liu Ma",
            "label": "Liu200547",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "Computer simulations are used in the design of next-generation particle accelerators for modeling. To meet design requirements and to reduce cost and technological risk in the later stages of accelerator design, construction, and operations, very high-resolution modeling is essential. The scale and complexity of these computer simulations requires the use of powerful high-performance computing platforms using software and algorithms targeted to parallel and distributed environments as well as advanced data analysis and visualization tools that make it possible to understand the resulting terabytes of simulation data. This chapter illustrates the visualization challenges introduced by the most advanced particle accelerator simulations and describe visualization solutions derived to address these challenges. Two primary visualization problems are considered: first, the problem of visualizing very dense point data and second, visualizing very dense line data. While these two problems are specific to accelerator physics data, the techniques described in the chapter are also suited to any other applications concerned with the visualization of particle and field line data.",
            "topic": 19,
            "cx": 464.45,
            "cy": -1444.97,
            "rx": 65.52,
            "ry": 26.74,
            "text1": "Liu200547",
            "text2": "0"
        },
        {
            "id": "2111106392",
            "name": "Interactivity is the key to expressive visualization",
            "year": 2002,
            "firstName": "Eric B. Lum",
            "label": "B.2002Interactivity",
            "isKeyPaper": 1.0,
            "citationCount": 9,
            "abstract": "",
            "topic": 79,
            "cx": 3986.45,
            "cy": -1714.19,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "B.2002Inte...",
            "text2": "9"
        },
        {
            "id": "2127273065",
            "name": "Intelligent Focus+Context Volume Visualization",
            "year": 2008,
            "firstName": "Cheng Kai Chen",
            "label": "Kai2008Intelligent",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "Although graphics processing unit (GPU) acceleration makes possible interactive volume rendering, successful volume visualization relies on the ability to quickly and correctly classify the volume into different materials or features. Among various classification techniques, one very attractive and effective method is employing machine learning to classify the whole volume according to some minimum user input through an interactive brushing interface, where users paint directly on slices of the volume. For routine visualization tasks, we can thus reduce their cost if the visualization system can learn the tasks and apply the captured knowledge in future tasks. This paper presents an intelligent, interactive visualization system that supports FocusContext viewing of volume data. Features of interest should be the focal point of the visualization, and by applying appropriate rendering methods we are able to enhance these features and create more illustrative visualizations in a FocusContext style. We show with a set of case studies that it is possible to use machine learning to not only help classify volume but also better present the classified results. This new capability makes visualization a more usable tool.",
            "topic": 7,
            "cx": 4250.45,
            "cy": -1175.75,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2008Int...",
            "text2": "4"
        },
        {
            "id": "2043965591",
            "name": "Scientific Discovery through Advanced Visualization",
            "year": 2005,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2005Scientific",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "The SciDAC program of the Department of Energy has brought together tremendous scientific expertises and computing resources to realize the promise of terascale computing for attempting to answer some of the most important basic science questions. Scientific visualization is an indispensable path to gleaning insight from the massive data produced by terascale simulations. Unless the visualization challenges presented by the terascale simulations be adequately addressed, the value of conducting these immense and costly simulations is not being fully realized. In this paper, we introduce several key visualization technologies that address the critical need of many SciDAC scientists in the application areas from accelerator simulations, earthquake modeling, plasma physics, supernova modeling, to turbulent combustion simulations.",
            "topic": 53,
            "cx": 2016.45,
            "cy": -1444.97,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2005Sci...",
            "text2": "7"
        },
        {
            "id": "2138290184",
            "name": "Visualizing Multivariate Volume Data from Turbulent Combustion Simulations",
            "year": 2007,
            "firstName": "Hiroshi Akiba",
            "label": "Akiba2007Visualizing",
            "isKeyPaper": 1.0,
            "citationCount": 39,
            "abstract": "To understand dynamic mechanisms, scientists need intuitive and convenient ways to validate known relationships and reveal hidden ones among multiple variables",
            "topic": 7,
            "cx": 2150.45,
            "cy": -1265.49,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Akiba2007V...",
            "text2": "39"
        },
        {
            "id": "2156990842",
            "name": "Kinetic visualization a technique for illustrating 3D shape and structure",
            "year": 2002,
            "firstName": "Eric B. Lum",
            "label": "B.2002Kinetic",
            "isKeyPaper": 1.0,
            "citationCount": 27,
            "abstract": "Motion provides strong visual cues for the perception of shape and depth, as demonstrated by cognitive scientists and visual artists. This paper presents a novel visualization technique --- kinetic visualization --- that uses particle systems to add supplemental motion cues which can aid in the perception of shape and spatial relationships of static objects. Based on a set of rules following perceptual and physical principles, particles flowing over the surface of an object not only bring out, but also attract attention to, essential information on the shape of the object that might not be readily visible with conventional rendering that uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that in many cases the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. The results of a preliminary user study that we have conducted also show evidence that the supplemental motion cues help.",
            "topic": 85,
            "cx": 3023.45,
            "cy": -1714.19,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2002Kine...",
            "text2": "27"
        },
        {
            "id": "2025518624",
            "name": "AniViz A Template-Based Animation Tool for Volume Visualization",
            "year": 2010,
            "firstName": "Hiroshi Akiba",
            "label": "Akiba2010AniViz",
            "isKeyPaper": 1.0,
            "citationCount": 14,
            "abstract": "Interactive visualization is the key to insightful exploration. Animation can effectively convey a complex process or structure. Deriving a sequence of desired keyframes is a painstaking process entailing much trial and error. To help alleviate this problem, we developed AniViz-a tool for making visualization animations of time-varying, multivariate volume data. AniViz is an animation tool following two principles. First, it's desirable to directly turn the results of data exploration and visualization into animation content. Second, users can create a complex animation sequence by combining several simple effects. Such effects, and operators to combine them, are fine-tuned via an intuitive user interface.",
            "topic": 65,
            "cx": 3234.45,
            "cy": -996.27,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Akiba2010A...",
            "text2": "14"
        },
        {
            "id": "2064959254",
            "name": "Recent advances in hardware-accelerated volume rendering",
            "year": 2003,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2003Recent",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Abstract The programmability and texture support of consumer graphics accelerators have drawn a lot of attention from visualization researchers, resulting in some very important advances in interactive volume data visualization. For many applications, scientists can now perform routine data visualization and analysis tasks on their desktop PC with a consumer graphics card that was designed mainly for playing video games. This paper presents several representative hardware-accelerated algorithms that have been introduced recently to address the problems of classification, illumination, non-photorealistic rendering, decoding, and image compositing in volume data visualization.",
            "topic": 7,
            "cx": 2013.45,
            "cy": -1624.45,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Liu2003Rec...",
            "text2": "13"
        },
        {
            "id": "2146362647",
            "name": "RINGS A Technique for Visualizing Large Hierarchies",
            "year": 2002,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2002RINGS",
            "isKeyPaper": 1.0,
            "citationCount": 61,
            "abstract": "We present RINGS, a technique for visualizing large trees. We introduce a new ringed circular layout of nodes to make more efficient use of limited display space. RINGS provides the user with the means to specify areas of primary andsecond ary focus, andis able to show multiple foci without compromising understanding of the graph. The strength of RINGS is its ability to show more area in focus andmore contextual information than existing techniques. We demonstrate the effectiveness of RINGS by applying it to the visualization of a Unix file directory.",
            "topic": 25,
            "cx": 2804.45,
            "cy": -1714.19,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Tee2002RIN...",
            "text2": "61"
        },
        {
            "id": "2130218153",
            "name": "MoireGraphs radial focus+context visualization and interaction for graphs with visual nodes",
            "year": 2003,
            "firstName": "T. J. Jankun Kelly",
            "label": "J.2003MoireGraphs",
            "isKeyPaper": 1.0,
            "citationCount": 84,
            "abstract": "Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focuscontext radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.",
            "topic": 10,
            "cx": 2802.45,
            "cy": -1624.45,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "J.2003Moir...",
            "text2": "84"
        },
        {
            "id": "1611667971",
            "name": "Depicting Time Evolving Flow with Illustrative Visualization Techniques",
            "year": 2009,
            "firstName": "Wei Hsien Hsu",
            "label": "Hsien2009Depicting",
            "isKeyPaper": 1.0,
            "citationCount": 17,
            "abstract": "Visualization has become an indispensable tool for scientists to extract knowledge from large amounts of data and convey that knowledge to others. Visualization may be exploratory or illustrative. Exploratory visualization generally provides multiple views of the data at different levels of abstraction and should be highly interactive, whereas illustrative visualization is often made offline at high quality with sufficient knowledge about the data and features of interest. Techniques used by professional illustrators may be borrowed to enhance the clarity and aesthetics of the visualization. This paper presents a set of visualization techniques for presenting the evolution of 3D flow. While the spatial features of the data is rendered in 3D space, the temporal behaviors of the flow are depicted using image-based methods. We demonstrate visualization results generated using three data sets obtained from simulations.",
            "topic": 12,
            "cx": 2227.45,
            "cy": -1086.01,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Hsien2009D...",
            "text2": "17"
        },
        {
            "id": "2166303794",
            "name": "Parallel hierarchical visualization of large time-varying 3D vector fields",
            "year": 2007,
            "firstName": "Hongfeng Yu",
            "label": "Yu2007Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 57,
            "abstract": "We present the design of a scalable parallel pathline construction method for visualizing large time-varying 3D vector fields. A 4D (i.e., time and the 3D spatial domain) representation of the vector field is introduced to make a time-accurate depiction of the flow field. This representation also allows us to obtain pathlines through streamline tracing in the 4D space. Furthermore, a hierarchical representation of the 4D vector field, constructed by clustering the 4D field, makes possible interactive visualization of the flow field at different levels of abstraction. Based on this hierarchical representation, a data partitioning scheme is designed to achieve high parallel efficiency. We demonstrate the performance of parallel pathline visualization using data sets obtained from terascale flow simulations. This new capability will enable scientists to study their time-varying vector fields at the resolution and interactivity previously unavailable to them.",
            "topic": 27,
            "cx": 808.45,
            "cy": -1265.49,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Yu2007Para...",
            "text2": "57"
        },
        {
            "id": "2005878980",
            "name": "High-performance computing and visualization of earthquake simulations and ground-motion sensor network data",
            "year": 2012,
            "firstName": "Tung Ju Hsieh",
            "label": "Ju2012High-performance",
            "isKeyPaper": 0.769231,
            "citationCount": 3,
            "abstract": "Comparing numerical simulation results with accelerograph readings is essential in earthquake investigations and discoveries. We provide a case study on the magnitude 7.6 Taiwan Chi-Chi earthquake in 1999. More than 400 seismic sensor stations recorded this event, and the readings from this event increased global strong-motion records fivefold so that the accuracy of the earthquake simulation was enhanced significantly. Direct volume rendering is used to depict the space-time relationships of numerical results and seismic readings. When earthquake simulation data are volume rendered, it reveals the sequence of seismic wave initiation, propagation, attenuation, and energy releasing events of fault ruptures so that the direction of seismic wave propagation can be observed. Both accelerograph readings and earthquake simulation data are used to generate a sequence of ground-motion maps. Stacking these maps up in sequence forms a volume data. Visual analysis of the time-varying component reveals hidden features for better comparison and evaluation. Earthquake scientists are able to obtain insights and evaluate their simulation criteria from volume rendering.",
            "topic": 66,
            "cx": 1712.45,
            "cy": -816.79,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Ju2012High...",
            "text2": "3"
        },
        {
            "id": "2095627337",
            "name": "Detecting flaws and intruders with visual data analysis",
            "year": 2004,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2004Detecting",
            "isKeyPaper": 1.0,
            "citationCount": 59,
            "abstract": "The task of sifting through large amounts of data to find useful information spawned the field of data mining. Most data mining approaches are based on machine-learning techniques, numerical analysis, or statistical modeling. They use human interaction and visualization only minimally. Such automatic methods can miss some important features of the data. Incorporating human perception into the data mining process through interactive visualization can help us better understand the complex behaviors of computer network systems. This article describes visual-analytics-based solutions and outlines a visual exploration process for log analysis. Three log-file analysis applications demonstrate our approach's effectiveness in discovering flaws and intruders in network systems.",
            "topic": 33,
            "cx": 2948.45,
            "cy": -1534.71,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Tee2004Det...",
            "text2": "59"
        },
        {
            "id": "2155542779",
            "name": "A visual exploration process for the analysis of Internet routing data",
            "year": 2003,
            "firstName": "Soon Tee Teoh",
            "label": "Tee2003A",
            "isKeyPaper": 1.0,
            "citationCount": 41,
            "abstract": "The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.",
            "topic": 29,
            "cx": 3136.45,
            "cy": -1624.45,
            "rx": 61.54,
            "ry": 26.74,
            "text1": "Tee2003A",
            "text2": "41"
        },
        {
            "id": "1855245415",
            "name": "Cyber security through visualization",
            "year": 2006,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2006Cyber",
            "isKeyPaper": 1.0,
            "citationCount": 8,
            "abstract": "Networked computers are subject to attack, misuse, and abuse. Organizations and individuals are making every effort to build and maintain trustworthy computing systems. The main strategy is to closely monitor and inspect network activities by collecting and analyzing data about the network traffic and the trails of system usage. The analysis usually requires large amounts of finely detailed, high-dimensional data to enable analysts to uncover hidden threats and make calculated predictions in a timely fashion. The traditional, signature-based and statistical methods are limited in their capability to cope with the large, evolving data and the dynamic nature of the Internet. Visualization proves effective to aid in understanding large, high-dimensional data commonly found in many demanding applications such as large-scale scientific simulations and biomedicine. There is thus a growing interest in the development of visualization methods as alternative or complementary solutions to the pressing cyber security problems (Brodley, Chan, Lippmann & Yurcik 2004, Ma, North & Yurcik 2005). The challenge is to develop new visual representations, layout methods, user interfaces, and interaction techniques that can effectively facilitate visual interrogation and communication of the vast amounts of cyber security information. Visual data analysis is inherently an iterative process, where each iteration provides more insight into the data being shown. A typical example of this process occurs with any type of overview plus detail visualization. Patterns in the overview tend to direct what the user chooses to view in more detail, and the detailed view can provide insight on regions of the overview. This drill-down process, starting at a high semantic level and progressing to more detailed views, creates a feedback loop as shown in Figure 1, which can lend itself well to visualizing the relationships between large number of objects, such as port and network scans. In most cases, different visual representations are needed for constructing these different views. In particular, each specific region of interest may be defined in a space of arbitrary dimensions. The challenge is thus to seek the best space and visual representation in that space for each type of analysis task. I show with three different tasks how visualization can assist in the analysis of computer network activities for detecting anomalies using the drill-down process.",
            "topic": 29,
            "cx": 3086.45,
            "cy": -1355.23,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Liu2006Cyb...",
            "text2": "8"
        },
        {
            "id": "2263579231",
            "name": "Interactive and perceptually enhanced visualization of large complex line-based datasets",
            "year": 2003,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2003Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "Increasing computing power, including that available from Linux clusters and supercomputers permits increasing accuracy in modeling and physics-based simulation of natural phenomena, which, in turn, results in increasingly larger and more detailed data. One class of this detailed data is consists of sets of different line types which should be visualized simultaneously to understand their relationships to one another. Examples include electric and magnetic field lines, velocity and vorticity field lines, or the trajectory paths of different particle types. The extreme size and high density of these datasets can overwhelm current visualization techniques by requiring too much memory, or too much compute time. Very dense lines can also result in unintelligible images where the depth relationships between the lines can not be conveyed with current methods. n To circumvent the pitfalls of current visualization technique with respect to difficult line-based data, the visualization techniques presented in this dissertation take into account perceptual issues. By providing the cues that the human visual system uses to resolve depth relationships, making use of the natural image processing capabilities of that system, and simulating real-world illumination, the visualization methods avoid ambiguity and present compelling images which are easily interpreted, and which reduce the likelihood of illusions. n Three visualization methods are presented, each with their own area of applicability. The first method efficiently combines two existing line rendering techniques, and is suitable for older machines with slower CPUs and graphics hardware with minimal texturing capabilities. The second method provides self-orienting geometry for texturing. It is appropriate for large datasets where the lines to be visualized project to be at least several pixels wide, and presents lines with the appearance of three dimensional tubes, but much more efficiently than using actual polygonal tubes, and with a greater degree of flexibility for taking full advantage of the sophisticated texturing capabilities of modern graphics hardware. The final visualization method is based on anisotropic volume rendering, and is appropriate for gigantic, very dense line datasets, where line thicknesses can range from one pixel to extremely sub-pixel. Together, these three methods cover a very broad range of dataset sizes, and are demonstrated for visualizing simulations of wake vortices around the tail of an airplane, electric and magnetic fields within a linear accelerator structures, and charged particle trajectories generated and influenced by those fields.",
            "topic": 88,
            "cx": 379.45,
            "cy": -1624.45,
            "rx": 77.15,
            "ry": 26.74,
            "text1": "Liu2003Int...",
            "text2": "2"
        },
        {
            "id": "2536708871",
            "name": "Anisotropic Volume Rendering for Extremely Dense Thin Line Data",
            "year": 2004,
            "firstName": "G. Schussman",
            "label": "Schussman2004Anisotropic",
            "isKeyPaper": 1.0,
            "citationCount": 19,
            "abstract": "Many large scale physics-based simulations which take place on PC clusters or supercomputers produce huge amounts of data including vector fields. While these vector data such as electromagnetic fields, fluid flow fields, or particle paths can be represented by lines, the sheer number of the lines overwhelms the memory and computation capability of a high-end PC used for visualization. Further, very dense or intertwined lines, rendered with traditional visualization techniques, can produce unintelligible results with unclear depth relationships between the lines and no sense of global structure. Our approach is to apply a lighting model to the lines and sample them into an anisotropic voxel representation based on spherical harmonics as a preprocessing step. Then we evaluate and render these voxels for a given view using traditional volume rendering. For extremely large line based datasets, conversion to anisotropic voxels reduces the overall storage and rendering for O(n) lines to O(1) with a large constant that is still small enough to allow meaningful visualization of the entire dataset at nearly interactive rates on a single commodity PC.",
            "topic": 7,
            "cx": 379.45,
            "cy": -1534.71,
            "rx": 84.71,
            "ry": 26.74,
            "text1": "Schussman2...",
            "text2": "19"
        },
        {
            "id": "2099306854",
            "name": "Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing",
            "year": 2009,
            "firstName": "Christopher Wesley Muelder",
            "label": "Wesley2009Visual",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.",
            "topic": 19,
            "cx": 1041.45,
            "cy": -1086.01,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Wesley2009...",
            "text2": "20"
        },
        {
            "id": "2054501662",
            "name": "A cluster-space visual interface for arbitrary dimensional classification of volume data",
            "year": 2004,
            "firstName": "Fan Yin Tzeng",
            "label": "Yin2004A",
            "isKeyPaper": 1.0,
            "citationCount": 60,
            "abstract": "In volume visualization, users typically specify transfer functions to classify the data and assign visual attributes to each material class. Higher-dimensional classification makes it easier to differentiate material classes since more data properties are considered. One of the difficulties in using higher-dimensional classification is the absence of appropriate user interfaces. We introduce an intuitive user interface that allows the user to work in the cluster space, which shows the material classes with a set of material widgets, rather than work in the transfer function space. This interface not only provides the user the capability to specify arbitrary-dimensional transfer functions, but also allows the user to operate directly on the classification and visualization results.",
            "topic": 81,
            "cx": 4224.45,
            "cy": -1534.71,
            "rx": 60.21,
            "ry": 26.74,
            "text1": "Yin2004A",
            "text2": "60"
        },
        {
            "id": "2170839387",
            "name": "Lighting Transfer Functions Using Gradient Aligned Sampling",
            "year": 2004,
            "firstName": "Eric B. Lum",
            "label": "B.2004Lighting",
            "isKeyPaper": 1.0,
            "citationCount": 78,
            "abstract": "An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.",
            "topic": 81,
            "cx": 4604.45,
            "cy": -1534.71,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2004Ligh...",
            "text2": "78"
        },
        {
            "id": "2131385811",
            "name": "Interactive multi-scale exploration for volume classification",
            "year": 2006,
            "firstName": "Eric B. Lum",
            "label": "B.2006Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 19,
            "abstract": "Filter banks are a class of signal processing techniques that can be used to reveal the local energy of a signal at multiple scales. Utilizing such filtering allows us to consider local texture and other data characteristics, and permits volume classification and visualization that cannot be accomplished easily using conventional, transfer function-based methods. Our filter bank approach increases the dimensionality, and thus, the complexity of the classification task. We have therefore developed an interactive user interface for specifying and visualizing these higher dimensional classifiers, which enables volume data exploration and visualization in a filter-bank space. We demonstrate that this technique is particularly effective for the classification of noisy data, and for classifying regions that are difficult to approach using conventional methods.",
            "topic": 7,
            "cx": 4712.45,
            "cy": -1355.23,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "B.2006Inte...",
            "text2": "19"
        },
        {
            "id": "2163363303",
            "name": "Size-based Transfer Functions A New Volume Exploration Technique",
            "year": 2008,
            "firstName": "Carlos D. Correa",
            "label": "D.2008Size-based",
            "isKeyPaper": 1.0,
            "citationCount": 135,
            "abstract": "The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.",
            "topic": 81,
            "cx": 4500.45,
            "cy": -1175.75,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "D.2008Size...",
            "text2": "135"
        },
        {
            "id": "2011060348",
            "name": "The Occlusion Spectrum for Volume Classification and Visualization",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009The",
            "isKeyPaper": 1.0,
            "citationCount": 72,
            "abstract": "Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.",
            "topic": 7,
            "cx": 4869.45,
            "cy": -1086.01,
            "rx": 66.44,
            "ry": 26.74,
            "text1": "D.2009The",
            "text2": "72"
        },
        {
            "id": "2138396059",
            "name": "Visibility-driven transfer functions",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009Visibility-driven",
            "isKeyPaper": 1.0,
            "citationCount": 44,
            "abstract": "Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the notion of visibility-driven transfer functions, which are transfer functions that provide a good visibility of features of interest from a given viewpoint. To achieve this, we introduce visibility histograms. These histograms provide graphical cues that intuitively inform the user about the contribution of particular scalar values to the final image. By carefully manipulating the parameters of the opacity transfer function, users can now maximize the visibility of the intervals of interest in a volume data set. Based on this observation, we also propose a semi-automated method for generating transfer functions, which progressively improves a transfer function defined by the user, according to a certain importance metric. Now the user does not have to deal with the tedious task of making small changes to the transfer function parameters, but now he/she can rely on the system to perform these searches automatically. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D opacity transfer functions based on scalar values, as well as with multidimensional transfer functions and other more sophisticated rendering algorithms.",
            "topic": 81,
            "cx": 4709.45,
            "cy": -1086.01,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "D.2009Visi...",
            "text2": "44"
        },
        {
            "id": "2188310855",
            "name": "for Volume Classification and Visualization",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009for",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "Fig. 1. Left: MRI of a meningionma. Transfer functions (TF) based on boundaries (insets on the left: top, 1D TF with gradient modulation, bottom, 2D TF of intensity vs. gradient magnitude) cannot separate the tumor from the vessels (where gradients are also strong). A transfer function based on occlusion separates the tumor from the vessels and the ventricular structures from skull and skin. Right: CT dataset with contrast agent. Classification is difficult due to overlap between bone and vessel structures (see red color in ribcage in the insets). An occlusion-based TF properly classifies bone and also highlights internal structures (blue). Abstractxe2x80x94Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge. In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.",
            "topic": 7,
            "cx": 4415.45,
            "cy": -1086.01,
            "rx": 62.45,
            "ry": 26.74,
            "text1": "D.2009for",
            "text2": "0"
        },
        {
            "id": "2029393506",
            "name": "Visibility Histograms and Visibility-Driven Transfer Functions",
            "year": 2011,
            "firstName": "Carlos D. Correa",
            "label": "D.2011Visibility",
            "isKeyPaper": 1.0,
            "citationCount": 75,
            "abstract": "Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the general notion of visibility histograms, which are multidimensional graphical representations of the distribution of visibility in a volume-rendered image. In this paper, we explore the 1D and 2D transfer functions that result from intensity values and gradient magnitude. With the help of these histograms, users can manage a complex set of transfer function parameters that maximize the visibility of the intervals of interest and provide high quality images of volume data. We present a semiautomated method for generating transfer functions, which progressively explores the transfer function space toward the goal of maximizing visibility of important structures. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D and 2D opacity transfer functions based on scalar values, as well as with other more sophisticated rendering algorithms.",
            "topic": 81,
            "cx": 4605.45,
            "cy": -906.53,
            "rx": 75.82,
            "ry": 26.74,
            "text1": "D.2011Visi...",
            "text2": "75"
        },
        {
            "id": "2964305288",
            "name": "Lighting Transfer Functions for Direct Volume Rendering",
            "year": 2004,
            "firstName": "Eric B. Lum",
            "label": "B.2004Lighting",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "Author(s): Lum, Eric; Ma, Kwan-Liu | Abstract: An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.",
            "topic": 81,
            "cx": 4782.45,
            "cy": -1534.71,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "B.2004Ligh...",
            "text2": "2"
        },
        {
            "id": "1541210462",
            "name": "A visualization methodology for characterization of network scans",
            "year": 2005,
            "firstName": "Christopher Wesley Muelder",
            "label": "Wesley2005A",
            "isKeyPaper": 1.0,
            "citationCount": 49,
            "abstract": "Many methods have been developed for monitoring network traffic, both using visualization and statistics. Most of these methods focus on the detection of suspicious or malicious activities. But what they often fail to do refine and exercise measures that contribute to the characterization of such activities and their sources, once they are detected. In particular, many tools exist that detect network scans or visualize them at a high level, but not very many tools exist that are capable of categorizing and analyzing network scans. This paper presents a means of facilitating the process of characterization by using visualization and statistics techniques to analyze the patterns found in the timing of network scans through a method of continuous improvement in measures that serve to separate the components of interest in the characterization so the user can control separately for the effects of attack tool employed, performance characteristics of the attack platform, and the effects of network routing in the arrival patterns of hostile probes. The end result is a system that allows large numbers of network scans to be rapidly compared and subsequently identified.",
            "topic": 29,
            "cx": 3817.45,
            "cy": -1444.97,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Wesley2005...",
            "text2": "49"
        },
        {
            "id": "2026867881",
            "name": "Guest Editors Introduction Visualization for Cybersecurity",
            "year": 2006,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2006Guest",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "The guest editor introduces this special issue. The five theme articles highlight the latest development and practice for visualization for cybersecurity.",
            "topic": 0,
            "cx": 3638.45,
            "cy": -1355.23,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Liu2006Gue...",
            "text2": "2"
        },
        {
            "id": "2182215430",
            "name": "Visualization for Cybersecurity",
            "year": 2006,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2006Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "etworked computers have become an integral part of our everyday life, used for a variety of purposes at home, in the workplace, and at schools. They are so ubiquitous and easy to access that they are also vulnerable. Any computer exposed to the Internet is likely to be regularly scanned and attacked by both automated and manual means. Both organizations and individuals are making every effort to build and maintain trustworthy computing systems. The main strategy is to closely monitor and inspect network activities by collecting and analyzing data about the network traffic and the trails of system usage. The analysis usually requires large amounts of finely detailed, high-dimensional data to enable analysts to uncover hidden threats and make calculated predictions in a timely fashion. The traditional, signature-based and statistical methods are limited in their capability to cope with the large, evolving data and the dynamic nature of the Internet.",
            "topic": 84,
            "cx": 3817.45,
            "cy": -1355.23,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2006Vis...",
            "text2": "1"
        },
        {
            "id": "2158598639",
            "name": "Content Based Graph Visualization of Audio Data for Music Library Navigation",
            "year": 2010,
            "firstName": "Chris Muelder",
            "label": "Muelder2010Content",
            "isKeyPaper": 1.0,
            "citationCount": 18,
            "abstract": "As a user's digital music collection grows, it can become difficult to navigate. Music library programs aid in this task by organizing music according to tags such as artist or title. However these generally utilize a text based interface, and they do not take into account the content of the music itself. As such, they do not handle untagged or mistagged music well. Automated metrics exist, but are not as widely used since they have the potential to be unreliable. This paper presents a graph-based visual interface for exploring a library of music based on analysis of the content of the music rather than tag information, which allows the user to navigate a music library thematically.",
            "topic": 28,
            "cx": 3921.45,
            "cy": -996.27,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muelder201...",
            "text2": "18"
        },
        {
            "id": "2144823948",
            "name": "End-to-End Study of Parallel Volume Rendering on the IBM Blue Gene/P",
            "year": 2009,
            "firstName": "Tom Peterka",
            "label": "Peterka2009End-to-End",
            "isKeyPaper": 1.0,
            "citationCount": 40,
            "abstract": "In addition to their role as simulation engines, modern supercomputers can be harnessed for scientific visualization. Their extensive concurrency, parallel storage systems, and high-performance interconnects can mitigate the expanding size and complexity of scientific datasets and prepare for in situ visualization of these data. In ongoing research into testing parallel volume rendering on the IBM Blue Gene/P (BG/P), we measure performance of disk I/O, rendering, and compositing on large datasets, and evaluate bottlenecks with respect to system-specific I/O and communication patterns. To extend the scalability of the direct-send image compositing stage of the volume rendering algorithm, we limit the number of compositing cores when many small messages are exchanged. To improve the data-loading stage of the volume renderer, we study the I/O signatures of the algorithm in detail. The results of this research affirm that a distributed-memory computing architecture such as BG/P is a scalable platform for large visualization problems.",
            "topic": 7,
            "cx": 1267.45,
            "cy": -1086.01,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Peterka200...",
            "text2": "40"
        },
        {
            "id": "2594098541",
            "name": "In situ generated probability distribution functions for interactive post hoc visualization and analysis",
            "year": 2016,
            "firstName": "Yucong Chris Ye",
            "label": "Chris2016In",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "The growing power and capacity of supercomputers enable scientific simulations at extreme scale, leading to not only more accurate modeling and greater predictive ability but also massive quantities of data to analyze. New approaches to data analysis and visualization are this needed to support interactive exploration through selective data access for gaining insights into terabytes and petabytes of data. In this paper, we present an in situ data processing method for both generating probability distribution functions (PDFs) from field data and reorganizing particle data using a single spatial organization scheme. This coupling between PDFs and particles allows for the interactive post hoc exploration of both data types simultaneously. Scientists can explore trends in large-scale data through the PDFs and subsequently extract desired particle subsets for further analysis. We evaluate the usability of our in situ method using a petascale combustion simulation and demonstrate the increases in task efficiency and accuracy that the resulting workflow provides to scientists.",
            "topic": 47,
            "cx": 2520.45,
            "cy": -457.83,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Chris2016I...",
            "text2": "7"
        },
        {
            "id": "2118780007",
            "name": "An intelligent system approach to higher-dimensional classification of volume data",
            "year": 2005,
            "firstName": "Fan Yin Tzeng",
            "label": "Yin2005An",
            "isKeyPaper": 1.0,
            "citationCount": 111,
            "abstract": "In volume data visualization, the classification step is used to determine voxel visibility and is usually carried out through the interactive editing of a transfer function that defines a mapping between voxel value and color/opacity. This approach is limited by the difficulties in working effectively in the transfer function space beyond two dimensions. We present a new approach to the volume classification problem which couples machine learning and a painting metaphor to allow more sophisticated classification in an intuitive manner. The user works in the volume data space by directly painting on sample slices of the volume and the painted voxels are used in an iterative training process. The trained system can then classify the entire volume. Both classification and rendering can be hardware accelerated, providing immediate visual feedback as painting progresses. Such an intelligent system approach enables the user to perform classification in a much higher dimensional space without explicitly specifying the mapping for every dimension used. Furthermore, the trained system for one data set may be reused to classify other data sets with similar characteristics.",
            "topic": 7,
            "cx": 4224.45,
            "cy": -1444.97,
            "rx": 66.44,
            "ry": 26.74,
            "text1": "Yin2005An",
            "text2": "111"
        },
        {
            "id": "2542252643",
            "name": "Information and Knowledge assisted analysis and Visualization of large-scale data",
            "year": 2008,
            "firstName": "Chaoli Wang",
            "label": "Wang2008Information",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "The ever-increasing sizes of data produced from a variety of scientific studies post a formidable challenge for the subsequent data analysis and visualization tasks. While steady advances in graphics hardware enable faster rendering, achieving interactive visualization of large data must also rely on effective data filtering and organization. In many cases, the best interactivity can only be obtained by taking into account the intrinsic properties of the data and domain knowledge to better reduce and organize the data for visualization. As a result, in recent years, we have seen increasing research and development efforts into the area of information and knowledge assisted visualization (IKV). In this paper, we survey research in IKV of scientific data and also identify a few directions for further work in this emerging area.",
            "topic": 0,
            "cx": 1965.45,
            "cy": -1175.75,
            "rx": 84.71,
            "ry": 26.74,
            "text1": "Wang2008In...",
            "text2": "4"
        },
        {
            "id": "2138422603",
            "name": "Interactive feature extraction and tracking by utilizing region coherency",
            "year": 2009,
            "firstName": "Chris Muelder",
            "label": "Muelder2009Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 33,
            "abstract": "The ability to extract and follow time-varying flow features in volume data generated from large-scale numerical simulations enables scientists to effectively see and validate modeled phenomena and processes. Extracted features often take much less storage space and computing resources to visualize. Most feature extraction and tracking methods first identify features of interest in each time step independently, then correspond these features in consecutive time steps of the data. Since these methods handle each time step separately, they do not use the coherency of the feature along the time dimension in the extraction process. In this paper, we present a prediction-correction method that uses a prediction step to make the best guess of the feature region in the subsequent time step, followed by growing and shrinking the border of the predicted region to coherently extract the actual feature of interest. This method makes use of the temporal-space coherency of the data to accelerate the extraction process while implicitly solving the tedious correspondence problem that previous methods focus on. Our method is low cost with very little storage overhead, and thus facilitates interactive or runtime extraction and visualization, unlike previous methods which were largely suited for batch-mode processing due to high computational cost.",
            "topic": 61,
            "cx": 1447.45,
            "cy": -1086.01,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muelder200...",
            "text2": "33"
        },
        {
            "id": "2169175194",
            "name": "Visualization and parallel I/O at extreme scale",
            "year": 2008,
            "firstName": "Robert Ross",
            "label": "Ross2008Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 24,
            "abstract": "In our efforts to solve ever more challenging problems through computational techniques, the scale of our compute systems continues to grow. As we approach petascale, it becomes increasingly important that all the resources in the system be used as efficiently as possible, not just the floating-point units. Because of hardware, software, and usability challenges, storage resources are often one of the most poorly used and performing components of today's compute systems. This situation can be especially true in the case of the analysis phases of scientific workflows. In this paper we discuss the impact of large-scale data on visual analysis operations and examine a collection of approaches to I/O in the visual analysis process. First we examine the performance of volume rendering on a leadership-computing platform and assess the relative cost of I/O, rendering, and compositing operations. Next we analyze the performance implications of eliminating preprocessing from this example workflow. Then we describe a technique that uses data reorganization to improve access times for data-intensive volume rendering.",
            "topic": 47,
            "cx": 1667.45,
            "cy": -1175.75,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Ross2008Vi...",
            "text2": "24"
        },
        {
            "id": "2000673357",
            "name": "Dax Toolkit A proposed framework for data analysis and visualization at Extreme Scale",
            "year": 2011,
            "firstName": "Kenneth Moreland",
            "label": "Moreland2011Dax",
            "isKeyPaper": 0.482288,
            "citationCount": 44,
            "abstract": "Experts agree that the exascale machine will comprise processors that contain many cores, which in turn will necessitate a much higher degree of concurrency. Software will require a minimum of a 1,000 times more concurrency. Most parallel analysis and visualization algorithms today work by partitioning data and running mostly serial algorithms concurrently on each data partition. Although this approach lends itself well to the concurrency of current high-performance computing, it does not exhibit the appropriate pervasive parallelism required for exascale computing. The data partitions are too small and the overhead of the threads is too large to make effective use of all the cores in an extreme-scale machine. This paper introduces a new visualization framework designed to exhibit the pervasive parallelism necessary for extreme scale machines. We demonstrate the use of this system on a GPU processor, which we feel is the best analog to an exascale node that we have available today.",
            "topic": 47,
            "cx": 1861.45,
            "cy": -906.53,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Moreland20...",
            "text2": "44"
        },
        {
            "id": "2047503975",
            "name": "Visualizing Flow of Uncertainty through Analytical Processes",
            "year": 2012,
            "firstName": "Yingcai Wu",
            "label": "Wu2012Visualizing",
            "isKeyPaper": 0.657124,
            "citationCount": 33,
            "abstract": "Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.",
            "topic": 14,
            "cx": 1895.45,
            "cy": -816.79,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Wu2012Visu...",
            "text2": "33"
        },
        {
            "id": "2293321482",
            "name": "Visualization Techniques for Studying Large-Scale Flow Fields from Fusion Simulations",
            "year": 2016,
            "firstName": "Franz Sauer",
            "label": "Sauer2016Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "This article presents a joint study between computer scientists and fusion scientists in developing visual tools for studying patterns in flow fields from large-scale magnetic confinement fusion simulations. The authors visualize time-varying flow data by generating trajectory curves via massless particle advection and design a set of color functions, pathline filters, and projection methods specific to achieve fusion research objectives. These tools aid scientists in managing the visual complexity of large trajectory datasets and are crucial in locating and understanding subtle features of interest. The authors demonstrate the effectiveness of their techniques by using real fusion simulation data and provide insight by domain scientists. They also discuss how their methods address common scalability concerns.",
            "topic": 12,
            "cx": 852.45,
            "cy": -457.83,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Sauer2016V...",
            "text2": "3"
        },
        {
            "id": "2032623256",
            "name": "Multiple Uncertainties in Time-Variant Cosmological Particle Data",
            "year": 2008,
            "firstName": "Steve Haroz",
            "label": "Haroz2008Multiple",
            "isKeyPaper": 1.0,
            "citationCount": 19,
            "abstract": "Though the mediums for visualization are limited, the potential dimensions of a dataset are not. In many areas of scientific study, understanding the correlations between those dimensions and their uncertainties is pivotal to mining useful information from a dataset. Obtaining this insight can necessitate visualizing the many relationships among temporal, spatial, and other dimensionalities of data and its uncertainties. We utilize multiple views for interactive dataset exploration and selection of important features, and we apply those techniques to the unique challenges of cosmological particle datasets. We show how interactivity and incorporation of multiple visualization techniques help overcome the problem of limited visualization dimensions and allow many types of uncertainty to be seen in correlation with other variables.",
            "topic": 14,
            "cx": 4979.45,
            "cy": -1175.75,
            "rx": 86.95,
            "ry": 26.74,
            "text1": "Haroz2008M...",
            "text2": "19"
        },
        {
            "id": "2345742246",
            "name": "An integrated visualization system for interactive analysis of large heterogeneous cosmology data",
            "year": 2016,
            "firstName": "Annie Preston",
            "label": "Preston2016An",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "Cosmological simulations produce a multitude of data types whose large scale makes them difficult to thoroughly explore in an interactive setting. One aspect of particular interest to scientists is the evolution of groups of dark matter particles, or halos, described by merger trees. However, in order to fully understand subtleties in the merger trees, other data types derived from the simulation must be incorporated as well. In this work, we develop a novel interactive linked-view visualization system that focuses on simultaneously exploring dark matter halos, their hierarchical evolution, corresponding particle data, and other quantitative information. We employ a parallel remote renderer and a local merger tree selection tool so that users can analyze large data sets interactively. This allows scientists to assess their simulation code, understand inconsistencies in extracted data, and intuitively understand simulation behavior on all scales. We demonstrate the effectiveness of our system through a set of case studies on large-scale cosmological data from the HACC (Hardware/Hybrid Accelerated Cosmology Code) simulation framework.",
            "topic": 0,
            "cx": 4979.45,
            "cy": -457.83,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Preston201...",
            "text2": "7"
        },
        {
            "id": "2040195604",
            "name": "StarGate A Unified Interactive Visualization of Software Projects",
            "year": 2008,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2008StarGate",
            "isKeyPaper": 1.0,
            "citationCount": 33,
            "abstract": "With the success of open source software projects, such as Apache and Mozilla, comes the opportunity to study the development process. In this paper, we present StarGate: a novel system for visualizing software projects. Whereas previous software project visualizations concentrated mainly on the source code changes, we literally place the developers in the center of our design. Developers are grouped visually into clusters corresponding to the areas of the file repository they work on the most. Connections are drawn between people who communicate via email. The changes to the repository are also displayed. With StarGate, it is easy to look beyond the source code and see trends in developer activity. The system can be used by anyone interested in the project, but it especially benefits project managers, project novices and software engineering researchers.",
            "topic": 2,
            "cx": 1041.45,
            "cy": -1175.75,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu2008Sta...",
            "text2": "33"
        },
        {
            "id": "2088064270",
            "name": "Parallel visualization on leadership computing resources",
            "year": 2009,
            "firstName": "Tom Peterka",
            "label": "Peterka2009Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Changes are needed in the way that visualization is performed, if we expect the analysis of scientific data to be effective at the petascale and beyond. By using similar techniques as those used to parallelize simulations, such as parallel I/O, load balancing, and effective use of interprocess communication, the supercomputers that compute these datasets can also serve as analysis and visualization engines for them. Our team is assessing the feasibility of performing parallel scientific visualization on some of the most powerful computational resources of the U.S. Department of Energy's National Laboratories in order to pave the way for analyzing the next generation of computational results. This paper highlights some of the conclusions of that research.",
            "topic": 19,
            "cx": 1754.45,
            "cy": -1086.01,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Peterka200...",
            "text2": "3"
        },
        {
            "id": "1965305253",
            "name": "A framework for uncertainty-aware visual analytics",
            "year": 2009,
            "firstName": "Carlos D. Correa",
            "label": "D.2009A",
            "isKeyPaper": 1.0,
            "citationCount": 78,
            "abstract": "Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.",
            "topic": 14,
            "cx": 1602.45,
            "cy": -1086.01,
            "rx": 54.39,
            "ry": 26.74,
            "text1": "D.2009A",
            "text2": "78"
        },
        {
            "id": "2027714334",
            "name": "Flow-based scatterplots for sensitivity analysis",
            "year": 2010,
            "firstName": "Yu Hsuan Chan",
            "label": "Hsuan2010Flow-based",
            "isKeyPaper": 1.0,
            "citationCount": 44,
            "abstract": "Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.",
            "topic": 8,
            "cx": 1559.45,
            "cy": -996.27,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Hsuan2010F...",
            "text2": "44"
        },
        {
            "id": "2070833402",
            "name": "Regression Cube A Technique for Multidimensional Visual Exploration and Interactive Pattern Finding",
            "year": 2014,
            "firstName": "Yu Hsuan Chan",
            "label": "Hsuan2014Regression",
            "isKeyPaper": 1.0,
            "citationCount": 8,
            "abstract": "Scatterplots are commonly used to visualize multidimensional data; however, 2D projections of data offer limited understanding of the high-dimensional interactions between data points. We introduce an interactive 3D extension of scatterplots called the Regression Cube (RC), which augments a 3D scatterplot with three facets on which the correlations between the two variables are revealed by sensitivity lines and sensitivity streamlines. The sensitivity visualization of local regression on the 2D projections provides insights about the shape of the data through its orientation and continuity cues. We also introduce a series of visual operations such as clustering, brushing, and selection supported in RC. By iteratively refining the selection of data points of interest, RC is able to reveal salient local correlation patterns that may otherwise remain hidden with a global analysis. We have demonstrated our system with two examples and a user-oriented evaluation, and we show how RCs enable interactive visual exploration of multidimensional datasets via a variety of classification and information retrieval tasks. A video demo of RC is available.",
            "topic": 8,
            "cx": 1600.45,
            "cy": -637.31,
            "rx": 86.03,
            "ry": 26.74,
            "text1": "Hsuan2014R...",
            "text2": "8"
        },
        {
            "id": "2041380214",
            "name": "A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation",
            "year": 2013,
            "firstName": "Wei Hsien Hsu",
            "label": "Hsien2013A",
            "isKeyPaper": 1.0,
            "citationCount": 9,
            "abstract": "We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.",
            "topic": 7,
            "cx": 3515.45,
            "cy": -727.05,
            "rx": 73.58,
            "ry": 26.74,
            "text1": "Hsien2013A",
            "text2": "9"
        },
        {
            "id": "2046832287",
            "name": "Visibility guided multimodal volume visualization",
            "year": 2013,
            "firstName": "Lin Zheng",
            "label": "Zheng2013Visibility",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "With the advances in dual medical imaging, the requirements for multimodal and multifield volume visualization begin to emerge. One of the challenges in multimodal visualization is how to simplify the process of generating informative pictures from complementary data. In this paper we present an automatic technique that makes use of dual modality information, such as CT and PET, to produce effective focuscontext volume visualization. With volume ray casting, per-ray visibility histograms summarize the contribution of samples along each ray to the final image. By quantifying visibility for the region of interest, indicated by the PET data, occluding tissues can be made just transparent enough to give a clear view of the features in that region while preserving some context. Unlike most previous methods relying on costly-preprocessing and tedious manual tuning, our technique achieves comparable and better results based on on-the-fly processing that still enables interactive visualization. Our work thus offers a powerful visualization technique for examining multimodal volume data. We demonstrate the technique with scenarios for the detection and diagnosis of cancer and other pathologies.",
            "topic": 7,
            "cx": 4829.45,
            "cy": -727.05,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Zheng2013V...",
            "text2": "1"
        },
        {
            "id": "2294608516",
            "name": "Visual Analysis of Cloud Computing Performance Using Behavioral Lines",
            "year": 2016,
            "firstName": "Chris Muelder",
            "label": "Muelder2016Visual",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Cloud computing is an essential technology to Big Data analytics and services. A cloud computing system is often comprised of a large number of parallel computing and storage devices. Monitoring the usage and performance of such a system is important for efficient operations, maintenance, and security. Tracing every application on a large cloud system is untenable due to scale and privacy issues. But profile data can be collected relatively efficiently by regularly sampling the state of the system, including properties such as CPU load, memory usage, network usage, and others, creating a set of multivariate time series for each system. Adequate tools for studying such large-scale, multidimensional data are lacking. In this paper, we present a visual based analysis approach to understanding and analyzing the performance and behavior of cloud computing systems. Our design is based on similarity measures and a layout method to portray the behavior of each compute node over time. When visualizing a large number of behavioral lines together, distinct patterns often appear suggesting particular types of performance bottleneck. The resulting system provides multiple linked views, which allow the user to interactively explore the data by examining the data or a selected subset at different levels of detail. Our case studies, which use datasets collected from two different cloud systems, show that this visual based approach is effective in identifying trends and anomalies of the systems.",
            "topic": 73,
            "cx": 631.45,
            "cy": -457.83,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muelder201...",
            "text2": "13"
        },
        {
            "id": "2760106839",
            "name": "Visual Analytics Techniques for Exploring the Design Space of Large-Scale High-Radix Networks",
            "year": 2017,
            "firstName": "Jianping Kelvin Li",
            "label": "Kelvin2017Visual",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "High-radix, low-diameter, hierarchical networks based on the Dragonfly topology are common picks for building next generation HPC systems. However, effective tools are lacking for analyzing the network performance and exploring the design choices for such emerging networks at scale. In this paper, we present visual analytics methods that couple data aggregation techniques with interactive visualizations for analyzing large-scale Dragonfly networks. We create an interactive visual analytics system based on these techniques. To facilitate effective analysis and exploration of network behaviors, our system provides intuitive, scalable visualizations that can be customized to show various traffic characteristics and correlate between different performance metrics. Using high-fidelity network simulation and HPC applications communication traces, we demonstrate the usefulness of our system with several case studies on exploring network behaviors at scale with different workloads, routing strategies, and job placement policies. Our simulations and visualizations provide valuable insights for mitigating network congestion and inter-job interference.",
            "topic": 84,
            "cx": 848.45,
            "cy": -368.09,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kelvin2017...",
            "text2": "4"
        },
        {
            "id": "1457609601",
            "name": "Scalable parallel feature extraction and tracking for large time-varying 3D volume data",
            "year": 2013,
            "firstName": "Yang Wang",
            "label": "Wang2013Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 9,
            "abstract": "Large-scale time-varying volume data sets can take terabytes to petabytes of storage space to store and process. One promising approach is to process the data in parallel, and then extract and analyze only features of interest, reducing required memory space by several orders of magnitude for following visualization tasks. However, extracting volume features in parallel is a non-trivial task as features might span over multiple processors, and local partial features are only visible within their own processors. In this paper, we discuss how to generate and maintain connectivity information of features across different processors. Based on the connectivity information, partial features can be integrated, which makes it possible to extract and track features for large data in parallel. We demonstrate the effectiveness and scalability of our approach using two data sets with up to 16384 processors.",
            "topic": 64,
            "cx": 1371.45,
            "cy": -727.05,
            "rx": 86.95,
            "ry": 26.74,
            "text1": "Wang2013Sc...",
            "text2": "9"
        },
        {
            "id": "2141005805",
            "name": "In Situ Visualization at Extreme Scale Challenges and Opportunities",
            "year": 2009,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2009In",
            "isKeyPaper": 1.0,
            "citationCount": 99,
            "abstract": "In situ visualization is clearly a promising solution for ultrascale simulations. We've seen some success in realizing this solution and in ongoing efforts to add support for in situ visualization to open source visualization toolkits such as ParaView and Visit. However, for others to adopt this approach, we need further research and experimental studies to derive a set of guidelines and usable visualization software components. If this research is successful, it will lead to a new visualization and data-understanding infrastructure, potentially change how scientists work, and accelerate scientific discovery. This paper discusses critical issues in realizing in situ visualization and suggest important research directions.",
            "topic": 47,
            "cx": 2467.45,
            "cy": -1086.01,
            "rx": 62.87,
            "ry": 26.74,
            "text1": "Liu2009In",
            "text2": "99"
        },
        {
            "id": "1964937799",
            "name": "A new approach to remote visualization of large volume data",
            "year": 2010,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2010A",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "",
            "topic": 7,
            "cx": 3570.45,
            "cy": -996.27,
            "rx": 60.21,
            "ry": 26.74,
            "text1": "Liu2010A",
            "text2": "3"
        },
        {
            "id": "2023029656",
            "name": "Scientific Storytelling Using Visualization",
            "year": 2012,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2012Scientific",
            "isKeyPaper": 1.0,
            "citationCount": 63,
            "abstract": "Scientists frequently tell stories using visualizations of scientific data, in the process of disseminating findings to peers and the general public. However, techniques and methods for effective scientific storytelling have received little attention so far. This article explores how literary and theatrical narrative conventions can inform the design and presentation of visualizations, and discusses the challenges of adapting scientific visualizations for broader audiences. It also summarizes recent workshops' findings on the role of storytelling in visualizations, and presents several examples of successful scientific-storytelling production teams. The conclusion is that scientific storytelling deserves greater support and recognition by the visualization community.",
            "topic": 53,
            "cx": 3294.45,
            "cy": -816.79,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Liu2012Sci...",
            "text2": "63"
        },
        {
            "id": "2113470734",
            "name": "Storytelling via Navigation A Novel Approach to Animation for Scientific Visualization",
            "year": 2014,
            "firstName": "Isaac H. Liao",
            "label": "H.2014Storytelling",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "In scientific visualization, volume rendering is commonly used to show three-dimensional, time-varying data sets. To understand the spatial structure of volume data sets and how they change over time, animation is often necessary. Most current visualization tools use conventional keyframe-based interfaces to create animations, which can be tedious and time-consuming. We present a new, semi-automatic approach to creating animations of volume data based on a userxe2x80x99s interaction history as they navigate through a data set and adjust rendering parameters. Through a user study, we show that this new method requires significantly less time and perceived effort on the part of users compared to keyframe-based approaches, while still generating animations of comparable quality.",
            "topic": 65,
            "cx": 3482.45,
            "cy": -637.31,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "H.2014Stor...",
            "text2": "4"
        },
        {
            "id": "2046125873",
            "name": "Distance visualization of ultrascale data with explorable images",
            "year": 2010,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2010Distance",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "This talk presents a new approach to distance visualization of very large data sets output from scientific supercomputing. The processing power of massively parallel supercomputers increases at a rather fast rate, about an order of magnitude faster every three years, enabling scientists to model complex physical phenomena and chemical processes at unprecedented fidelity. Several petascale computers are already in operation (http://www.top500.org) and exascale computing is around the corner. Each run of a petascale simulation typically outputs several hundred terabytes of data to disk. Transferring data at this scale over wide-area networks to the scientist's laboratory for post-processing analysis is not an option. Even the data files may be transferred, existing desktop data analysis and visualization tools cannot effectively handle such large-scale data. If the scientists may use the same supercomputing facility for data analysis and visualization, there are three viable solutions: xe2x80xa2 in situ visualization, where visualization is computed during the simulation on the same supercomputer, xe2x80xa2 co-processing visualization, where visualization is computed during the simulation on a separate computer, and xe2x80xa2 post-processing visualization, where visualization is computed after simulation is over.",
            "topic": 47,
            "cx": 2879.45,
            "cy": -996.27,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Liu2010Dis...",
            "text2": "1"
        },
        {
            "id": "2070002217",
            "name": "A sketch-based interface for classifying and visualizing vector fields",
            "year": 2010,
            "firstName": "Jishang Wei",
            "label": "Wei2010A",
            "isKeyPaper": 1.0,
            "citationCount": 34,
            "abstract": "In flow visualization, field lines are often used to convey both global and local structure and movement of the flow. One challenge is to find and classify the representative field lines. Most existing solutions follow an automatic approach that generates field lines characterizing the flow and arranges these lines into a single picture. In our work, we advocate a user-centric approach to exploring 3D vector fields. Our method allows the user to sketch 2D curves for pattern matching in 2D and field lines clustering in 3D. Specifically, a 3D field line whose view-dependent 2D projection is most similar to the user drawing will be identified and utilized to extract all similar 3D field lines. Furthermore, we employ an automatic clustering method to generate field-line templates for the user to locate subfields of interest. This semi-automatic process leverages the user's knowledge about the flow field through intuitive user interaction, resulting in a promising alternative to existing flow visualization solutions. With our sketch-based interface, the user can effectively dissect the flow field and make more structured visualization for analysis or presentation.",
            "topic": 27,
            "cx": 1109.45,
            "cy": -996.27,
            "rx": 62.87,
            "ry": 26.74,
            "text1": "Wei2010A",
            "text2": "34"
        },
        {
            "id": "2077122434",
            "name": "Parallel clustering for visualizing large scientific line data",
            "year": 2011,
            "firstName": "Jishang Wei",
            "label": "Wei2011Parallel",
            "isKeyPaper": 1.0,
            "citationCount": 13,
            "abstract": "Scientists often need to extract, visualize and analyze lines from vast amounts of data to understand dynamic structures and interactions. The effectiveness of such a visual validation and analysis process mainly relies on a good strategy to categorize and visualize the lines. However, the sheer size of line data produced by state-of-the-art scientific simulations poses great challenges to preparing the data for visualization. In this paper, we present a parallelization design of regression model-based clustering to categorize large line data derived from detailed scientific simulations by leveraging the power of heterogeneous computers. This parallel clustering method employs the Expectation Maximization algorithm to iteratively approximate the optimal data partitioning. First, we use a sorted-balance algorithm to partition and distribute the lines with various lengths among multiple compute nodes. During the following iterative clustering process, regression model parameters are recovered based on the local lines on each individual node, with only a few inter-node message exchanges involved. Meanwhile, the workload of regression model computing is well balanced across the nodes. The experimental results demonstrate that our approach can effectively categorize large line data in a scalable manner to concisely convey dynamic structures and interactions, leading to a visualization that captures salient features and suppresses visual clutter to facilitate scientific exploration of large line data.",
            "topic": 53,
            "cx": 1109.45,
            "cy": -906.53,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Wei2011Par...",
            "text2": "13"
        },
        {
            "id": "2591193418",
            "name": "Spatio-Temporal Feature Exploration in Combined Particle/Volume Reference Frames",
            "year": 2017,
            "firstName": "Franz Sauer",
            "label": "Sauer2017Spatio-Temporal",
            "isKeyPaper": 1.0,
            "citationCount": 4,
            "abstract": "The use of large-scale scientific simulations that can represent physical systems using both particle and volume data simultaneously is gaining popularity as each of these reference frames has an inherent set of advantages when studying different phenomena. Furthermore, being able to study the dynamic evolution of these time varying data types is an integral part of nearly all scientific endeavors. However, the techniques available to scientists generally limit them to studying each reference frame separately making it difficult to draw connections between the two. In this work we present a novel method of feature exploration that can be used to investigate spatio-temporal patterns in both data types simultaneously. More specifically, we focus on how spatio-temporal subsets can be identified from both reference frames, and develop new ways of visually presenting the embedded information to a user in an intuitive manner. We demonstrate the effectiveness of our method using case studies of real world scientific datasets and illustrate the new types of exploration and analyses that can be achieved through this technique.",
            "topic": 68,
            "cx": 1027.45,
            "cy": -368.09,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Sauer2017S...",
            "text2": "4"
        },
        {
            "id": "2102136719",
            "name": "Explorable images for visualizing volume data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010Explorable",
            "isKeyPaper": 1.0,
            "citationCount": 22,
            "abstract": "We present a technique which automatically converts a small number of single-view volume rendered images of the same 3D data set into a compact representation of that data set. This representation is a multi-layered image, or an explorable image, which enables interactive exploration of volume data in transfer function space without accessing the original data. We achieve this by automatically extracting layers depicted in composited images. The layers can then be recombined in different ways to simulate opacity changes and recoloring of individual features. Our results demonstrate that explorable images are especially useful when the volume data is too large for interactive exploration, takes too long to render due to the underlying mesh structure or desired shading effect, or if the original volume data is not available. Explorable images can offer real-time image-based interaction as a preview mechanism for remote visualization or visualization of large volume data on low-end hardware, within a mobile device, or a Web browser.",
            "topic": 7,
            "cx": 2703.45,
            "cy": -996.27,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "22"
        },
        {
            "id": "2151882909",
            "name": "Visualization by Proxy A Novel Framework for Deferred Interaction with Volume Data",
            "year": 2010,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2010Visualization",
            "isKeyPaper": 1.0,
            "citationCount": 42,
            "abstract": "Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.",
            "topic": 7,
            "cx": 3055.45,
            "cy": -996.27,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "42"
        },
        {
            "id": "1996388339",
            "name": "A preview and exploratory technique for large-scale scientific simulations",
            "year": 2011,
            "firstName": "Anna Tikhonova",
            "label": "Tikhonova2011A",
            "isKeyPaper": 1.0,
            "citationCount": 18,
            "abstract": "Successful in-situ and remote visualization solutions must have minimal storage requirements and account for only a small percentage of supercomputing time. One solution that meets these requirements is to store a compact intermediate representation of the data, instead of a 3D volume itself. Recent work explores the use of attenuation functions as a data representation that summarizes the distribution of attenuation along the rays. This representation goes beyond conventional static images and allows users to dynamically explore their data, for example, to change color and opacity parameters, without accessing the original 3D data. The computation and storage costs of this method may still be prohibitively expensive for large and time-varying data sets, thus limiting its applicability in the real-world scenarios. In this paper, we present an efficient algorithm for computing attenuation functions in parallel. We exploit the fact that the distribution of attenuation can be constructed recursively from a hierarchy of blocks or intervals of the data, which is a highly parallelizeable process. We have developed a library of routines that can be used in a distance visualization scenario or can be called directly from a simulation code to generate explorable images in-situ. Through a number of examples, we demonstrate the application of this work to large-scale scientific simulations in a real-world parallel environment with thousands of processors. We also explore various compression methods for reducing the size of the RAF. Finally, we present a method for computing an alternative RAF representation, which more closely encodes the actual distribution of samples along a ray, using kernel density estimation.",
            "topic": 47,
            "cx": 2616.45,
            "cy": -906.53,
            "rx": 79.39,
            "ry": 26.74,
            "text1": "Tikhonova2...",
            "text2": "18"
        },
        {
            "id": "1983184648",
            "name": "Out-of-core visualization of time-varying hybrid-grid volume data",
            "year": 2014,
            "firstName": "Min Shih",
            "label": "Shih2014Out-of-core",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Traditional computational fluid dynamics (CFD) solvers are usually written for a single gridding paradigm such as structured-Cartesian, structured-body-fitted, or unstructured grids. Each type of mesh paradigms has inherent advantages and disadvantages. Thus, the methods of coupling multiple mesh paradigms have been developed to facilitate the use of different solvers in different part of the computational domain. However, the complex hybrid gridding paradigm poses challenges to rendering calculations for visualizing the data. This paper describes a volume visualization system for time-varying adaptive moving-body CFD datasets, where the grid system consists of unstructured grids near the body surface, coupled with Structured Adaptive Mesh Refinement (SAMR) grid in the off-body domain. We present two approaches to the hybrid-grid volume ray casting: a KD-tree based single-pass algorithm, and a multi-pass algorithm using the depth peeling technique. The system has a three-level memory hierarchy: GPU memory, main memory, and a solid state drive (SSD). Through data caching and prefetching within the memory hierarchy, the latency of time-step swapping can be hidden. Experimental results show that our system allows interactive volume exploration on single-GPU commodity PCs.",
            "topic": 46,
            "cx": 2289.45,
            "cy": -637.31,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Shih2014Ou...",
            "text2": "3"
        },
        {
            "id": "188549894",
            "name": "Advanced visualization techniques for abstract graphs and computer networks",
            "year": 2011,
            "firstName": "Kwan Liu Ma",
            "label": "Liu2011Advanced",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "Network structures are prevalent in many disciplines. Analysis of these networks can lead to many kinds of domain-specific insights. Many networks contain static information, but some are constantly evolving making analysis hard. Even datasets that are not naturally networks can be transformed into networks which can reveal interesting patterns. And some networks have relatively simple structures, but have underlying temporal activity that can be difficult to analyze through traditional methods. This dissertation research presents new methods for time and space efficient visualization of traditional and time varying networks, methods for transforming sets of time-series data into networks that can be analyzed through these methods, and methods for visualizing the temporal activity of complex yet topologically static networks.",
            "topic": 84,
            "cx": 469.45,
            "cy": -906.53,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Liu2011Adv...",
            "text2": "2"
        },
        {
            "id": "2524731154",
            "name": "Improved Cluster Tracking for Visualization of Large Dynamic Graphs",
            "year": 2013,
            "firstName": "Chris Muelder",
            "label": "Muelder2013Improved",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "Analysis and visualization of dynamic graphs is a challenging problem. Clustering can be applied to dynamic graphs in order to generate interactive visualizations with both high stability and good layout quality. However, the existing implementation is naive and unoptimized. Here we present new algorithms to improve both the temporal clustering results and the efficiency of the cluster tracking calculation, and evaluate the results and performance.",
            "topic": 10,
            "cx": 169.45,
            "cy": -727.05,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Muelder201...",
            "text2": "0"
        },
        {
            "id": "2124654985",
            "name": "Perceptually-Based Depth-Ordering Enhancement for Direct Volume Rendering",
            "year": 2013,
            "firstName": "Lin Zheng",
            "label": "Zheng2013Perceptually-Based",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "Visualizing complex volume data usually renders selected parts of the volume semitransparently to see inner structures of the volume or provide a context. This presents a challenge for volume rendering methods to produce images with unambiguous depth-ordering perception. Existing methods use visual cues such as halos and shadows to enhance depth perception. Along with other limitations, these methods introduce redundant information and require additional overhead. This paper presents a new approach to enhancing depth-ordering perception of volume rendered images without using additional visual cues. We set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception as well as the faithfulness of the information revealed. Guided by the function, we use a conjugate gradient method to iteratively and judiciously enhance the results. Our method can complement existing systems for enhancing volume rendering results. The experimental results demonstrate the usefulness and effectiveness of our approach.",
            "topic": 7,
            "cx": 4605.45,
            "cy": -727.05,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Zheng2013P...",
            "text2": "20"
        },
        {
            "id": "2020814412",
            "name": "Visual Analysis of Particle Behaviors to Understand Combustion Simulations",
            "year": 2012,
            "firstName": "Jishang Wei",
            "label": "Wei2012Visual",
            "isKeyPaper": 1.0,
            "citationCount": 11,
            "abstract": "Simulations of turbulent flames have used particles to capture the dynamic behavior of combustion in next-generation engines. Each particle includes a history of its movement positions and changing thermochemical states. Analyzing such a set of many millions of particles helps scientists understand turbulence. A dual-space method enables effective visual analysis of both the spatial movement and attribute evolution of particles. A cluster-label-classify strategy categorizes particles' attribute evolution curves. Intuitive tools integrate users' domain knowledge to steer the classification. The dual-space method has been used to analyze particle data in combustion simulations and can be applied to other scientific simulations involving particle-data analysis. This video shows an expository movie that combustion scientists have used when discussing their simulation results with colleagues. This simulation employs visual analysis in both the physical space and phase space, with categorization driven by supervised learning.",
            "topic": 75,
            "cx": 1109.45,
            "cy": -816.79,
            "rx": 80.72,
            "ry": 26.74,
            "text1": "Wei2012Vis...",
            "text2": "11"
        },
        {
            "id": "2133623148",
            "name": "A Comparison of Gradient Estimation Methods for Volume Rendering on Unstructured Meshes",
            "year": 2011,
            "firstName": "Carlos D. Correa",
            "label": "D.2011A",
            "isKeyPaper": 1.0,
            "citationCount": 30,
            "abstract": "This paper presents a study of gradient estimation methods for rendering unstructured-mesh volume data. Gradient estimation is necessary for rendering shaded isosurfaces and specular highlights, which provide important cues for shape and depth. Gradient estimation has been widely studied and deployed for regular-grid volume data to achieve local illumination effects, but has been, otherwise, for unstructured-mesh data. As a result, most of the unstructured-mesh volume visualizations made so far were unlit. In this paper, we present a comprehensive study of gradient estimation methods for unstructured meshes with respect to their cost and performance. Through a number of benchmarks, we discuss the effects of mesh quality and scalar function complexity in the accuracy of the reconstruction, and their impact in lighting-enabled volume rendering. Based on our study, we also propose two heuristic improvements to the gradient reconstruction process. The first heuristic improves the rendering quality with a hybrid algorithm that combines the results of the multiple reconstruction methods, based on the properties of a given mesh. The second heuristic improves the efficiency of its GPU implementation, by restricting the computation of the gradient on a fixed-size local neighborhood.",
            "topic": 7,
            "cx": 2464.45,
            "cy": -906.53,
            "rx": 54.39,
            "ry": 26.74,
            "text1": "D.2011A",
            "text2": "30"
        },
        {
            "id": "1601538659",
            "name": "Advanced lighting for unstructured-grid data visualization",
            "year": 2015,
            "firstName": "Min Shih",
            "label": "Shih2015Advanced",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "The benefits of using advanced illumination models in volume visualization have been demonstrated by many researchers. Interactive volume rendering incorporated with advanced lighting has been achieved with GPU acceleration for regular-grid volume data, making volume visualization even more appealing as a tool for 3D data exploration. This paper presents an interactive illumination strategy, which is specially designed and optimized for volume visualization of unstructured-grid data. The basis of the design is a partial differential equation based illumination model to simulate the light propagation, absorption, and scattering within the volumetric medium. In particular, a two-level scheme is introduced to overcome the challenges presented by unstructured grids. Test results show that the added illumination effects such as global shadowing and multiple scattering not only lead to more visually pleasing visualization, but also greatly enhance the perception of the depth information and complex spatial relationships for features of interest in the volume data. This volume visualization enhancement is introduced at a time when unstructured grids are becoming increasingly popular for a variety of scientific simulation applications.",
            "topic": 7,
            "cx": 2752.45,
            "cy": -547.57,
            "rx": 82.96,
            "ry": 26.74,
            "text1": "Shih2015Ad...",
            "text2": "1"
        },
        {
            "id": "2007546607",
            "name": "Design Considerations for Optimizing Storyline Visualizations",
            "year": 2012,
            "firstName": "Yuzuru Tanahashi",
            "label": "Tanahashi2012Design",
            "isKeyPaper": 1.0,
            "citationCount": 97,
            "abstract": "Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's xe2x80x9cMovie Narrative Chartsxe2x80x9d [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.",
            "topic": 58,
            "cx": 424.45,
            "cy": -816.79,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Tanahashi2...",
            "text2": "97"
        },
        {
            "id": "1976035129",
            "name": "A Study on Enhancing Timeline-Like Visualization with Verbal Text",
            "year": 2013,
            "firstName": "Jia Kai Chou",
            "label": "Kai2013A",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "There has been a long-standing question of whether sound or audio annotations may assist in data visualization tasks. This paper presents our study focusing on enhancing timeline/storyline like visualizations with audio annotations. Timeline visualizations are widely used to illustrate interactions among different entities over time. This type of visualizations facilitate reviewing important activities and their associations. For a long timeline, however, it is difficult for the viewer to remember all the essential information found in the visualization process. Since hearing is another primary human sense for perceiving information, we conjecture that adding audio annotations to selected sections of a timeline visualization can help improve the viewer's recall of important events. We have designed a user study based on augmenting storyline visualizations with verbal text, and tested subjects with three different settings: visual cues only, verbal text only, and both. While our test results do not give a strong indication of the clear advantage of adding verbal text, the lessons learned in our study suggest directions for further study and will help us and others design audio-augmented visualization systems.",
            "topic": 45,
            "cx": 424.45,
            "cy": -727.05,
            "rx": 60.62,
            "ry": 26.74,
            "text1": "Kai2013A",
            "text2": "1"
        },
        {
            "id": "2022893238",
            "name": "An Efficient Framework for Generating Storyline Visualizations from Streaming Data",
            "year": 2015,
            "firstName": "Yuzuru Tanahashi",
            "label": "Tanahashi2015An",
            "isKeyPaper": 1.0,
            "citationCount": 31,
            "abstract": "This paper presents a novel framework for applying storyline visualizations to streaming data. The framework includes three components: a new data management scheme for processing and storing the incoming data, a layout construction algorithm specifically designed for incrementally generating storylines from streaming data, and a layout refinement algorithm for improving the legibility of the visualization. By dividing the layout computation to two separate components, one for constructing and another for refining, our framework effectively provides the users with the ability to follow and reason dynamic data. The evaluation studies of our storyline visualization framework demonstrate its efficacy to present streaming data as well as its superior performance over existing methods in terms of both computational efficiency and visual clarity.",
            "topic": 92,
            "cx": 212.45,
            "cy": -547.57,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Tanahashi2...",
            "text2": "31"
        },
        {
            "id": "2545930194",
            "name": "A study on designing effective introductory materials for information visualization",
            "year": 2016,
            "firstName": "Yuzuru Tanahashi",
            "label": "Tanahashi2016A",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "Designing introductory materials is extremely important when developing new information visualization techniques. All users, regardless of their domain knowledge, first must learn how to interpret the visually encoded information in order to infer knowledge from visualizations. Yet, despite its significance, there has been little research on how to design effective introductory materials for information visualization. This paper presents a study on the design of online guides that educate new users on how to utilize information visualizations, particularly focusing on the employment of exercise questions in the guides. We use two concepts from educational psychology, learning type (or learning style) and teaching method, to design four unique types of online guides. The effects of the guides are measured by comprehension tests of a large group of crowdsourced participants. The tests covered four visualization types (graph, scatter plot, storyline, and tree map) and a complete range of visual analytics tasks. Our statistical analyses indicate that online guides which employ active learning and the top-down teaching method are the most effective. Our study provides quantitative insight into the use of exercise questions in online guides for information visualizations and will inspire further research on design considerations for other elements in introductory materials.",
            "topic": 6,
            "cx": 318.45,
            "cy": -457.83,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Tanahashi2...",
            "text2": "6"
        },
        {
            "id": "2509421351",
            "name": "Temporal Summary Images An Approach to Narrative Visualization via Interactive Annotation Generation and Placement",
            "year": 2017,
            "firstName": "Chris Bryan",
            "label": "Bryan2017Temporal",
            "isKeyPaper": 1.0,
            "citationCount": 26,
            "abstract": "Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.",
            "topic": 68,
            "cx": 1458.45,
            "cy": -368.09,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Bryan2017T...",
            "text2": "26"
        },
        {
            "id": "1990559478",
            "name": "Living Liquid Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors",
            "year": 2012,
            "firstName": "Joyce Ma",
            "label": "Ma2012Living",
            "isKeyPaper": 1.0,
            "citationCount": 29,
            "abstract": "Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.",
            "topic": 53,
            "cx": 743.45,
            "cy": -816.79,
            "rx": 81.13,
            "ry": 26.74,
            "text1": "Ma2012Livi...",
            "text2": "29"
        },
        {
            "id": "2005063628",
            "name": "Stock Lamp An Engagement-Versatile Visualization Design",
            "year": 2015,
            "firstName": "Yuzuru Tanahashi",
            "label": "Tanahashi2015Stock",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "Design methodologies for information visualizations are typically based on the assumption that the users will be fully engaged in the visual exploration of the displayed information. However, recent research suggests that there is an increasing diversity in how users engage with modern visualizations, and that the traditional design theories do not always satisfy the varied users needs. In this paper, we present a new design concept, engagement-versatile design, for visualizations that target users with a variety of engagement styles. Without losing generality, we demonstrate the feasibility of this concept through the designing of a system called Stock Lamp, an engagement-versatile visualization that helps users keep track of the stock market in real-time. This design process includes identifying different modes of engagement, deriving design implications from each engagement-mode, and applying them to the visualization's design. Our user study shows that Stock Lamp is able to consistently relay market information even when the users are multi-tasking. We believe this study establishes a new concept that promotes a systematic design approach that leverages both theoretical and empirical design methodologies for future visualization development.",
            "topic": 6,
            "cx": 424.45,
            "cy": -547.57,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Tanahashi2...",
            "text2": "6"
        },
        {
            "id": "2544125743",
            "name": "Audience-Targeted Design Considerations for Effective Scientific Storytelling",
            "year": 2016,
            "firstName": "Franz Sauer",
            "label": "Sauer2016Audience-Targeted",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "An effective visualization must be carefully designed according to its purpose. This article describes three projects focused on scientific storytelling in a different domain area and for a different target audience. The authors describe the lessons learned working in each scientific field and the techniques used to tailor the visual narrative to a specific audience type. The three projects are a visualization of particle accelerator data designed for domain scientists, a presentation of new findings from the fusion community designed for nonexpert adults, and an interactive exhibit of phytoplankton populations tailored toward museum visitors, especially children. Special design decisions had to be made to handle the unique conditions of each scientific area as well as the given background knowledge of the target audience. By evaluating the effectiveness of each of method, the authors gain insight into which aspects become important in developing a visualization with maximum usability.",
            "topic": 53,
            "cx": 3264.45,
            "cy": -457.83,
            "rx": 83.38,
            "ry": 26.74,
            "text1": "Sauer2016A...",
            "text2": "1"
        },
        {
            "id": "2969331663",
            "name": "Decoding a Complex Visualization in a Science Museum \u00e2\u20ac\u201c An Empirical Study",
            "year": 2020,
            "firstName": "Joyce Ma",
            "label": "Ma2020Decoding",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "This study describes a detailed analysis of museum visitors' decoding process as they used a visualization designed to support exploration of a large, complex dataset. Quantitative and qualitative analyses revealed that it took, on average, 43 seconds for visitors to decode enough of the visualization to see patterns and relationships in the underlying data represented, and 54 seconds to arrive at their first correct data interpretation. Furthermore, visitors decoded throughout and not only upon initial use of the visualization. The study analyzed think-aloud data to identify issues visitors had mapping the visual representations to their intended referents, examine why they occurred, and consider if and how these decoding issues were resolved. The paper also describes how multiple visual encodings both helped and hindered decoding and concludes with implications on the design and adaptation of visualizations for informal science learning venues.",
            "topic": 53,
            "cx": 742.45,
            "cy": -98.87,
            "rx": 87.86,
            "ry": 26.74,
            "text1": "Ma2020Deco...",
            "text2": "0"
        },
        {
            "id": "2971723077",
            "name": "Cluster-Based Visualization for Merger Tree Data The Challenge of Missing Expectations",
            "year": 2018,
            "firstName": "Annie Preston",
            "label": "Preston2018Cluster-Based",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "Scientific simulations are yielding increasing amounts of data; to visualize the full output from a simulation, one must first reduce clutter and obstruction. Clustering algorithms are common tools for condensing information and decreasing clutter when analyzing and visualizing simulation output. Often, simulation data have intuitive groupings. In some cases, though, such as merger trees from N-body dark matter simulations, there are limited expectations for clustering results. We investigate cluster-based visualization design for merger tree data, testing whether multidimensional encodings and opening the black box can allow for meaningful representation and exploration of these data.",
            "topic": 82,
            "cx": 1138.45,
            "cy": -278.35,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Preston201...",
            "text2": "0"
        },
        {
            "id": "3004294313",
            "name": "A User-Centered Design Study in Scientific Visualization Targeting Domain Experts",
            "year": 2020,
            "firstName": "Yucong Chris Ye",
            "label": "Chris2020A",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "The development of usable visualization solutions is essential for ensuring both their adoption and effectiveness. User-centered design principles, which involve users throughout the entire development process, have been shown to be effective in numerous information visualization endeavors. We describe how we applied these principles in scientific visualization over a two year collaboration to develop a hybrid in situ/post hoc solution tailored towards combustion researcher needs. Furthermore, we examine the importance of user-centered design and lessons learned over the design process in an effort to aid others seeking to develop effective scientific visualization solutions.",
            "topic": 53,
            "cx": 3011.45,
            "cy": -98.87,
            "rx": 71.34,
            "ry": 26.74,
            "text1": "Chris2020A",
            "text2": "0"
        },
        {
            "id": "2216435688",
            "name": "Revealing the fog-of-war A visualization-directed uncertainty-aware approach for exploring high-dimensional data",
            "year": 2015,
            "firstName": "Yang Wang",
            "label": "Wang2015Revealing",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Dimensionality Reduction (DR) is a crucial tool to facilitate high-dimensional data analysis. As the volume and the variety of features used to describe a phenomenon keeps increasing, DR has become not only desirable but paramount. However, DR can result in unreliable depictions of data. The uncertainties involved in DR may stem from the selection of methods, parameter configurations, and the constraints imposed by the user. To address these uncertainties, various means of DR quality assessment have been proposed in the literature. Nevertheless, how to optimize the trade-off between the quantification efficiency and accuracy is yet to be further studied. The purpose of this paper is to present a general technique, in the context of visual analytics, to support efficient uncertainty-aware high-dimensional data exploration. We model the uncertainty based on how well neighborhood geometries are preserved during DR. We employ approximated nearest neighbor (ANN) search algorithms to speed up the quantification process with marginal decrease in accuracy. We then visualize the quantified uncertainties in the form of augmented scatter plot. We test our technique with three real world datasets against several well-known DR techniques, and discuss possible underlying causes that lead to certain embedding patterns. Our results show that our approach is effective and beneficial for both DR assessment and user-centered data exploration.",
            "topic": 14,
            "cx": 1893.45,
            "cy": -547.57,
            "rx": 88.28,
            "ry": 26.74,
            "text1": "Wang2015Re...",
            "text2": "3"
        },
        {
            "id": "2949117914",
            "name": "Visual Analysis of Simulation Uncertainty Using Cost-Effective Sampling",
            "year": 2018,
            "firstName": "Annie Preston",
            "label": "Preston2018Visual",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "Studying large, complex simulations entails understanding their uncertainties. However, visualization tools that rapidly quantify simulation uncertainty may require precise tuning, give limited information, or struggle to disentangle uncertainty sources. We propose a fast, scalable regression-based approach that uses bootstrapping on small samples of simulation data to model the effect of uncertainty from discreteness. We test the approach on three types of simulations with unique sources of uncertainty: particles (dark matter), ensembles (ocean), and discretized flows (traffic). We create a visualization tool to facilitate this modeling, showing training data and predictions in real time. Scientists, who need to provide only modest supervision, can use our tool to quickly understand how initial conditions and parameterizations affect observable quantities, their uncertainties, and their agreement with experimental data. We show that our tool offers a speedup of several orders of magnitude over comparable uncertainty calculation approaches.",
            "topic": 14,
            "cx": 1777.45,
            "cy": -278.35,
            "rx": 79.81,
            "ry": 26.74,
            "text1": "Preston201...",
            "text2": "0"
        },
        {
            "id": "2007142861",
            "name": "Fast global illumination for interactive volume visualization",
            "year": 2013,
            "firstName": "Yubo Zhang",
            "label": "Zhang2013Fast",
            "isKeyPaper": 1.0,
            "citationCount": 20,
            "abstract": "High quality global illumination can enhance the visual perception of depth cue and local thickness of volumetric data but it is seldom used in scientific visualization because of its high computational cost. This paper presents a novel grid-based illumination technique which is specially designed and optimized for volume visualization purpose. It supports common light sources and dynamic transfer function editing. Our method models light propagation, including both absorption and scattering, in a volume using a convection-diffusion equation that can be solved numerically. The main advantage of such technique is that the light modeling and simulation can be separated, where we can use a unified partial-differential equation to model various illumination effects, and adopt highly-parallelized grid-based numerical schemes to solve it. Results show that our method can achieve high quality volume illumination with dynamic color and opacity mapping and various light sources in real-time. The added illumination effects can greatly enhance the visual perception of spatial structures of volume data.",
            "topic": 7,
            "cx": 3179.45,
            "cy": -727.05,
            "rx": 84.29,
            "ry": 26.74,
            "text1": "Zhang2013F...",
            "text2": "20"
        },
        {
            "id": "2091956487",
            "name": "Using global illumination in volume visualization of rheumatoid arthritis CT data",
            "year": 2014,
            "firstName": "Lin Zheng",
            "label": "Zheng2014Using",
            "isKeyPaper": 1.0,
            "citationCount": 8,
            "abstract": "Proper lighting in rendering is essential for visualizing 3D objects, but most visualization software tools still employ simple lighting models. The advent of hardware-accelerated advanced lighting suggests that volume visualization can be truly usable for clinical work. Researchers studied how volume rendering incorporating global illumination impacted perception of bone surface features captured by x-ray computed-tomography scanners for clinical monitoring of rheumatoid arthritis patients. The results, evaluated by clinical researchers familiar with the disease and medical-image interpretation, indicate that interactive visualization with global illumination helped the researchers derive more accurate interpretations of the image data. With clinical needs and the recent advancement of volume visualization technology, this study is timely and points the way for further research.",
            "topic": 7,
            "cx": 3159.45,
            "cy": -637.31,
            "rx": 86.03,
            "ry": 26.74,
            "text1": "Zheng2014U...",
            "text2": "8"
        },
        {
            "id": "2940673288",
            "name": "TalkTraces Real-Time Capture and Visualization of Verbal Content in Meetings",
            "year": 2019,
            "firstName": "Senthil Chandrasegaran",
            "label": "Chandrasegaran2019TalkTraces",
            "isKeyPaper": 0.882353,
            "citationCount": 3,
            "abstract": "Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute the discussion relatedness to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content.",
            "topic": 15,
            "cx": 424.45,
            "cy": -188.61,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Chandraseg...",
            "text2": "3"
        },
        {
            "id": "2943863288",
            "name": "An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data",
            "year": 2020,
            "firstName": "Takanori Fujiwara",
            "label": "Fujiwara2020An",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer's mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.",
            "topic": 8,
            "cx": 212.45,
            "cy": -98.87,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Fujiwara20...",
            "text2": "7"
        },
        {
            "id": "2187671748",
            "name": "Scalable visualization of discrete velocity decompositions using spatially organized histograms",
            "year": 2015,
            "firstName": "Tyson Neuroth",
            "label": "Neuroth2015Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "Visualizing the velocity decomposition of a group of objects has applications to many studied data types, such as Lagrangian-based flow data or geospatial movement data. Traditional visualization techniques are often subject to a trade-off between visual clutter and loss of detail, especially in a large scale setting. The use of 2D velocity histograms can alleviate these issues. While they have been used throughout domain specific areas on a basic level, there has been very little work in the visualization community on leveraging them to perform more advanced visualization tasks. In this work, we develop an interactive system which utilizes velocity histograms to visualize the velocity decomposition of a group of objects. In addition, we extend our tool to utilize two schemes for histogram generation: an on-the-fly sampling scheme as well as an in situ scheme to maintain interactivity in extreme scale applications.",
            "topic": 75,
            "cx": 2935.45,
            "cy": -547.57,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Neuroth201...",
            "text2": "6"
        },
        {
            "id": "2561922343",
            "name": "Scalable Visualization of Time-varying Multi-parameter Distributions Using Spatially Organized Histograms",
            "year": 2017,
            "firstName": "Tyson Neuroth",
            "label": "Neuroth2017Scalable",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Visualizing distributions from data samples as well as spatial and temporal trends of multiple variables is fundamental to analyzing the output of todayxe2x80x99s scientific simulations. However, traditional visualization techniques are often subject to a trade-off between visual clutter and loss of detail, especially in a large-scale setting. In this work, we extend the use of spatially organized histograms into a sophisticated visualization system that can more effectively study trends between multiple variables throughout a spatial domain. Furthermore, we exploit the use of isosurfaces to visualize time-varying trends found within histogram distributions. This technique is adapted into both an on-the-fly scheme as well as an in situ scheme to maintain real-time interactivity at a variety of data scales.",
            "topic": 15,
            "cx": 2935.45,
            "cy": -368.09,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Neuroth201...",
            "text2": "3"
        },
        {
            "id": "2558750989",
            "name": "Privacy preserving event sequence data visualization using a Sankey diagram-like representation",
            "year": 2016,
            "firstName": "Jia Kai Chou",
            "label": "Kai2016Privacy",
            "isKeyPaper": 1.0,
            "citationCount": 10,
            "abstract": "Given the growing rates and richness of data being collected nowadays, it is non-trivial for data owners to determine a single best publishing granularity that presents the most value of the data while preserving its privacy. There have been extensive studies on privacy preserving algorithms in the data mining community, but relatively few have been done to provide a supervised control over the anonymization process. We present the design and evaluation of a visual interface that assists users to employ commonly used data anonymization techniques for making privacy preserving visualizations of the data. We focus on event sequence data due to its vulnerability to privacy concerns. Our visual interface is designed for data owners to examine potential privacy issues, obfuscate information as suggested by the algorithm, and fine-tune the results per their requests. Case studies using multiple datasets under different scenarios demonstrate the effectiveness of our design. These studies show that using visualization as an interface can help identify potential privacy issues, reveal underlying anonymization processes, and allow users to balance between data utility and privacy.",
            "topic": 15,
            "cx": 5155.45,
            "cy": -457.83,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2016Pri...",
            "text2": "10"
        },
        {
            "id": "2754406527",
            "name": "Privacy preserving visualization for social network data with ontology information",
            "year": 2017,
            "firstName": "Jia Kai Chou",
            "label": "Kai2017Privacy",
            "isKeyPaper": 1.0,
            "citationCount": 7,
            "abstract": "Analyzing social network data helps sociologists understand the behaviors of individuals and groups as well as the relationships between them. With additional ontology information, the semantics behind the network structure can be further explored. Unfortunately, creating network visualizations with these datasets for presentation can inadvertently expose the private and sensitive information of individuals that reside in the data. To deal with this problem, we generalize conventional data anonymization models (originally designed for relational data) and formally apply them in the context of privacy preserving ontological network visualization. We use these models to identify the privacy leaks that exist in a visualization, provide graph modification actions that remove and/or perceptually minimize the effect of the identified leaks, and discuss strategies for what types of privacy actions to choose depending on the context of the leaks. We implement an ontological visualization interface with associated privacy preserving operations, and demonstrate with two case studies using real-world datasets to show that our approach can identify and solve potential privacy issues while balancing overall graph readability and utility.",
            "topic": 58,
            "cx": 5102.45,
            "cy": -368.09,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2017Pri...",
            "text2": "7"
        },
        {
            "id": "2889118017",
            "name": "Privacy Preserving Visualization A Study on Event Sequence Data",
            "year": 2019,
            "firstName": "Jia Kai Chou",
            "label": "Kai2019Privacy",
            "isKeyPaper": 1.0,
            "citationCount": 2,
            "abstract": "",
            "topic": 15,
            "cx": 5189.45,
            "cy": -188.61,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kai2019Pri...",
            "text2": "2"
        },
        {
            "id": "2964458439",
            "name": "Interactive Spatiotemporal Visualization of Phase Space Particle Trajectories Using Distance Plots",
            "year": 2019,
            "firstName": "Tyson Neuroth",
            "label": "Neuroth2019Interactive",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "The distance plot (or unthresholded recurrence plot) has been shown to be a useful tool for analyzing spatiotemporal patterns in high-dimensional phase space trajectories. We incorporate this technique into an interactive visualization with multiple linked phase plots, and extend the distance plot to also visualize marker particle weights from particle-in-cell (PIC) simulations together with the phase space trajectories. By linking the distance plot with phase plots, one can more easily investigate the spatiotemporal patterns, and by extending the plot to visualize particle weights in conjunction with the phase space trajectories, the visualization better supports the needs of domain experts studying particle-in-cell simulations. We demonstrate our resulting visualization design using particles from an XGC Tokamak fusion simulation.",
            "topic": 16,
            "cx": 2935.45,
            "cy": -188.61,
            "rx": 82.05,
            "ry": 26.74,
            "text1": "Neuroth201...",
            "text2": "0"
        },
        {
            "id": "2944385809",
            "name": "An Empirical Study on Perceptually Masking Privacy in Graph Visualizations",
            "year": 2018,
            "firstName": "Jia Kai Chou",
            "label": "Kai2018An",
            "isKeyPaper": 1.0,
            "citationCount": 1,
            "abstract": "Researchers such as sociologists create visualizations of multivariate node-link diagrams to present findings about the relationships in communities. Unfortunately, such visualizations can inadvertently expose the ostensibly private identities of the persons that make up the dataset. By purposely violating graph readability metrics for a small region of the graph, we conjecture that local, exposed privacy leaks may be perceptually masked from easy recognition. In particular, we consider three commonly known metricsxe2x80x94edge crossing, node clustering, and node-edge overlappingxe2x80x94as a strategy to hide leaks. We evaluate the effectiveness of violating these metrics by conducting a user study that measures subject performance at visually searching for and identifying a privacy leak. Results show that when more masking operations are applied, participants needed more time to locate the privacy leak, though exhaustive, brute force search can eventually find it. We suggest future directions on how perceptual masking can be a viable strategy, primarily where modifying the underlying network structure is unfeasible.",
            "topic": 10,
            "cx": 5075.45,
            "cy": -278.35,
            "rx": 67.35,
            "ry": 26.74,
            "text1": "Kai2018An",
            "text2": "1"
        },
        {
            "id": "2891789817",
            "name": "P4 Portable Parallel Processing Pipelines for Interactive Information Visualization",
            "year": 2020,
            "firstName": "Jianping Kelvin Li",
            "label": "Kelvin2020P4",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "We present P4, an information visualization toolkit that combines declarative design specification and GPU computing for building high-performance interactive systems. Most of the existing information visualization toolkits do not harness the power of parallel processors in today's mainstream computers. P4 leverages GPU computing to accelerate both data processing and visualization rendering for interactive visualization applications. P4's programming interface offers a declarative visualization grammar for rapid specifications of data transformations, visual encodings, and interactions. By simplifying the development of GPU-accelerated visualization systems while supporting a high degree of flexibility and customization for design specification, P4 narrows the gap between expressiveness and scalability in information visualization toolkits. Through a range of examples and benchmark tests, we demonstrate that P4 provides high efficiency for creating interactive visualizations and offers drastic performance improvement over current state-of-the-art toolkits.",
            "topic": 19,
            "cx": 925.45,
            "cy": -98.87,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kelvin2020...",
            "text2": "3"
        },
        {
            "id": "2751731070",
            "name": "What Would a Graph Look Like in this Layout A Machine Learning Approach to Large Graph Visualization",
            "year": 2018,
            "firstName": "Oh Hyun Kwon",
            "label": "Hyun2018What",
            "isKeyPaper": 1.0,
            "citationCount": 16,
            "abstract": "Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a xe2x80x9cgoodxe2x80x9d layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.",
            "topic": 10,
            "cx": 5327.45,
            "cy": -278.35,
            "rx": 90.52,
            "ry": 26.74,
            "text1": "Hyun2018Wh...",
            "text2": "16"
        },
        {
            "id": "2941265453",
            "name": "A Deep Generative Model for Graph Layout",
            "year": 2020,
            "firstName": "Oh Hyun Kwon",
            "label": "Hyun2020A",
            "isKeyPaper": 1.0,
            "citationCount": 3,
            "abstract": "Different layouts can characterize different aspects of the same graph. Finding a xe2x80x9cgoodxe2x80x9d layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.",
            "topic": 10,
            "cx": 5327.45,
            "cy": -98.87,
            "rx": 71.34,
            "ry": 26.74,
            "text1": "Hyun2020A",
            "text2": "3"
        },
        {
            "id": "2969683715",
            "name": "P5 Portable Progressive Parallel Processing Pipelines for Interactive Data Analysis and Visualization",
            "year": 2020,
            "firstName": "Jianping Kelvin Li",
            "label": "Kelvin2020P5",
            "isKeyPaper": 1.0,
            "citationCount": 0,
            "abstract": "We present P5, a web-based visualization toolkit that combines declarative visualization grammar and GPU computing for progressive data analysis and visualization. To interactively analyze and explore big data, progressive analytics and visualization methods have recently emerged. Progressive visualizations of incrementally refining results have the advantages of allowing users to steer the analysis process and make early decisions. P5 leverages declarative grammar for specifying visualization designs and exploits GPU computing to accelerate progressive data processing and rendering. The declarative specifications can be modified during progressive processing to create different visualizations for analyzing the intermediate results. To enable user interactions for progressive data analysis, P5 utilizes the GPU to automatically aggregate and index data based on declarative interaction specifications to facilitate effective interactive visualization. We demonstrate the effectiveness and usefulness of P5 through a variety of example applications and several performance benchmark tests.",
            "topic": 19,
            "cx": 1099.45,
            "cy": -98.87,
            "rx": 77.56,
            "ry": 26.74,
            "text1": "Kelvin2020...",
            "text2": "0"
        },
        {
            "id": "2943864384",
            "name": "Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning",
            "year": 2020,
            "firstName": "Takanori Fujiwara",
            "label": "Fujiwara2020Supporting",
            "isKeyPaper": 1.0,
            "citationCount": 6,
            "abstract": "Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good first glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster's characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature's relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters' feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.",
            "topic": 82,
            "cx": 387.45,
            "cy": -98.87,
            "rx": 78.48,
            "ry": 26.74,
            "text1": "Fujiwara20...",
            "text2": "6"
        }
    ],
    [
        {
            "source": "1991",
            "target": "1992",
            "d": "M34.45,-2647.52C34.45,-2632.16 34.45,-2609.84 34.45,-2594.47"
        },
        {
            "source": "33641593",
            "target": "2160946550",
            "d": "M358.45,-2638.53C358.45,-2630.56 358.45,-2621.67 358.45,-2613.18",
            "citation_context": null
        },
        {
            "source": "1992",
            "target": "1993",
            "d": "M34.45,-2557.78C34.45,-2542.42 34.45,-2520.1 34.45,-2504.73"
        },
        {
            "source": "2160946550",
            "target": "2138311740",
            "d": "M333.47,-2550.2C323.82,-2540.58 312.65,-2529.46 302.43,-2519.26",
            "citation_context": null
        },
        {
            "source": "2160946550",
            "target": "2120835680",
            "d": "M383.43,-2550.2C393.08,-2540.58 404.24,-2529.46 414.46,-2519.26",
            "citation_context": null
        },
        {
            "source": "1993",
            "target": "1994",
            "d": "M34.45,-2468.26C34.45,-2455.13 34.45,-2437.09 34.45,-2423.89"
        },
        {
            "source": "2120835680",
            "target": "2118947032",
            "d": "M446.45,-2459.35C446.45,-2432.9 446.45,-2391.69 446.45,-2362.01",
            "citation_context": "Darmofal and Hairnes [2], Ma and Smith [ 7 ], and Pargendarm [9] use one streamline and vectors normal to the local velocity to form a streamribbon.In [ 7 ], to visualize both flow convection and diffusion, stat,istical dispersion of the fluid element,s about a streamline is computed by using added scalar information about the root mea,n square value for the vector field and it,s Lara.ngian time scale."
        },
        {
            "source": "2120835680",
            "target": "2040639571",
            "d": "M422.3,-2460.77C399.52,-2435.68 366.9,-2394.44 353.45,-2351.5 346.31,-2328.71 347.23,-2320.82 353.45,-2297.76 356.02,-2288.23 360.46,-2278.66 365.36,-2269.99",
            "citation_context": null
        },
        {
            "source": "2120835680",
            "target": "2138516914",
            "d": "M477.65,-2461.39C510.79,-2432.94 558.45,-2382.2 558.45,-2325.63 558.45,-2325.63 558.45,-2325.63 558.45,-1085.01 558.45,-1036.26 431.13,-967.58 356.77,-931.62",
            "citation_context": null
        },
        {
            "source": "1994",
            "target": "1995",
            "d": "M34.45,-2387.39C34.45,-2374.26 34.45,-2356.22 34.45,-2343.02"
        },
        {
            "source": "1995",
            "target": "1996",
            "d": "M34.45,-2306.3C34.45,-2290.94 34.45,-2268.62 34.45,-2253.25"
        },
        {
            "source": "2118947032",
            "target": "2040639571",
            "d": "M429.96,-2298.25C424.22,-2289.42 417.69,-2279.36 411.56,-2269.94",
            "citation_context": null
        },
        {
            "source": "1996",
            "target": "1997",
            "d": "M34.45,-2216.56C34.45,-2201.2 34.45,-2178.88 34.45,-2163.51"
        },
        {
            "source": "1567533377",
            "target": "2166470747",
            "d": "M2158.85,-2208.67C2109.58,-2148.33 1984.86,-1995.6 1929.57,-1927.88",
            "citation_context": "Rowlan [22] and Ma [ 14 ] independently demonstrated runtime tracking of three-dimensional numerical simulations using direct volume rendering on a massively parallel computer."
        },
        {
            "source": "1567533377",
            "target": "2039138386",
            "d": "M2184.19,-2208C2189.82,-2174.99 2198.45,-2116.1 2198.45,-2065.28 2198.45,-2065.28 2198.45,-2065.28 2198.45,-1982.41 2198.45,-1930.34 2189.2,-1910.55 2217.45,-1866.8 2226.68,-1852.5 2240.52,-1840.73 2254.71,-1831.44",
            "citation_context": null
        },
        {
            "source": "1567533377",
            "target": "2096945381",
            "d": "M2174.7,-2208C2169.07,-2174.99 2160.45,-2116.1 2160.45,-2065.28 2160.45,-2065.28 2160.45,-2065.28 2160.45,-1443.97 2160.45,-1303.4 1955.65,-1272.83 1834.84,-1267.02",
            "citation_context": null
        },
        {
            "source": "1567533377",
            "target": "2182470571",
            "d": "M2261.8,-2231.91C2658.85,-2221.82 4356.45,-2172.4 4356.45,-2065.28 4356.45,-2065.28 4356.45,-2065.28 4356.45,-1264.49 4356.45,-720.65 3727.77,-1001.88 3207.45,-843.66 3147.2,-825.34 2768.15,-642.88 2626.64,-574.38",
            "citation_context": null
        },
        {
            "source": "2040639571",
            "target": "2136917153",
            "d": "M396.51,-2207.83C404.81,-2174.89 417.45,-2116.32 417.45,-2065.28 417.45,-2065.28 417.45,-2065.28 417.45,-1892.67 417.45,-1843.13 428.22,-1786.75 436.41,-1751.08",
            "citation_context": "Additional work has been done for efficient computation and rendering of streamribbons and streamtubes [28]."
        },
        {
            "source": "2040639571",
            "target": "2138516914",
            "d": "M356.49,-2209.93C320.05,-2180.38 266.45,-2126.52 266.45,-2065.28 266.45,-2065.28 266.45,-2065.28 266.45,-1085.01 266.45,-1034.97 281.07,-978.7 292.18,-943.2",
            "citation_context": null
        },
        {
            "source": "1997",
            "target": "1998",
            "d": "M34.45,-2127.04C34.45,-2113.91 34.45,-2095.87 34.45,-2082.67"
        },
        {
            "source": "1991484114",
            "target": "2136730689",
            "d": "M918.45,-2118.14C918.45,-2086.53 918.45,-2031.56 918.45,-1984.41 918.45,-1984.41 918.45,-1984.41 918.45,-1533.71 918.45,-1328.97 1200.48,-1229.94 1338.78,-1193.68",
            "citation_context": "The direct send approach is easiest to understand; each process requests the sub-images from all of those processes that have something to contribute to it [17], [18], [19]."
        },
        {
            "source": "1998",
            "target": "1999",
            "d": "M34.45,-2046.17C34.45,-2033.04 34.45,-2015 34.45,-2001.8"
        },
        {
            "source": "1999",
            "target": "2000",
            "d": "M34.45,-1965.08C34.45,-1949.72 34.45,-1927.4 34.45,-1912.03"
        },
        {
            "source": "2018246367",
            "target": "1982953486",
            "d": "M3302.24,-1958.2C3315.61,-1947.35 3331.46,-1934.47 3345.39,-1923.15",
            "citation_context": "The image graph system [12] was designed with visualization data exploration in mind, and thus satisfies the criteria we presented."
        },
        {
            "source": "2018246367",
            "target": "2090746914",
            "d": "M3335.57,-1966.22C3394.44,-1951.11 3482.15,-1928.61 3543.43,-1912.89",
            "citation_context": null
        },
        {
            "source": "2018246367",
            "target": "2154046714",
            "d": "M3272.45,-1956.22C3272.45,-1925.73 3272.45,-1875.18 3272.45,-1840.98",
            "citation_context": "Two interfaces of this type are the Design Galleries system [6] and image graphs [7]."
        },
        {
            "source": "2018246367",
            "target": "2143275883",
            "d": "M3221.82,-1962.26C3191.53,-1950.18 3152.27,-1934.51 3117.45,-1920.54 2919.53,-1841.13 2868.48,-1825.03 2672.45,-1741.06 2669.05,-1739.61 2665.55,-1738.08 2662.04,-1736.53",
            "citation_context": "The fourth type of interface presented here is the Image Graph [21]."
        },
        {
            "source": "2018246367",
            "target": "2114265882",
            "d": "M3190.61,-1981.05C2990.07,-1975.49 2490.45,-1947.37 2490.45,-1804.93 2490.45,-1804.93 2490.45,-1804.93 2490.45,-1443.97 2490.45,-1387.99 2504.66,-1371.41 2540.45,-1328.36 2553.32,-1312.87 2571.04,-1299.71 2587.49,-1289.56",
            "citation_context": "Visualization Space Paths: Several novel visualization user interfaces [6], [7], [8], [9] assume visualization exploration is equivalent to navigating a multidimensional parameter space."
        },
        {
            "source": "2018246367",
            "target": "2146955194",
            "d": "M3343.05,-1969.63C3375.74,-1960.62 3413.08,-1945.54 3439.45,-1920.54 3480.07,-1882.03 3489.45,-1860.91 3489.45,-1804.93 3489.45,-1804.93 3489.45,-1804.93 3489.45,-1354.23 3489.45,-1301.38 3516.93,-1245.59 3537.7,-1210.98",
            "citation_context": "For instance, Design Gallery [14] and Image Graphs [15] are two such interfaces."
        },
        {
            "source": "2018246367",
            "target": "2150064314",
            "d": "M3253.4,-1956.93C3216.73,-1904.52 3143.74,-1781.67 3188.45,-1687.32 3199.27,-1664.49 3215.89,-1670.41 3232.45,-1651.32 3271.82,-1605.96 3302.45,-1595.78 3302.45,-1535.71 3302.45,-1535.71 3302.45,-1535.71 3302.45,-1174.75 3302.45,-1116.47 3346.01,-1061.56 3378.55,-1028.67",
            "citation_context": "Many [3, 6, 7, 8] have realized the concept of visualization by examples."
        },
        {
            "source": "2092430905",
            "target": "2115314149",
            "d": "M1330.16,-1956.45C1348.82,-1893.61 1396.46,-1733.16 1417.81,-1661.26",
            "citation_context": "Ma and Crockett [16] demonstrate a highly efficient, cell-projection volume rendering algorithm using up to 512 T3E processors for rendering 18 millions tetrahedral elements from an aerodynamic flow simulation."
        },
        {
            "source": "2092430905",
            "target": "115809921",
            "d": "M1256.6,-1968.5C1228.43,-1959.34 1197.48,-1944.46 1177.45,-1920.54 1090.98,-1817.34 1084.79,-1646.07 1086.61,-1571.85",
            "citation_context": "Ma and Crockett ( 13 ) demonstrate a highly efficient, cell-projection volume rendering algorithm using up to 512 T3E processors for rendering 18 millions tetrahedral elements from an aerodynamic flow simulation."
        },
        {
            "source": "2092430905",
            "target": "1556372880",
            "d": "M1322.45,-1956.25C1322.45,-1921.63 1322.45,-1858.7 1322.45,-1804.93 1322.45,-1804.93 1322.45,-1804.93 1322.45,-1713.19 1322.45,-1661.12 1323.26,-1646.37 1341.45,-1597.58 1345.05,-1587.93 1350.22,-1578.13 1355.6,-1569.26",
            "citation_context": "Ma and Crockett [ MC99 ] demonstrate a highly efficient, cellprojection volume rendering algorithm using up to 512 T3E processors for rendering 18 millions tetrahedral elements from an aerodynamic flow simulation."
        },
        {
            "source": "2092430905",
            "target": "2162126826",
            "d": "M1339.54,-1957.18C1375.68,-1903.04 1460.98,-1770.91 1515.45,-1651.32 1527.37,-1625.15 1538.12,-1594.43 1545.62,-1571.23",
            "citation_context": "Ma and Crockett [20] demonstrate a highly efficient, cell-projection volume rendering algorithm using up to 512 T3E processors for rendering 18 million tetrahedral elements from an aerodynamic flow simulation."
        },
        {
            "source": "2092430905",
            "target": "2010314815",
            "d": "M1275.12,-1961.62C1258.52,-1951.74 1241.72,-1938.16 1232.45,-1920.54 1155.06,-1773.43 1211.33,-1563.73 1238.75,-1481.23",
            "citation_context": null
        },
        {
            "source": "2092430905",
            "target": "2148775223",
            "d": "M1353.51,-1958.43C1366.96,-1947.47 1382.54,-1933.95 1395.45,-1920.54 1542.36,-1767.9 1689.47,-1560.02 1744.66,-1479.62",
            "citation_context": "SC|05 November 12-18, 2005, Seattle, Washington, USA (c) 2005 ACM 1-59593-061-2/05/0011 $5.00 Several parallel visualization solutions are available for this large data problem [1, 12,  13 , 14, 28, 29]"
        },
        {
            "source": "2092430905",
            "target": "2188498653",
            "d": "M1312.86,-1956.56C1286.69,-1881.4 1221.51,-1658.69 1306.45,-1507.84 1344.9,-1439.55 1427.91,-1398.48 1487.75,-1376.65",
            "citation_context": "Our test on a Cray T3E using up to 512 processors to render an aerodynamic data set consisting of 18 million tetrahedral elements shows this renderer achieves above 75% parallel efficiency [ 4 ]."
        },
        {
            "source": "2116283033",
            "target": "2115314149",
            "d": "M1084.81,-1957.88C1149.85,-1894.96 1322.56,-1727.88 1395.36,-1657.46",
            "citation_context": "A similar approach is also used for the rendering of AMR data [12]."
        },
        {
            "source": "2116283033",
            "target": "2136730689",
            "d": "M1045.89,-1956.75C1029.32,-1922.94 1003.45,-1861.15 1003.45,-1804.93 1003.45,-1804.93 1003.45,-1804.93 1003.45,-1623.45 1003.45,-1571.38 994.93,-1552.05 1022.45,-1507.84 1073.24,-1426.22 1125.04,-1444.18 1198.45,-1382.1 1267.43,-1323.76 1276.35,-1300.22 1342.45,-1238.62 1353.53,-1228.3 1365.88,-1217.34 1377.14,-1207.57",
            "citation_context": "In the future we will also begin to study how this research can be extended to encompass adaptive mesh refined (AMR) time-varying datasets [29], [30]."
        },
        {
            "source": "2000",
            "target": "2001",
            "d": "M34.45,-1875.34C34.45,-1859.98 34.45,-1837.66 34.45,-1822.29"
        },
        {
            "source": "27528377",
            "target": "2039138386",
            "d": "M2311.85,-1866.35C2311.67,-1858.38 2311.46,-1849.49 2311.27,-1841",
            "citation_context": "Ma and Shen [11] discuss how nonuniform quantization along with octree and difference encoding can be employed to speed up rendering of timevarying volume data."
        },
        {
            "source": "1982953486",
            "target": "2090746914",
            "d": "M3430.72,-1893.67C3462.56,-1893.67 3494.4,-1893.67 3526.24,-1893.67",
            "citation_context": null
        },
        {
            "source": "1982953486",
            "target": "2154046714",
            "d": "M3353.47,-1870.76C3340.19,-1859.97 3323.96,-1846.78 3309.53,-1835.06",
            "citation_context": "These issues were addressed by our spreadsheet-like interface described in [16]."
        },
        {
            "source": "1982953486",
            "target": "2150064314",
            "d": "M3397.27,-1868.05C3418.27,-1834.88 3451.45,-1773.27 3451.45,-1715.19 3451.45,-1715.19 3451.45,-1715.19 3451.45,-1354.23 3451.45,-1236.16 3430.64,-1097.35 3419.82,-1033.16",
            "citation_context": "[4, 5] introduce a spreadsheet-like interface for volume visualization; through this interface, the user can search for ideal visualizations by exploring in the visualization parameter space enumerating different transfer functions, views, etc."
        },
        {
            "source": "2090746914",
            "target": "1981608001",
            "d": "M3620.04,-1866.82C3621.81,-1858.68 3623.79,-1849.54 3625.67,-1840.84",
            "citation_context": null
        },
        {
            "source": "2090746914",
            "target": "2009776702",
            "d": "M3661.95,-1872.21C3681.81,-1861.93 3704.04,-1847.98 3720.45,-1830.8 3844.84,-1700.57 3848.03,-1641.5 3908.45,-1471.84 3928.93,-1414.33 3940.6,-1343.99 3946.22,-1302.35",
            "citation_context": "Such knowledge-enabling visualization will be a key aspect of future visualization systems [ 5 ]."
        },
        {
            "source": "2090746914",
            "target": "2154789475",
            "d": "M3684.21,-1881.73C3816.88,-1858.93 4092.45,-1801.22 4092.45,-1715.19 4092.45,-1715.19 4092.45,-1715.19 4092.45,-1443.97 4092.45,-1390.59 4121.86,-1334.93 4144.09,-1300.5",
            "citation_context": null
        },
        {
            "source": "2090746914",
            "target": "2146955194",
            "d": "M3580.44,-1869.44C3567.82,-1859.08 3554.6,-1845.81 3546.45,-1830.8 3521.59,-1785.05 3527.45,-1767.26 3527.45,-1715.19 3527.45,-1715.19 3527.45,-1715.19 3527.45,-1354.23 3527.45,-1304.46 3540.15,-1248.13 3549.79,-1212.54",
            "citation_context": "Capturing and visually analyzing the discovery process has been studied for the task of visualization [16]."
        },
        {
            "source": "2166470747",
            "target": "2039138386",
            "d": "M1972.68,-1880.26C2036.31,-1868.66 2132.53,-1850.26 2215.45,-1830.8 2223.85,-1828.83 2232.63,-1826.63 2241.32,-1824.37",
            "citation_context": "Ma and Camp [10] developed a post-processing parallel visualization strategy based on pipelined rendering."
        },
        {
            "source": "2166470747",
            "target": "2114283921",
            "d": "M1886.97,-1867.24C1868.13,-1836.27 1836.22,-1783.83 1815.24,-1749.36",
            "citation_context": "In addition to the large-data problem which is being addressed by high-performance computing [4, 5, 6, 9], two fundamental visualization problems must be solved."
        },
        {
            "source": "2166470747",
            "target": "2145293470",
            "d": "M1918.21,-1867.24C1937.4,-1836.27 1969.9,-1783.83 1991.27,-1749.36",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2166470747",
            "target": "2947284622",
            "d": "M1975.5,-1882.28C2023.34,-1873.37 2086.09,-1857.59 2136.45,-1830.8 2176.59,-1809.45 2214.8,-1773.69 2239.68,-1747.59",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [ 18 ]."
        },
        {
            "source": "2166470747",
            "target": "2115314149",
            "d": "M1822.03,-1891.06C1757,-1886.46 1665.27,-1872.27 1596.45,-1830.8 1526.54,-1788.68 1472.92,-1706.49 1446.53,-1659.88",
            "citation_context": "Ma and Camp [14] show that by properly grouping processors according to the rendering loads, compress-"
        },
        {
            "source": "2166470747",
            "target": "1556372880",
            "d": "M1821.94,-1891.13C1765.15,-1886.22 1690.11,-1871.6 1637.45,-1830.8 1544.97,-1759.16 1600.41,-1677.99 1515.45,-1597.58 1503.07,-1585.87 1467.56,-1569.88 1435.94,-1557.09",
            "citation_context": "Ma and Camp [ MC00 ] show that by properly grouping processors according to the rendering loads, compressing images before delivering, and completely overlapping uploading each time step of the data, rendering, and delivering the images, interframe delay can be kept to a minimum."
        },
        {
            "source": "2166470747",
            "target": "2162126826",
            "d": "M1822.46,-1889.73C1773.46,-1883.85 1712.64,-1868.65 1672.45,-1830.8 1623.49,-1784.7 1648.24,-1750.21 1624.45,-1687.32 1609.12,-1646.81 1604.35,-1637.02 1586.45,-1597.58 1582.43,-1588.72 1577.92,-1579.23 1573.65,-1570.41",
            "citation_context": "Ma and Camp [18] show that by properly grouping processors according to the rendering loads, compressing images before delivering, and completely overlapping the uploading, rendering, and delivering of the images, interframe delay can be kept to a minimum."
        },
        {
            "source": "2166470747",
            "target": "2148775223",
            "d": "M1951.07,-1872C1999.76,-1848.32 2071.87,-1804.44 2103.45,-1741.06 2131.89,-1683.99 2138.04,-1651.15 2103.45,-1597.58 2047.51,-1510.97 1928.9,-1473.33 1848.66,-1457.32",
            "citation_context": "SC|05 November 12-18, 2005, Seattle, Washington, USA (c) 2005 ACM 1-59593-061-2/05/0011 $5.00 Several parallel visualization solutions are available for this large data problem [1,  12 , 13, 14, 28, 29]"
        },
        {
            "source": "2166470747",
            "target": "2188498653",
            "d": "M1897.25,-1866.49C1887.93,-1812.25 1873.65,-1685.36 1923.45,-1597.58 1947.52,-1555.14 2080.89,-1515.11 2103.45,-1471.84 2114.49,-1450.66 2119.36,-1435.91 2103.45,-1418.1 2073.47,-1384.54 1791.49,-1366.87 1644.56,-1359.88",
            "citation_context": "The challenge also includes balancing competing resources and numerous tradeoffs [ 13 ]."
        },
        {
            "source": "2166470747",
            "target": "2136730689",
            "d": "M1857.47,-1871.19C1811.24,-1846.57 1741.13,-1801.69 1705.45,-1741.06 1658.4,-1661.14 1693.38,-1406.51 1643.45,-1328.36 1603.85,-1266.39 1528.84,-1224.17 1475.25,-1200.33",
            "citation_context": null
        },
        {
            "source": "2001",
            "target": "2002",
            "d": "M34.45,-1785.6C34.45,-1770.24 34.45,-1747.92 34.45,-1732.55"
        },
        {
            "source": "2039138386",
            "target": "2114283921",
            "d": "M2238.59,-1792.45C2160.41,-1780.83 2031.8,-1761.07 1921.45,-1741.06 1905.13,-1738.1 1887.68,-1734.7 1871.1,-1731.36",
            "citation_context": "In addition to the large-data problem which is being addressed by high-performance computing [4, 5, 6, 9], two fundamental visualization problems must be solved."
        },
        {
            "source": "2039138386",
            "target": "2145293470",
            "d": "M2251.93,-1785.7C2203.12,-1771.33 2133.47,-1750.82 2081.85,-1735.63",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20, 15], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2039138386",
            "target": "2947284622",
            "d": "M2298.07,-1777.08C2294.01,-1768.6 2289.44,-1759.04 2285.11,-1750.01",
            "citation_context": "Previous work in time-varying data visualization has mainly focused on data encoding [26, 20,  15 ], feature tracking [1, 27], and rendering efficiency [18]."
        },
        {
            "source": "2039138386",
            "target": "2103068632",
            "d": "M2389.72,-1802.61C2529.44,-1800.75 2812.69,-1790.74 2896.45,-1741.06 2898.59,-1739.79 2930.59,-1693.04 2953.46,-1659.39",
            "citation_context": "capability of commodity PC graphics cards and the temporal compression technique described in [ 7 ] we achieve interactive texture-based volumetric kinetic visualization.We therefore apply the temporal compression technique described by Lum et al. [ 7 ] to compress these textures by up to a factor of eight."
        },
        {
            "source": "2039138386",
            "target": "2096608735",
            "d": "M2335,-1778.35C2343.87,-1767.79 2352.84,-1754.74 2357.45,-1741.06 2365.07,-1718.43 2358.38,-1711.19 2357.45,-1687.32 2353.22,-1579.81 2338.45,-1553.57 2338.45,-1445.97 2338.45,-1445.97 2338.45,-1445.97 2338.45,-1174.75 2338.45,-1122.68 2355.78,-1096.44 2319.45,-1059.14 2260.09,-998.2 2214.13,-1043.16 2131.45,-1023.14 2124.53,-1021.47 2117.35,-1019.59 2110.2,-1017.63",
            "citation_context": "Another example, Lum et al. [ 11 ] presented a GPU-based volume rendering technique for interactive visualization of the time-varying volume data."
        },
        {
            "source": "2039138386",
            "target": "2133015261",
            "d": "M2333.64,-1778.22C2342.43,-1767.55 2351.69,-1754.44 2357.45,-1741.06 2378.02,-1693.23 2376.45,-1677.52 2376.45,-1625.45 2376.45,-1625.45 2376.45,-1625.45 2376.45,-1174.75 2376.45,-1122.27 2384.47,-1100.72 2352.45,-1059.14 2339.08,-1041.78 2319.52,-1028.94 2299.88,-1019.61",
            "citation_context": null
        },
        {
            "source": "2039138386",
            "target": "2131433745",
            "d": "M2367.47,-1785.07C2389.62,-1775.39 2413.26,-1761.19 2428.45,-1741.06 2460.05,-1699.17 2452.45,-1677.93 2452.45,-1625.45 2452.45,-1625.45 2452.45,-1625.45 2452.45,-1443.97 2452.45,-1291.83 2519.95,-1263.77 2539.45,-1112.88 2542.51,-1089.19 2547.41,-1081.66 2539.45,-1059.14 2535.71,-1048.57 2529.32,-1038.49 2522.33,-1029.64",
            "citation_context": null
        },
        {
            "source": "2133638798",
            "target": "1725558581",
            "d": "M807.45,-1776.74C807.45,-1746.25 807.45,-1695.7 807.45,-1661.5",
            "citation_context": "Because of the remarkable advances in PC graphics hardware, image compositing is increasingly becoming the bottleneck of parallel renderings, and there have been efforts in building hardware image compositing devices [10,11,12,13,14]."
        },
        {
            "source": "2154046714",
            "target": "2091518855",
            "d": "M3272.45,-1776.61C3272.45,-1768.64 3272.45,-1759.75 3272.45,-1751.26",
            "citation_context": null
        },
        {
            "source": "2154046714",
            "target": "2143275883",
            "d": "M3197.33,-1801.8C3083.63,-1798.58 2861.75,-1786.46 2679.45,-1741.06 2673.78,-1739.65 2667.96,-1737.84 2662.24,-1735.84",
            "citation_context": "This behavior is not true of Jankun-Kelly and Maxe2x80x99s visualization exploration spreadsheet-like interface [16]."
        },
        {
            "source": "2154046714",
            "target": "2167688344",
            "d": "M3199.19,-1798.23C3056.88,-1788.6 2753.4,-1765.49 2712.45,-1741.06 2710.31,-1739.79 2678.31,-1693.04 2655.44,-1659.39",
            "citation_context": "Wood [ 2 ] generalized Angxe2x80x99s approach to discuss four different compositions of Web-based visualization.IEEE Computer Society Press, Los Alamitos, CA, October 17xe2x80x9021 1994. [ 2 ] J. Wood, K. Brodlie, and H. Wright.Our web interface implements an entirely web-based version of the visualization exploration sheet-like interface discussed in [ 2 ].The visualization process for both information and scientific visualization is an iterative sequence of user-applied transformations from data to view [1,  2 , 3]. The fundamental operation that occurs during the visualization process is the formation of parameter value sets to derive visualization results.[ 2 ] C. Upson, T. A. Faulhaber, Jr., D. Kamins, D. Laidlaw, D. Schlegel,"
        },
        {
            "source": "2154046714",
            "target": "2114265882",
            "d": "M3228.65,-1781.75C3213,-1771.75 3197.11,-1758.2 3188.45,-1741.06 3177.67,-1719.75 3177.36,-1708.48 3188.45,-1687.32 3201.49,-1662.42 3227.4,-1676.22 3240.45,-1651.32 3288.95,-1558.75 3337.55,-1470.77 3177.45,-1328.36 3141.73,-1296.6 2826.83,-1276.6 2692.62,-1269.45",
            "citation_context": "Visualization Space Paths: Several novel visualization user interfaces [6], [7], [8], [9] assume visualization exploration is equivalent to navigating a multidimensional parameter space."
        },
        {
            "source": "2154046714",
            "target": "2150064314",
            "d": "M3313.97,-1781.53C3329.69,-1771.36 3346.23,-1757.74 3356.45,-1741.06 3383.64,-1696.65 3375.45,-1677.52 3375.45,-1625.45 3375.45,-1625.45 3375.45,-1625.45 3375.45,-1174.75 3375.45,-1124.71 3390.07,-1068.44 3401.18,-1032.94",
            "citation_context": "[4, 5] introduce a spreadsheet-like interface for volume visualization; through this interface, the user can search for ideal visualizations by exploring in the visualization parameter space enumerating different transfer functions, views, etc."
        },
        {
            "source": "2154046714",
            "target": "2293301496",
            "d": "M3322.91,-1784.05C3343.39,-1774.09 3365.66,-1759.95 3380.45,-1741.06 3413.39,-1698.99 3413.45,-1678.89 3413.45,-1625.45 3413.45,-1625.45 3413.45,-1625.45 3413.45,-1354.23 3413.45,-1259.51 3412.36,-1223.7 3470.45,-1148.88 3520.44,-1084.48 3606.03,-1042.65 3666.17,-1019.56",
            "citation_context": "Jankun-Kelly and Ma [5] proposed a spreadsheet-like interface for visualization exploration and encapsulation."
        },
        {
            "source": "2002",
            "target": "2003",
            "d": "M34.45,-1695.86C34.45,-1680.5 34.45,-1658.18 34.45,-1642.81"
        },
        {
            "source": "2136917153",
            "target": "2114283921",
            "d": "M530.42,-1714.19C921.75,-1714.19 1313.07,-1714.19 1704.4,-1714.19",
            "citation_context": "surfaces for illustrating field lines [12]."
        },
        {
            "source": "2136917153",
            "target": "42438372",
            "d": "M455.23,-1687.35C459,-1676.39 462.99,-1663.38 465.45,-1651.32 478.18,-1588.74 478.06,-1571.54 473.45,-1507.84 472.84,-1499.45 471.78,-1490.47 470.59,-1482.03",
            "citation_context": null
        },
        {
            "source": "2143275883",
            "target": "2167688344",
            "d": "M2620.46,-1687.34C2622.03,-1679.2 2623.8,-1670.06 2625.49,-1661.36",
            "citation_context": "[4] have implemented a web-based interface to distributed or grid-based visualization systems."
        },
        {
            "source": "2143275883",
            "target": "2114265882",
            "d": "M2584.96,-1692.79C2571.33,-1682.06 2556.36,-1667.73 2547.45,-1651.32 2522.59,-1605.57 2528.45,-1587.78 2528.45,-1535.71 2528.45,-1535.71 2528.45,-1535.71 2528.45,-1443.97 2528.45,-1385.78 2570.58,-1329.77 2601.21,-1296.73",
            "citation_context": "work [1] based upon our experience applying them to"
        },
        {
            "source": "2111106392",
            "target": "2127273065",
            "d": "M4002.91,-1687.9C4023.03,-1654.48 4054.45,-1593.13 4054.45,-1535.71 4054.45,-1535.71 4054.45,-1535.71 4054.45,-1443.97 4054.45,-1352.23 4018.73,-1310.73 4075.45,-1238.62 4097.57,-1210.5 4133.42,-1195.13 4166.94,-1186.74",
            "citation_context": "These include selective and multi-level rendering [7], illustrative and non-photorealistic rendering [5, 15] and ghosted views [1, 23]."
        },
        {
            "source": "2114283921",
            "target": "42438372",
            "d": "M1757.37,-1690.37C1716.43,-1665.7 1648.14,-1626.1 1586.45,-1597.58 1545.09,-1578.46 1526.53,-1589.41 1490.45,-1561.58 1467.28,-1543.72 1477.99,-1522.09 1452.45,-1507.84 1412.77,-1485.7 764.29,-1457.92 540.03,-1448.92",
            "citation_context": null
        },
        {
            "source": "2114283921",
            "target": "2043965591",
            "d": "M1815.42,-1687.93C1834.86,-1664.51 1864.61,-1628.69 1890.45,-1597.58 1924.47,-1556.62 1963.69,-1509.44 1989.21,-1478.74",
            "citation_context": "One technique, based on a hybrid rendering approach, makes possible interactive exploration of large-scale particle data from particle beam dynamics modeling [1]."
        },
        {
            "source": "2114283921",
            "target": "2138290184",
            "d": "M1803.37,-1687.43C1826.11,-1623.08 1887.36,-1457.64 1929.45,-1418.1 1960.55,-1388.89 1982.11,-1404.47 2018.45,-1382.1 2056.7,-1358.55 2094.67,-1323.78 2120,-1298.52",
            "citation_context": null
        },
        {
            "source": "2156990842",
            "target": "2111106392",
            "d": "M3081.13,-1732.97C3114.67,-1742.91 3157.99,-1754.06 3197.45,-1759.06 3455.81,-1791.84 3764.82,-1751.34 3907.32,-1728.21",
            "citation_context": null
        },
        {
            "source": "2156990842",
            "target": "2103068632",
            "d": "M3009.6,-1687.34C3005.01,-1678.77 2999.83,-1669.1 2994.94,-1659.98",
            "citation_context": "in our previous work [ 1 ], is built on the inspirations we received from kinetic art [2], the studies done in cognitive science, specifically on structure-from-motion perception [3] [4], the ideas of particle systems [5], and the work of Interrante [6] on using texture to convey the shape of overlapping transparent surfaces.We expand on our previous work [ 1 ] in this paper, describing how a texture based representation of this motion can be used for improved interactivity with a larger number of motion primitives using commodity PC graphics hardware."
        },
        {
            "source": "2156990842",
            "target": "2025518624",
            "d": "M3084.02,-1696.44C3134.54,-1681.89 3199.51,-1661.59 3207.45,-1651.32 3259.89,-1583.5 3234.45,-1352.22 3234.45,-1266.49 3234.45,-1266.49 3234.45,-1266.49 3234.45,-1174.75 3234.45,-1126.02 3234.45,-1069.77 3234.45,-1033.89",
            "citation_context": null
        },
        {
            "source": "2145293470",
            "target": "2064959254",
            "d": "M2012.75,-1686.87C2012.84,-1678.9 2012.94,-1670.01 2013.04,-1661.52",
            "citation_context": null
        },
        {
            "source": "2145293470",
            "target": "2115314149",
            "d": "M1944.97,-1698.83C1925.19,-1694.85 1903.49,-1690.69 1883.45,-1687.32 1754.06,-1665.57 1602.98,-1646.22 1511.58,-1635.17",
            "citation_context": "To complicate the problem further, it could be desirable to create a single visualization by making use of multiple variables and/or multiple time steps [22]."
        },
        {
            "source": "2145293470",
            "target": "1556372880",
            "d": "M1951.46,-1696.09C1830.91,-1662.29 1563.27,-1587.25 1441.7,-1553.17",
            "citation_context": null
        },
        {
            "source": "2146362647",
            "target": "2130218153",
            "d": "M2803.85,-1686.87C2803.67,-1678.9 2803.46,-1670.01 2803.27,-1661.52",
            "citation_context": null
        },
        {
            "source": "2947284622",
            "target": "1611667971",
            "d": "M2267.25,-1687.04C2265.77,-1652.42 2263.45,-1589.5 2263.45,-1535.71 2263.45,-1535.71 2263.45,-1535.71 2263.45,-1264.49 2263.45,-1214.56 2249.59,-1158.27 2239.07,-1122.73",
            "citation_context": "Stompel and Ma [16] introduced a set of feature enhancedment techniques based on NPR to generate more perceptually effective visualization of multivariate and timevarying volume data."
        },
        {
            "source": "2003",
            "target": "2004",
            "d": "M34.45,-1606.12C34.45,-1590.76 34.45,-1568.44 34.45,-1553.07"
        },
        {
            "source": "1725558581",
            "target": "2166303794",
            "d": "M807.52,-1597.49C807.69,-1534.93 808.14,-1375.64 808.34,-1303.27",
            "citation_context": "[17] presented a scalable PC cluster system for enabling simultaneous volume computation and visualization, which includes 3D time-varying LIC volumes for animation."
        },
        {
            "source": "2115314149",
            "target": "115809921",
            "d": "M1367.27,-1607.66C1304.88,-1591.56 1208.75,-1566.76 1147.24,-1550.88",
            "citation_context": "The volume data sets we used in our study were generated by the highest-resolution earthquake simulation performed to date ( 2 )."
        },
        {
            "source": "2115314149",
            "target": "1556372880",
            "d": "M1414.01,-1597.6C1409.18,-1588.96 1403.72,-1579.18 1398.6,-1570",
            "citation_context": null
        },
        {
            "source": "2115314149",
            "target": "2162126826",
            "d": "M1462.41,-1600.17C1479.09,-1588.74 1499.28,-1574.9 1516.68,-1562.97",
            "citation_context": "In our previous work [16], a parallel volume renderer was developed for visualizing 3D unstructured volume data generated from the same, but smaller scale, earthquake simulation [24]."
        },
        {
            "source": "2115314149",
            "target": "2010314815",
            "d": "M1374.31,-1605.09C1351.15,-1595.1 1325.18,-1580.8 1306.45,-1561.58 1284.63,-1539.2 1270.18,-1506.52 1261.6,-1481.62",
            "citation_context": null
        },
        {
            "source": "2115314149",
            "target": "2148775223",
            "d": "M1497.48,-1611.75C1536.66,-1602.69 1585.16,-1587.22 1622.45,-1561.58 1647.65,-1544.25 1642.46,-1528.03 1665.45,-1507.84 1680.62,-1494.52 1699.03,-1482.37 1716.02,-1472.43",
            "citation_context": "SC|05 November 12-18, 2005, Seattle, Washington, USA (c) 2005 ACM 1-59593-061-2/05/0011 $5.00 Several parallel visualization solutions are available for this large data problem [1, 12, 13,  14 , 28, 29]"
        },
        {
            "source": "2115314149",
            "target": "2096608735",
            "d": "M1500.01,-1613.63C1591.21,-1597.89 1749.45,-1559.36 1853.45,-1471.84 1875.63,-1453.17 1873.27,-1441.46 1890.45,-1418.1 1962.55,-1320.05 2019.71,-1317.66 2059.45,-1202.62 2079.13,-1145.64 2065.95,-1074.64 2054.65,-1032.81",
            "citation_context": "Ma et al. [ 12 ] presented a parallel rendering algorithm for time-varying volume data on a 128-processor supercomputer, revealing 3D seismic wave propagation originating from the hypocenter of a simulated earthquake event."
        },
        {
            "source": "2115314149",
            "target": "2005878980",
            "d": "M1368.73,-1607.24C1337.51,-1597.08 1299.62,-1582 1269.45,-1561.58 1050.36,-1413.37 769.65,-1252.22 950.45,-1059.14 985.96,-1021.22 1131.26,-1036.59 1181.45,-1023.14 1360.93,-975.05 1563.15,-886.85 1657.93,-843.39",
            "citation_context": null
        },
        {
            "source": "2130218153",
            "target": "2095627337",
            "d": "M2840.05,-1600.86C2858.89,-1589.53 2881.88,-1575.72 2901.83,-1563.73",
            "citation_context": null
        },
        {
            "source": "2130218153",
            "target": "2114265882",
            "d": "M2790.22,-1597.78C2760.2,-1534.75 2682.85,-1372.32 2648.87,-1300.97",
            "citation_context": "In the first example (Figure 3a), the focus node for a focuscontext graph visualization (a MoireGraph [ 25 ]) was changed."
        },
        {
            "source": "2155542779",
            "target": "2095627337",
            "d": "M3095.19,-1604.2C3068.27,-1591.63 3032.82,-1575.09 3003.51,-1561.41",
            "citation_context": null
        },
        {
            "source": "2155542779",
            "target": "1855245415",
            "d": "M3131.56,-1597.34C3122.58,-1549.35 3103.44,-1447.03 3093.21,-1392.39",
            "citation_context": "After instability events are identified, it is possible to see the distribution of different events, their severity, duration, and frequency all in one single visualization ( Teoh, Ma &amp; Wu 2003 ), as shown in Figure 4."
        },
        {
            "source": "2167688344",
            "target": "2114265882",
            "d": "M2632.45,-1597.49C2632.45,-1534.93 2632.45,-1375.64 2632.45,-1303.27",
            "citation_context": null
        },
        {
            "source": "2263579231",
            "target": "2536708871",
            "d": "M379.45,-1597.13C379.45,-1589.16 379.45,-1580.27 379.45,-1571.78",
            "citation_context": "Space constraints preclude showing the complete derivations here, but they are available in [Schussman 2003]."
        },
        {
            "source": "2004",
            "target": "2005",
            "d": "M34.45,-1516.38C34.45,-1501.02 34.45,-1478.7 34.45,-1463.33"
        },
        {
            "source": "115809921",
            "target": "2099306854",
            "d": "M1074.11,-1508.61C1044.25,-1454.71 976.21,-1323.03 952.45,-1202.62 947.82,-1179.19 941.38,-1170.05 952.45,-1148.88 959.88,-1134.65 972.25,-1123.04 985.43,-1113.87",
            "citation_context": "The communications between parallel processes and data storage servers has also been researched through analysis of access patterns [20, 31, 32]."
        },
        {
            "source": "1556372880",
            "target": "2162126826",
            "d": "M1444.09,-1534.71C1459.33,-1534.71 1474.58,-1534.71 1489.82,-1534.71",
            "citation_context": "In addition to employing multiple rendering processors, multiple input processors are used to maximize data rates with concurrent reads and writes [ 31 ].A thorough performance study of the 1DIP and 2DIP I/O strategies is presented in [ 31 ]."
        },
        {
            "source": "1556372880",
            "target": "2010314815",
            "d": "M1346.82,-1511.34C1329.88,-1499.74 1309.06,-1485.46 1291.2,-1473.22",
            "citation_context": null
        },
        {
            "source": "2054501662",
            "target": "2154789475",
            "d": "M4187.6,-1513.24C4172.87,-1502.92 4157.51,-1488.94 4149.45,-1471.84 4123.51,-1416.83 4140.36,-1344.4 4154.64,-1301.89",
            "citation_context": null
        },
        {
            "source": "2054501662",
            "target": "2127273065",
            "d": "M4261.29,-1513.24C4276.02,-1502.92 4291.39,-1488.94 4299.45,-1471.84 4340.58,-1384.58 4296.22,-1268.59 4268.78,-1211.5",
            "citation_context": "TzengandMa [ 22 ] introduced a cluster-space visual interface for arbitrary dimensional volume data visualization."
        },
        {
            "source": "2095627337",
            "target": "1855245415",
            "d": "M2968.22,-1508.28C2992.51,-1477.05 3033.77,-1423.98 3060.56,-1389.52",
            "citation_context": null
        },
        {
            "source": "2095627337",
            "target": "2114265882",
            "d": "M2928.66,-1508.44C2895.28,-1466.98 2824.15,-1383.61 2750.45,-1328.36 2728.91,-1312.22 2702.57,-1297.96 2680.24,-1287.22",
            "citation_context": null
        },
        {
            "source": "2162126826",
            "target": "2148775223",
            "d": "M1598.13,-1516.38C1630.11,-1503.08 1674.6,-1484.58 1709.96,-1469.88",
            "citation_context": "SC|05 November 12-18, 2005, Seattle, Washington, USA (c) 2005 ACM 1-59593-061-2/05/0011 $5.00 Several parallel visualization solutions are available for this large data problem [1, 12, 13, 14, 28,  29 ]"
        },
        {
            "source": "2162126826",
            "target": "2188498653",
            "d": "M1556.45,-1507.52C1556.45,-1477.03 1556.45,-1426.48 1556.45,-1392.28",
            "citation_context": "While we have developed parallel I/O strategies to address this I/O requirement [ 8 ], we feel simulation-time visualization would provide a more viable solution to the pressing petascale data challenge."
        },
        {
            "source": "2162126826",
            "target": "2166303794",
            "d": "M1514.51,-1516.63C1505.07,-1513.29 1495.02,-1510.13 1485.45,-1507.84 1354.83,-1476.65 1313.37,-1512.69 1185.45,-1471.84 1054.99,-1430.18 917.58,-1342.53 850.41,-1296.37",
            "citation_context": "rendering, and isosurface rendering, have benefited from utilizing a cluster of PCs for parallel rendering for performance speedup [27, 1, 25, 28]."
        },
        {
            "source": "2162126826",
            "target": "2136730689",
            "d": "M1513.63,-1516.89C1483.1,-1503.97 1445.85,-1486 1436.45,-1471.84 1383.48,-1392.09 1395.43,-1272.12 1405.86,-1212.72",
            "citation_context": "More recently, Yu demonstrated that parallel volume rendering performance can be further improved by overlapping simulation with visualization [7]."
        },
        {
            "source": "2162126826",
            "target": "2099306854",
            "d": "M1512.13,-1517.93C1475.04,-1504.22 1425.5,-1484.61 1408.45,-1471.84 1260.48,-1361.08 1286.51,-1269.48 1146.45,-1148.88 1130.95,-1135.54 1112.19,-1123.45 1094.83,-1113.57",
            "citation_context": "The communications between parallel processes and data storage servers has also been researched through analysis of access patterns [20, 31, 32]."
        },
        {
            "source": "2162126826",
            "target": "2096608735",
            "d": "M1531.91,-1510.35C1491.52,-1469.13 1420.18,-1382.74 1469.45,-1328.36 1524.02,-1268.12 1771.55,-1345.05 1833.45,-1292.36 1883.68,-1249.6 1828.78,-1199.19 1871.45,-1148.88 1896.67,-1119.15 1920.66,-1136.81 1951.45,-1112.88 1980.61,-1090.21 2006.08,-1056.46 2022.78,-1031.27",
            "citation_context": "In another example, Yu et al. [ 26 ] presented a parallel visualization algorithm for studying a large earthquake simulation to model 3D seismic wave propagation of the 1994 Northridge earth-Komatitsch et al. [ 7 ] conducted a global-scale simulation of seismic wave propagation and superimposed the simulation data over field-measured waveforms data."
        },
        {
            "source": "2170839387",
            "target": "2131385811",
            "d": "M4619.92,-1508.28C4638.77,-1477.31 4670.68,-1424.87 4691.66,-1390.4",
            "citation_context": null
        },
        {
            "source": "2170839387",
            "target": "2163363303",
            "d": "M4596.88,-1507.75C4578.57,-1444.9 4531.83,-1284.46 4510.88,-1212.56",
            "citation_context": "These ideas have been extended to include rendering parameters, leading to lighting transfer functions [17] and illustration-inspired operators [23, 1]."
        },
        {
            "source": "2170839387",
            "target": "2011060348",
            "d": "M4662.64,-1516.16C4712.28,-1500.84 4777.21,-1479.85 4787.45,-1471.84 4835.5,-1434.26 4861.45,-1417.24 4861.45,-1356.23 4861.45,-1356.23 4861.45,-1356.23 4861.45,-1264.49 4861.45,-1215.5 4864.53,-1158.99 4866.86,-1123.14",
            "citation_context": "In one end, next to convolution-based approaches (e.g., gradient and curvature) are lighting transfer functions [ 17 ] and shape detection filters [26]."
        },
        {
            "source": "2170839387",
            "target": "2138396059",
            "d": "M4659.84,-1515.19C4723.24,-1490.08 4818.45,-1438.65 4818.45,-1356.23 4818.45,-1356.23 4818.45,-1356.23 4818.45,-1264.49 4818.45,-1206.58 4775.78,-1151.66 4743.84,-1118.66",
            "citation_context": null
        },
        {
            "source": "2170839387",
            "target": "2188310855",
            "d": "M4550.09,-1514.89C4487.87,-1489.47 4394.45,-1437.74 4394.45,-1356.23 4394.45,-1356.23 4394.45,-1356.23 4394.45,-1264.49 4394.45,-1215.21 4402.53,-1158.77 4408.67,-1123.02",
            "citation_context": null
        },
        {
            "source": "2170839387",
            "target": "2029393506",
            "d": "M4604.93,-1507.55C4605.52,-1472.93 4606.45,-1410 4606.45,-1356.23 4606.45,-1356.23 4606.45,-1356.23 4606.45,-1264.49 4606.45,-1147.08 4605.9,-1007.95 4605.61,-943.55",
            "citation_context": null
        },
        {
            "source": "2536708871",
            "target": "42438372",
            "d": "M403.58,-1508.8C412.98,-1499.1 423.86,-1487.87 433.8,-1477.6",
            "citation_context": null
        },
        {
            "source": "2536708871",
            "target": "2138516914",
            "d": "M370.58,-1507.9C359.64,-1473.67 342.45,-1411.16 342.45,-1356.23 342.45,-1356.23 342.45,-1356.23 342.45,-1085.01 342.45,-1034.97 327.82,-978.7 316.72,-943.2",
            "citation_context": null
        },
        {
            "source": "2964305288",
            "target": "2131385811",
            "d": "M4772.27,-1507.9C4760.19,-1477.28 4739.98,-1426.05 4726.44,-1391.71",
            "citation_context": "Lum and Ma [25] present a transfer function method that uses pairs of gradient aligned samples to enhance material boundaries using changes in illumination."
        },
        {
            "source": "2005",
            "target": "2006",
            "d": "M34.45,-1426.64C34.45,-1411.28 34.45,-1388.96 34.45,-1373.59"
        },
        {
            "source": "1541210462",
            "target": "1855245415",
            "d": "M3741.29,-1434.83C3604.16,-1418.37 3316.62,-1383.86 3172.56,-1366.57",
            "citation_context": "However, because the scans are too chaotic to compare directly, frequency analysis, such as Fourier transforms or wavelet transforms, can be used to convert the scan patterns into scalograms, which can then be systematically compared ( Muelder, Ma & Bartoletti 2005b ).Furthermore, it is very helpful to allow the analyst to bias the overview in a manner reflecting the cognitive insight gained from looking at the detail view ( Muelder et al. 2005b )."
        },
        {
            "source": "1541210462",
            "target": "2026867881",
            "d": "M3773.2,-1422.28C3748.67,-1410.26 3717.99,-1395.22 3692.11,-1382.53",
            "citation_context": null
        },
        {
            "source": "1541210462",
            "target": "2182215430",
            "d": "M3817.45,-1417.65C3817.45,-1409.68 3817.45,-1400.79 3817.45,-1392.3",
            "citation_context": null
        },
        {
            "source": "1541210462",
            "target": "2154789475",
            "d": "M3860.84,-1422.03C3925.35,-1389.41 4046.38,-1328.21 4115.84,-1293.09",
            "citation_context": null
        },
        {
            "source": "1541210462",
            "target": "2158598639",
            "d": "M3863.69,-1422.56C3879.59,-1412.65 3895.61,-1399.23 3904.45,-1382.1 3915.4,-1360.88 3914.3,-1350.12 3904.45,-1328.36 3894.45,-1306.27 3873.45,-1314.45 3863.45,-1292.36 3853.6,-1270.6 3860.64,-1262.34 3863.45,-1238.62 3872.26,-1164.27 3895.83,-1079.66 3910.06,-1032.98",
            "citation_context": "We then employ and extend the visualization techniques of [ 17 ] in order to create an intuitive representation and interface.Unlike in our previous work [ 17 ], this approach does not use wavelets.The wavelet scalogram method of [ 17 ] was tried, but it did not produce effective results, so another method was needed."
        },
        {
            "source": "2010314815",
            "target": "2136730689",
            "d": "M1266.69,-1418.83C1295.86,-1370.71 1359.63,-1265.53 1392.67,-1211.02",
            "citation_context": "MPI-IO) collective file read calls perform data staging, tio in equation 1, allowing each process to read its own portion of the volume in parallel with all of the other processes [7], [24]."
        },
        {
            "source": "2010314815",
            "target": "2099306854",
            "d": "M1202.11,-1431.55C1176.62,-1422.37 1147.72,-1407.02 1132.45,-1382.1 1118.9,-1360.01 1142.55,-1171.8 1130.45,-1148.88 1122.95,-1134.69 1110.56,-1123.08 1097.38,-1113.92",
            "citation_context": null
        },
        {
            "source": "2010314815",
            "target": "2144823948",
            "d": "M1252.61,-1418.01C1255.41,-1355.45 1262.55,-1196.16 1265.8,-1123.79",
            "citation_context": "For example, Yu and Ma [22] overview I/O techniques for visualization in [22]."
        },
        {
            "source": "2010314815",
            "target": "2594098541",
            "d": "M1243.83,-1418.1C1227.97,-1362.74 1191.86,-1228.39 1179.45,-1112.88 1176.89,-1089.13 1177.54,-1082.95 1179.45,-1059.14 1188.14,-950.83 1218.45,-926.45 1218.45,-817.79 1218.45,-817.79 1218.45,-817.79 1218.45,-636.31 1218.45,-513.44 2140.6,-471.68 2432.77,-461.53",
            "citation_context": null
        },
        {
            "source": "2118780007",
            "target": "2148775223",
            "d": "M4163.61,-1455.91C4098.5,-1467.03 3992.07,-1483.48 3899.45,-1489.84 3682.07,-1504.78 2154.54,-1517.72 1938.45,-1489.84 1903.15,-1485.29 1864.75,-1475.65 1833.29,-1466.48",
            "citation_context": "Most of the previous efforts focused on data segmentation and classification problems for 2D medical images [6, 7, 16] or medical volume data [ 25 ].However, the feature extraction task can be time consuming with the data size increases, and this can be improved by implementing the neural network classifier in a fragment program [ 25 ].We have also used support vector machines [8] and obtained promising results for a different application [ 25 ]."
        },
        {
            "source": "2118780007",
            "target": "2154789475",
            "d": "M4216.3,-1418.16C4206.64,-1387.54 4190.48,-1336.31 4179.64,-1301.97",
            "citation_context": null
        },
        {
            "source": "2118780007",
            "target": "2127273065",
            "d": "M4232.71,-1418.3C4241.86,-1388.42 4256.03,-1337.42 4261.45,-1292.36 4264.3,-1268.65 4263.55,-1262.41 4261.45,-1238.62 4260.7,-1230.2 4259.4,-1221.21 4257.95,-1212.76",
            "citation_context": "They also introduced a new approach [20,  21 ] to volume classification and visualization where the user is able to paint on axis aligned slices of the three-dimensionalvolume, indicating voxels of interest.Tzeng and Ma [20,  21 ] and presented detailed results of their machine learning algorithm.However, the SVM implementation ran on the CPU, so it was not interactive, unlike the neural networkimplementedin graphicshardwarefrom Tzengand Ma [20,  21 ]."
        },
        {
            "source": "2148775223",
            "target": "2188498653",
            "d": "M1719.3,-1423.95C1688.2,-1411.02 1647.53,-1394.11 1614.62,-1380.42",
            "citation_context": null
        },
        {
            "source": "2148775223",
            "target": "2096945381",
            "d": "M1764.64,-1417.78C1761.38,-1387.29 1755.97,-1336.74 1752.31,-1302.54",
            "citation_context": "Another viable approach is to employ machine learning as demonstrated in [20]."
        },
        {
            "source": "2148775223",
            "target": "2146955194",
            "d": "M1832.07,-1430.05C1866.91,-1420.44 1909.41,-1405.15 1942.45,-1382.1 2010.39,-1334.7 1987.2,-1275.39 2061.45,-1238.62 2187.26,-1176.31 3164.49,-1175.07 3469.69,-1176.23",
            "citation_context": "The idea of making visualization by analogy [17, 18, 19] can be utilized to match processes created by different groups and to possibly configure existing or assemble new processes effectively."
        },
        {
            "source": "2148775223",
            "target": "2542252643",
            "d": "M1786.07,-1418.83C1821.9,-1370.49 1900.39,-1264.55 1940.61,-1210.27",
            "citation_context": "Intelligent feature tracking with the swirling flow data set [15]."
        },
        {
            "source": "2148775223",
            "target": "2138422603",
            "d": "M1750.35,-1418.42C1718.15,-1370.61 1649.21,-1269.65 1620.45,-1238.62 1603.5,-1220.34 1596.32,-1218.9 1577.45,-1202.62 1544.91,-1174.55 1508.39,-1141.97 1482.35,-1118.56",
            "citation_context": null
        },
        {
            "source": "2148775223",
            "target": "2131433745",
            "d": "M1799.28,-1420.42C1813.97,-1409.2 1831.44,-1395.37 1846.45,-1382.1 1914.13,-1322.26 1917.56,-1292.01 1990.45,-1238.62 2018.35,-1218.18 2034.91,-1227 2059.45,-1202.62 2110.63,-1151.75 2077.07,-1101.56 2135.45,-1059.14 2141,-1055.1 2306.49,-1027.33 2409.2,-1010.4",
            "citation_context": null
        },
        {
            "source": "2006",
            "target": "2007",
            "d": "M34.45,-1336.9C34.45,-1321.54 34.45,-1299.22 34.45,-1283.85"
        },
        {
            "source": "2131385811",
            "target": "2163363303",
            "d": "M4683.41,-1329.93C4645.27,-1298 4578.29,-1241.92 4536.82,-1207.2",
            "citation_context": "Vincken et al. [29] and Lum et al. [ 18 ] use pyramid representations to improve volume classio cation.This result is representative of previous multi-scale classio cation methods, such as the one by Lum et al. [ 18 ]."
        },
        {
            "source": "2007",
            "target": "2008",
            "d": "M34.45,-1247.16C34.45,-1231.8 34.45,-1209.48 34.45,-1194.11"
        },
        {
            "source": "2096945381",
            "target": "2136730689",
            "d": "M1688.56,-1248.81C1631.42,-1233.84 1545.31,-1211.29 1484.68,-1195.41",
            "citation_context": null
        },
        {
            "source": "2096945381",
            "target": "2169175194",
            "d": "M1725.45,-1239.58C1716.73,-1230.14 1706.67,-1219.24 1697.4,-1209.19",
            "citation_context": "In situ processing is the reduction, transformation, analysis, or viewing of data as it is being computed, using the same architecture as the computation [ 19 ].The Institute has explored in situ processing previously [ 19 ], including a study of in situ visualization for steering of a massively parallel earthquake simulation [20]."
        },
        {
            "source": "2096945381",
            "target": "2144823948",
            "d": "M1691,-1247.97C1657.02,-1237.16 1613.69,-1221.55 1577.45,-1202.62 1540.78,-1183.47 1539.07,-1166.07 1501.45,-1148.88 1440.66,-1121.1 1419.97,-1130.31 1355.45,-1112.88 1348.94,-1111.12 1342.18,-1109.24 1335.43,-1107.32",
            "citation_context": "Benefits of this approach include the elimination of data movement between computation and visualization architectures; the economies of large-scale, tightly coupled parallelism; and the possibility of visualizing a simulation while it is running [1]."
        },
        {
            "source": "2096945381",
            "target": "2000673357",
            "d": "M1754.84,-1238.24C1762.19,-1212.77 1776.43,-1174.33 1800.45,-1148.88 1824.18,-1123.72 1848.98,-1140.77 1869.45,-1112.88 1907.41,-1061.16 1897.25,-1032.47 1885.45,-969.4 1883.78,-960.51 1880.89,-951.26 1877.67,-942.71",
            "citation_context": "This, coupled with a renewed interest in running visualization in situ with simulations to overcome file I/O constraints [30,31,47,51,52], ensures that high performance visualization code will run on the same technology as the simulation code for the foreseeable future."
        },
        {
            "source": "2096945381",
            "target": "2594098541",
            "d": "M1768.32,-1239.39C1788.03,-1215.13 1819.68,-1177.89 1850.45,-1148.88 1869.34,-1131.07 1881.02,-1133.76 1896.45,-1112.88 1906.88,-1098.76 2009.45,-835.35 2009.45,-817.79 2009.45,-817.79 2009.45,-817.79 2009.45,-636.31 2009.45,-546.55 2294.38,-491.88 2438.71,-469.94",
            "citation_context": null
        },
        {
            "source": "2114265882",
            "target": "2047503975",
            "d": "M2636.24,-1238.55C2643.01,-1181.34 2650.32,-1043.56 2577.45,-969.4 2521.49,-912.45 2479.48,-950.29 2401.45,-933.4 2248.61,-900.31 2070.46,-858.96 1971.55,-835.75",
            "citation_context": "It is challenging to model and capture the analytical processes effectively [20]."
        },
        {
            "source": "2166303794",
            "target": "2138516914",
            "d": "M788.99,-1239.2C735.14,-1169.32 587.14,-978.22 572.45,-969.4 498.02,-924.71 464.42,-955.45 380.45,-933.4 374.75,-931.9 368.86,-930.2 362.99,-928.39",
            "citation_context": null
        },
        {
            "source": "2166303794",
            "target": "2293321482",
            "d": "M818.99,-1238.82C832,-1204.75 852.45,-1142.41 852.45,-1087.01 852.45,-1087.01 852.45,-1087.01 852.45,-636.31 852.45,-587.58 852.45,-531.33 852.45,-495.45",
            "citation_context": null
        },
        {
            "source": "2008",
            "target": "2009",
            "d": "M34.45,-1157.42C34.45,-1142.06 34.45,-1119.74 34.45,-1104.37"
        },
        {
            "source": "2032623256",
            "target": "2345742246",
            "d": "M4979.45,-1148.59C4979.45,-1113.97 4979.45,-1051.04 4979.45,-997.27 4979.45,-997.27 4979.45,-997.27 4979.45,-636.31 4979.45,-587.58 4979.45,-531.33 4979.45,-495.45",
            "citation_context": null
        },
        {
            "source": "2040195604",
            "target": "2099306854",
            "d": "M1041.45,-1148.43C1041.45,-1140.46 1041.45,-1131.57 1041.45,-1123.08",
            "citation_context": "StarGate [17] is a tool that visualizes both the evolution of the software repository and the communication patterns of the developers involved."
        },
        {
            "source": "2136730689",
            "target": "2169175194",
            "d": "M1492.82,-1175.75C1520.67,-1175.75 1548.51,-1175.75 1576.36,-1175.75",
            "citation_context": "However, the expanding size and complexity of data shift the burden onto the I/O system, meaning this cost must be recognized and included in our analyses as an integral component of parallel visualization [5]."
        },
        {
            "source": "2136730689",
            "target": "2088064270",
            "d": "M1477.33,-1159.85C1528.39,-1147.76 1601.7,-1129.96 1665.45,-1112.88 1672.29,-1111.05 1679.4,-1109.08 1686.5,-1107.08",
            "citation_context": "[4, 5] showed that I/O can consume up to 90% of the total visualization time."
        },
        {
            "source": "2136730689",
            "target": "2144823948",
            "d": "M1375.47,-1151.93C1356.63,-1140.6 1333.71,-1126.83 1313.83,-1114.89",
            "citation_context": "work, where we examine the use of large numbers of tightly connected processor nodes in the context of a parallel ray casting volume rendering algorithm implemented on the IBM Blue Gene/P (BG/P) system at Argonne National Laboratory [2]."
        },
        {
            "source": "2169175194",
            "target": "2099306854",
            "d": "M1596.46,-1163C1567.09,-1158.31 1532.67,-1153.06 1501.45,-1148.88 1358.72,-1129.79 1321.87,-1134.16 1179.45,-1112.88 1160.15,-1110 1139.43,-1106.39 1120.06,-1102.79",
            "citation_context": "The communications between parallel processes and data storage servers has also been researched through analysis of access patterns [20, 31, 32]."
        },
        {
            "source": "2169175194",
            "target": "2000673357",
            "d": "M1726.43,-1157.34C1774.24,-1142.67 1834.9,-1122.57 1842.45,-1112.88 1880.33,-1064.24 1875.84,-988.12 1868.85,-943.5",
            "citation_context": "This, coupled with a renewed interest in running visualization in situ with simulations to overcome file I/O constraints [30,31,47,51,52], ensures that high performance visualization code will run on the same technology as the simulation code for the foreseeable future."
        },
        {
            "source": "2163363303",
            "target": "2011060348",
            "d": "M4569.35,-1162.77C4629.3,-1151.74 4718.28,-1133.94 4794.45,-1112.88 4800.06,-1111.33 4805.86,-1109.58 4811.64,-1107.75",
            "citation_context": "Correa and Ma use size-based transfer functions to classify features based on their size [ 3 ]."
        },
        {
            "source": "2163363303",
            "target": "2188310855",
            "d": "M4476.32,-1149.84C4466.84,-1140.06 4455.85,-1128.72 4445.84,-1118.38",
            "citation_context": null
        },
        {
            "source": "2163363303",
            "target": "2029393506",
            "d": "M4510.71,-1148.64C4529.65,-1100.43 4570.14,-997.38 4591.54,-942.93",
            "citation_context": null
        },
        {
            "source": "2009",
            "target": "2010",
            "d": "M34.45,-1067.68C34.45,-1052.32 34.45,-1030 34.45,-1014.63"
        },
        {
            "source": "1965305253",
            "target": "2027714334",
            "d": "M1590.01,-1059.63C1585.77,-1050.98 1580.95,-1041.15 1576.42,-1031.89",
            "citation_context": "[11] used sensitivity analysis to propagate the uncertainty in a series of data transformations and propose a number of extensions to show this uncertainty in 2D scatter plots."
        },
        {
            "source": "1965305253",
            "target": "2047503975",
            "d": "M1636.03,-1064.48C1652.2,-1053.53 1671.14,-1039.04 1685.45,-1023.14 1735.01,-968.03 1716.1,-930.06 1770.45,-879.66 1787.69,-863.67 1809.84,-850.9 1830.7,-841.22",
            "citation_context": null
        },
        {
            "source": "1965305253",
            "target": "2070833402",
            "d": "M1627.48,-1061.86C1637.26,-1051.15 1647.34,-1037.59 1652.45,-1023.14 1660.41,-1000.62 1655.24,-993.12 1652.45,-969.4 1645.73,-912.34 1632.19,-900.28 1622.45,-843.66 1612.32,-784.83 1606.06,-715.65 1602.92,-674.48",
            "citation_context": null
        },
        {
            "source": "2011060348",
            "target": "2041380214",
            "d": "M4855.69,-1059.55C4829.91,-1014.63 4769.69,-922.04 4690.45,-879.66 4500.45,-778.05 3834.45,-741.21 3598.82,-731.18",
            "citation_context": null
        },
        {
            "source": "2011060348",
            "target": "2046832287",
            "d": "M4866.54,-1059.05C4859.5,-996.2 4841.52,-835.76 4833.46,-763.86",
            "citation_context": null
        },
        {
            "source": "2088064270",
            "target": "2000673357",
            "d": "M1769.78,-1059.58C1788.4,-1028.7 1819.89,-976.47 1840.67,-941.99",
            "citation_context": "Consequently, researchers are beginning to leverage the same supercomputers used for creating the data [40, 41, 59]."
        },
        {
            "source": "2099306854",
            "target": "2294608516",
            "d": "M959.57,-1084.29C840.72,-1078.43 634.45,-1048.02 634.45,-907.53 634.45,-907.53 634.45,-907.53 634.45,-636.31 634.45,-587.58 633.3,-531.33 632.43,-495.44",
            "citation_context": null
        },
        {
            "source": "2099306854",
            "target": "2760106839",
            "d": "M1022.12,-1059.83C998.73,-1026.77 962.45,-966.05 962.45,-907.53 962.45,-907.53 962.45,-907.53 962.45,-546.57 962.45,-494.5 971.91,-474.57 943.45,-430.96 933.83,-416.22 919.33,-404.22 904.54,-394.86",
            "citation_context": "Therefore, visual analytics techniques have been introduced to analyze massive MPI traces [23], [24], [25]."
        },
        {
            "source": "2138396059",
            "target": "2131433745",
            "d": "M4639.8,-1075.19C4595.9,-1069.43 4537.97,-1062.62 4486.45,-1059.14 4071.54,-1031.15 3028.75,-1069.15 2615.45,-1023.14 2598.19,-1021.22 2579.8,-1018.08 2562.55,-1014.64",
            "citation_context": null
        },
        {
            "source": "2138396059",
            "target": "2029393506",
            "d": "M4694.55,-1059.58C4676.4,-1028.61 4645.67,-976.17 4625.47,-941.7",
            "citation_context": null
        },
        {
            "source": "2138396059",
            "target": "2046832287",
            "d": "M4718.17,-1059.05C4739.34,-996.08 4793.46,-835.1 4817.56,-763.42",
            "citation_context": "To this end, we exploit the notion of visibility histograms [22], which summarize the distribution of visibility of structure of interest from a given viewpoint."
        },
        {
            "source": "2138422603",
            "target": "1611667971",
            "d": "M1489.36,-1109.35C1507.03,-1117.92 1528.18,-1126.58 1548.45,-1130.88 1610.73,-1144.09 2059.05,-1143.54 2121.45,-1130.88 2139.37,-1127.24 2158.03,-1120.47 2174.61,-1113.27",
            "citation_context": "Muelder and Ma [12] introduced a prediction-correction method to make the best guess of the feature region in the subsequent time step to achieve a better tracking result."
        },
        {
            "source": "2138422603",
            "target": "1457609601",
            "d": "M1441.5,-1059.14C1438.98,-1048.06 1436.03,-1034.98 1433.45,-1023.14 1413.11,-929.93 1390.31,-819.87 1378.85,-764.2",
            "citation_context": null
        },
        {
            "source": "2138422603",
            "target": "2182470571",
            "d": "M1448.7,-1059.12C1453.55,-964.51 1472.42,-641.43 1505.45,-610.44 1523.27,-593.72 2234.43,-562.64 2486.21,-552.14",
            "citation_context": "On the other hand, prediction-correction based approaches [6, 22, 24] first predict candidate regions according to the feature descriptors (such as boundary or centroid location) extracted from previous time steps, and then adjust the predicted region to match the corresponding region in the next time step for correct feature tracking."
        },
        {
            "source": "2141005805",
            "target": "2000673357",
            "d": "M2428.21,-1064.6C2409.12,-1053.67 2386.46,-1039.18 2368.45,-1023.14 2345.6,-1002.8 2352.08,-984.45 2325.45,-969.4 2263.48,-934.39 2069.12,-918.33 1952.52,-911.67",
            "citation_context": "This, coupled with a renewed interest in running visualization in situ with simulations to overcome file I/O constraints [30,31,47,51,52], ensures that high performance visualization code will run on the same technology as the simulation code for the foreseeable future."
        },
        {
            "source": "2141005805",
            "target": "2182470571",
            "d": "M2434.23,-1063.06C2421.47,-1052.65 2408.32,-1038.99 2401.45,-1023.14 2376.1,-964.63 2386.32,-941.61 2401.45,-879.66 2430.17,-762.05 2508.64,-639.69 2548.9,-582.21",
            "citation_context": "Ma [19] presents the challenges and opportunities of in situ visualization."
        },
        {
            "source": "2010",
            "target": "2011",
            "d": "M34.45,-977.94C34.45,-962.58 34.45,-940.26 34.45,-924.89"
        },
        {
            "source": "2027714334",
            "target": "2070833402",
            "d": "M1561.44,-969.14C1565.53,-917.57 1575.64,-799.12 1589.45,-700.18 1590.62,-691.81 1592.08,-682.83 1593.56,-674.39",
            "citation_context": "We employ sensitivity flows [Chan et al. 2010], which enhance traditional scatterplots with local regression analysis, so that the analysts can understand locally linear relationships at a glance."
        },
        {
            "source": "2025518624",
            "target": "2023029656",
            "d": "M3243.17,-969.46C3253.53,-938.84 3270.84,-887.61 3282.45,-853.27",
            "citation_context": "AniViz [7] realizes this concept by allowing the user of a visualization system to do exactly that, and to present the story as an animation."
        },
        {
            "source": "2025518624",
            "target": "2041380214",
            "d": "M3293.57,-977.62C3348.38,-961.05 3422.25,-938.13 3427.45,-933.4 3477.23,-888.12 3499.95,-809.91 3509.43,-764.19",
            "citation_context": null
        },
        {
            "source": "2025518624",
            "target": "2113470734",
            "d": "M3264.57,-971.15C3297.38,-943.47 3349.44,-895.21 3381.45,-843.66 3417.15,-786.17 3399.37,-759.23 3432.45,-700.18 3438.08,-690.13 3445.35,-680.05 3452.6,-671.04",
            "citation_context": null
        },
        {
            "source": "2070002217",
            "target": "2077122434",
            "d": "M1109.45,-968.95C1109.45,-960.98 1109.45,-952.09 1109.45,-943.6",
            "citation_context": null
        },
        {
            "source": "2070002217",
            "target": "2070833402",
            "d": "M1149.86,-975.26C1167.24,-964.88 1186.51,-950.72 1199.45,-933.4 1264.71,-846.07 1193.63,-772.23 1275.45,-700.18 1309.26,-670.41 1423.67,-653.89 1507.21,-645.56",
            "citation_context": "described in Wei et al. [2010] to differentiate sensitivity streamlines at a global scale."
        },
        {
            "source": "2070002217",
            "target": "2591193418",
            "d": "M1067.79,-976.12C1050.15,-965.91 1031.03,-951.65 1019.45,-933.4 991.54,-889.44 1000.45,-869.86 1000.45,-817.79 1000.45,-817.79 1000.45,-817.79 1000.45,-546.57 1000.45,-497.07 1010.84,-440.68 1018.73,-405",
            "citation_context": null
        },
        {
            "source": "2096608735",
            "target": "2005878980",
            "d": "M2030.02,-969.48C2014.81,-942.85 1987.51,-902.12 1952.45,-879.66 1894.72,-842.68 1868.74,-861.14 1802.45,-843.66 1795.79,-841.91 1788.88,-840.03 1781.97,-838.11",
            "citation_context": null
        },
        {
            "source": "2102136719",
            "target": "1964937799",
            "d": "M2743.6,-1019.6C2760.55,-1028.18 2780.88,-1036.83 2800.45,-1041.14 2875.43,-1057.64 3417.22,-1060.75 3491.45,-1041.14 3504.69,-1037.64 3518.04,-1031.35 3529.91,-1024.57",
            "citation_context": null
        },
        {
            "source": "2102136719",
            "target": "2046125873",
            "d": "M2782.85,-996.27C2785.29,-996.27 2787.73,-996.27 2790.18,-996.27",
            "citation_context": null
        },
        {
            "source": "2102136719",
            "target": "2151882909",
            "d": "M2743.6,-1019.6C2760.55,-1028.18 2780.88,-1036.83 2800.45,-1041.14 2869.03,-1056.23 2889.87,-1056.23 2958.45,-1041.14 2974.65,-1037.57 2991.38,-1031.02 3006.28,-1024.01",
            "citation_context": "propose a method for changing the color and opacity mappings of volume rendered images, based on alpha estimation of a given set of layers [30]."
        },
        {
            "source": "2102136719",
            "target": "1996388339",
            "d": "M2678.75,-970.36C2669.21,-960.74 2658.17,-949.61 2648.07,-939.42",
            "citation_context": null
        },
        {
            "source": "2133015261",
            "target": "2542252643",
            "d": "M2161.68,-1014.1C2130.36,-1024.02 2093.6,-1038.7 2064.45,-1059.14 2033.15,-1081.09 2005.62,-1115.15 1987.58,-1140.62",
            "citation_context": "Fig. 3. Application-driven compression of the V-flame combustion data set [ 20 ].Wang et al. [ 20 ] have experimented with this application-driven approach to compressing large-scale time-varying volume data."
        },
        {
            "source": "2133015261",
            "target": "1983184648",
            "d": "M2232.88,-969.31C2243.62,-906.46 2271.04,-746.02 2283.33,-674.12",
            "citation_context": null
        },
        {
            "source": "2131433745",
            "target": "1964937799",
            "d": "M2539.44,-1017.15C2564.49,-1026.5 2595.56,-1036.47 2624.45,-1041.14 2719.54,-1056.53 3398.31,-1065.75 3491.45,-1041.14 3504.69,-1037.64 3518.04,-1031.35 3529.91,-1024.57",
            "citation_context": null
        },
        {
            "source": "2131433745",
            "target": "2046125873",
            "d": "M2539.44,-1017.15C2564.49,-1026.5 2595.56,-1036.47 2624.45,-1041.14 2693.77,-1052.36 2713.87,-1056.23 2782.45,-1041.14 2798.65,-1037.57 2815.38,-1031.02 2830.28,-1024.01",
            "citation_context": null
        },
        {
            "source": "2131433745",
            "target": "2151882909",
            "d": "M2539.44,-1017.15C2564.49,-1026.5 2595.56,-1036.47 2624.45,-1041.14 2697.72,-1053 2885.96,-1057.09 2958.45,-1041.14 2974.65,-1037.57 2991.38,-1031.02 3006.28,-1024.01",
            "citation_context": "In our previous work [31], we propose a similar method."
        },
        {
            "source": "2131433745",
            "target": "1996388339",
            "d": "M2523.48,-971.76C2539,-961.04 2557.53,-948.23 2573.95,-936.89",
            "citation_context": null
        },
        {
            "source": "2151882909",
            "target": "1964937799",
            "d": "M3095.6,-1019.6C3112.55,-1028.18 3132.88,-1036.83 3152.45,-1041.14 3226.02,-1057.33 3418.61,-1060.38 3491.45,-1041.14 3504.69,-1037.64 3518.04,-1031.35 3529.91,-1024.57",
            "citation_context": null
        },
        {
            "source": "2151882909",
            "target": "2182470571",
            "d": "M2998.37,-977.61C2903.45,-946.5 2723.45,-879.39 2723.45,-817.79 2723.45,-817.79 2723.45,-817.79 2723.45,-726.05 2723.45,-661.05 2664.03,-607.57 2619.99,-576.85",
            "citation_context": "[29], is a volume data exploration method without requiring the original volume data and a powerful computer."
        },
        {
            "source": "2011",
            "target": "2012",
            "d": "M34.45,-888.2C34.45,-872.84 34.45,-850.52 34.45,-835.15"
        },
        {
            "source": "188549894",
            "target": "2524731154",
            "d": "M420.83,-885.04C395.47,-873.79 364.23,-859.02 337.45,-843.66 291.72,-817.45 242.35,-782.62 209.05,-758.07",
            "citation_context": null
        },
        {
            "source": "1996388339",
            "target": "2182470571",
            "d": "M2613.32,-879.57C2605.75,-816.72 2586.42,-656.28 2577.76,-584.38",
            "citation_context": "Different techniques are proposed to enhance the explorability of in situ visualization, such as volumetric depth images [11], image databases [2], and explorable images [30]."
        },
        {
            "source": "1996388339",
            "target": "2594098541",
            "d": "M2578.46,-882.84C2534.32,-853.25 2467.45,-797.05 2467.45,-728.05 2467.45,-728.05 2467.45,-728.05 2467.45,-636.31 2467.45,-584.24 2469.44,-569.92 2486.45,-520.7 2489.69,-511.33 2494.27,-501.7 2499.03,-492.92",
            "citation_context": null
        },
        {
            "source": "2029393506",
            "target": "2124654985",
            "d": "M4605.45,-879.34C4605.45,-848.85 4605.45,-798.29 4605.45,-764.1",
            "citation_context": null
        },
        {
            "source": "2077122434",
            "target": "2020814412",
            "d": "M1109.45,-879.21C1109.45,-871.24 1109.45,-862.35 1109.45,-853.86",
            "citation_context": null
        },
        {
            "source": "2133623148",
            "target": "1983184648",
            "d": "M2450.65,-880.52C2428.64,-841.16 2383.52,-762.81 2339.45,-700.18 2332.62,-690.48 2324.75,-680.33 2317.31,-671.12",
            "citation_context": null
        },
        {
            "source": "2133623148",
            "target": "1601538659",
            "d": "M2499.72,-886.01C2559.95,-850.58 2681.54,-769.51 2737.45,-664.18 2750.42,-639.73 2753.82,-608.41 2754.16,-584.54",
            "citation_context": "Although gradient-based local Phong lighting has been used to help understand spatial structures in unstructured-grid data [7], the model is not sufficient to resolve the spatial ambiguities within complex volumetric features."
        },
        {
            "source": "2012",
            "target": "2013",
            "d": "M34.45,-798.46C34.45,-783.1 34.45,-760.78 34.45,-745.41"
        },
        {
            "source": "2007546607",
            "target": "1976035129",
            "d": "M424.45,-789.47C424.45,-781.5 424.45,-772.61 424.45,-764.12",
            "citation_context": null
        },
        {
            "source": "2007546607",
            "target": "2524731154",
            "d": "M370.37,-797.18C330.63,-783.51 276.45,-764.87 234.37,-750.39",
            "citation_context": null
        },
        {
            "source": "2007546607",
            "target": "2022893238",
            "d": "M370.39,-797.18C347.72,-787.21 322.49,-772.99 304.45,-753.92 258.1,-704.97 232.44,-628.71 220.63,-584.19",
            "citation_context": null
        },
        {
            "source": "2007546607",
            "target": "2294608516",
            "d": "M480.68,-797.9C503.33,-788.14 527.95,-773.88 544.45,-753.92 577.54,-713.88 610.57,-564.32 624.53,-494.79",
            "citation_context": "Storylines [23], [24], [25], [26] are a popular discrete form of this, where cluster membership is shown directly by line bundling."
        },
        {
            "source": "2007546607",
            "target": "2545930194",
            "d": "M388.76,-792.63C375.83,-782.36 362.45,-769.14 354.45,-753.92 310.01,-669.42 310.99,-552.96 314.96,-494.85",
            "citation_context": null
        },
        {
            "source": "2007546607",
            "target": "2509421351",
            "d": "M460.01,-792.56C472.92,-782.28 486.31,-769.07 494.45,-753.92 511.58,-722 512.87,-455.58 539.45,-430.96 586.82,-387.08 1055.03,-399.42 1119.45,-394.96 1204.16,-389.1 1300.72,-381.66 1369.06,-376.26",
            "citation_context": "The chosen layout depends on the authorxe2x80x99s discretion; the four options we discuss in the current framework are line charts and streamgraphs [10] for purely numeric data, and storylines [40] and alluvial diagrams [33] for flow-based, categorical data."
        },
        {
            "source": "1990559478",
            "target": "2005063628",
            "d": "M714.58,-791.61C656.48,-742.94 525.54,-633.26 461.34,-579.48",
            "citation_context": ", [8, 26])."
        },
        {
            "source": "1990559478",
            "target": "2544125743",
            "d": "M803.91,-798.66C928.77,-763.31 1224.23,-679.77 1472.45,-610.44 1616.36,-570.24 1648.84,-543.94 1796.45,-520.7 1830.51,-515.34 2854.78,-474.88 3171.84,-462.45",
            "citation_context": null
        },
        {
            "source": "1990559478",
            "target": "2969331663",
            "d": "M743.21,-789.63C742.91,-755.01 742.45,-692.08 742.45,-638.31 742.45,-638.31 742.45,-638.31 742.45,-277.35 742.45,-228.62 742.45,-172.37 742.45,-136.48",
            "citation_context": "Recent projects include the National Oceanic and Atmospheric Administrationxe2x80x99s (NOAAxe2x80x99s) Science on a Sphere program, which visualizes environmental data on a spherical display [1]; the DeepTree exhibit, which allows visitors to interact with and explore an evolutionary tree of life with over 70,000 species [2]; and the Living Liquid project, which created interactive visualizations of the micro and macroscopic life in the worldxe2x80x99s oceans [3]."
        },
        {
            "source": "2020814412",
            "target": "2047503975",
            "d": "M1176.67,-831.81C1228.27,-842.54 1301.47,-856.03 1366.45,-861.66 1460.98,-869.85 1700.59,-881.18 1793.45,-861.66 1810.38,-858.1 1827.93,-851.55 1843.6,-844.54",
            "citation_context": "Recent advanced visualization systems can help users interactively explore particle behaviors in combustion simulations [41]."
        },
        {
            "source": "2020814412",
            "target": "2971723077",
            "d": "M1116.39,-789.85C1124.97,-755.46 1138.45,-692.79 1138.45,-638.31 1138.45,-638.31 1138.45,-638.31 1138.45,-456.83 1138.45,-408.1 1138.45,-351.85 1138.45,-315.97",
            "citation_context": "The authors of [25] propose a fast, scalable clustering technique for multi-length data from combustion simulations that allows the clusters to be subject to users specifications."
        },
        {
            "source": "2023029656",
            "target": "2544125743",
            "d": "M3292.27,-789.83C3286.99,-727.11 3273.55,-567.2 3267.49,-495.08",
            "citation_context": null
        },
        {
            "source": "2023029656",
            "target": "2509421351",
            "d": "M3218.95,-810.13C3175.25,-803.13 3122.03,-787.71 3086.45,-753.92 3046.91,-716.38 3045.45,-692.83 3045.45,-638.31 3045.45,-638.31 3045.45,-638.31 3045.45,-546.57 3045.45,-395.1 1888.91,-372.9 1550.44,-369.65",
            "citation_context": "The concept of data storytelling itself has been highlighted in the InfoVis, SciVis, and business communities [15,23,25,28]."
        },
        {
            "source": "2023029656",
            "target": "3004294313",
            "d": "M3314.26,-790.68C3338.24,-757.71 3375.45,-697.07 3375.45,-638.31 3375.45,-638.31 3375.45,-638.31 3375.45,-277.35 3375.45,-152.2 3199.45,-115.28 3092.22,-104.4",
            "citation_context": "scientific storytelling [32], statistical analysis of volumetric data [33], and particle trajectory analysis [34]."
        },
        {
            "source": "2047503975",
            "target": "2216435688",
            "d": "M1895.25,-789.68C1894.89,-741.79 1894.13,-639.8 1893.72,-585.07",
            "citation_context": "The uncertainty due to data transformation and integration may vary along the visual analytics pipeline [2]."
        },
        {
            "source": "2047503975",
            "target": "2949117914",
            "d": "M1865.67,-791.56C1830.71,-760.19 1777.45,-701.95 1777.45,-638.31 1777.45,-638.31 1777.45,-638.31 1777.45,-456.83 1777.45,-408.1 1777.45,-351.85 1777.45,-315.97",
            "citation_context": "The authors of [56] expand on this work, adding ellipsoids representing covariance for particular variables and flow trees to show the relative uncertainty introduced with each data transformation choice."
        },
        {
            "source": "2013",
            "target": "2014",
            "d": "M34.45,-708.72C34.45,-693.36 34.45,-671.04 34.45,-655.67"
        },
        {
            "source": "2007142861",
            "target": "2091956487",
            "d": "M3173.55,-700.2C3171.7,-692.06 3169.62,-682.92 3167.63,-674.22",
            "citation_context": null
        },
        {
            "source": "2007142861",
            "target": "1601538659",
            "d": "M3219.45,-703.31C3233.18,-693.25 3246.96,-680.06 3254.45,-664.18 3264.63,-642.58 3270.58,-628.05 3254.45,-610.44 3223.56,-576.72 2889.43,-582.67 2844.45,-574.44 2836.76,-573.03 2828.78,-571.27 2820.89,-569.33",
            "citation_context": "Several techniques to apply visually plausible global illumination effects to volume rendering at interactive speed have been introduced [2, 13, 15, 16, 20, 24, 29]."
        },
        {
            "source": "2041380214",
            "target": "2113470734",
            "d": "M3505.72,-700.2C3502.6,-691.89 3499.08,-682.52 3495.74,-673.65",
            "citation_context": null
        },
        {
            "source": "2014",
            "target": "2015",
            "d": "M34.45,-618.98C34.45,-603.62 34.45,-581.3 34.45,-565.93"
        },
        {
            "source": "2113470734",
            "target": "2544125743",
            "d": "M3452.59,-612.01C3413.48,-580.16 3344.88,-524.31 3302.2,-489.57",
            "citation_context": null
        },
        {
            "source": "2015",
            "target": "2016",
            "d": "M34.45,-529.24C34.45,-513.88 34.45,-491.56 34.45,-476.19"
        },
        {
            "source": "2005063628",
            "target": "2940673288",
            "d": "M424.45,-520.61C424.45,-458.04 424.45,-298.76 424.45,-226.39",
            "citation_context": null
        },
        {
            "source": "2022893238",
            "target": "2943863288",
            "d": "M212.45,-520.41C212.45,-485.79 212.45,-422.86 212.45,-369.09 212.45,-369.09 212.45,-369.09 212.45,-277.35 212.45,-228.62 212.45,-172.37 212.45,-136.48",
            "citation_context": "As for overcoming the issue of computational cost, incremental methods, such as [13, 40, 57], have been introduced."
        },
        {
            "source": "2187671748",
            "target": "2594098541",
            "d": "M2875.93,-528.84C2865.48,-525.96 2854.68,-523.13 2844.45,-520.7 2761.5,-501.03 2665.47,-483.32 2599.61,-471.94",
            "citation_context": null
        },
        {
            "source": "2187671748",
            "target": "2561922343",
            "d": "M2935.45,-520.38C2935.45,-489.89 2935.45,-439.33 2935.45,-405.14",
            "citation_context": "Our previous work [5] focused on using spatially organized histograms to represent the overall motion within sets of discrete objects."
        },
        {
            "source": "2182470571",
            "target": "2594098541",
            "d": "M2558.12,-521.19C2552.83,-512.45 2546.83,-502.5 2541.19,-493.16",
            "citation_context": null
        },
        {
            "source": "2016",
            "target": "2017",
            "d": "M34.45,-439.5C34.45,-424.13 34.45,-401.82 34.45,-386.45"
        },
        {
            "source": "2558750989",
            "target": "2754406527",
            "d": "M5140.12,-431.45C5134.83,-422.71 5128.83,-412.76 5123.19,-403.42",
            "citation_context": "Examples include applying kanonymity and l-diversity to parallel coordinates [7], investigating privacy issues in event sequence datasets [5], and discussing opportunities and challenges for privacy preserving visualization in the realm of electronic health record data [8]."
        },
        {
            "source": "2558750989",
            "target": "2889118017",
            "d": "M5173.1,-431.56C5179.59,-420.8 5186.16,-407.78 5189.45,-394.96 5204.28,-337.18 5199.72,-267.21 5194.79,-225.66",
            "citation_context": null
        },
        {
            "source": "2594098541",
            "target": "3004294313",
            "d": "M2541.88,-431.59C2590.45,-375.78 2714.79,-240.66 2844.45,-161.74 2875.32,-142.95 2912.83,-128.42 2944.46,-118.17",
            "citation_context": "and a interactive visualization of the simulation results [7]."
        },
        {
            "source": "2017",
            "target": "2018",
            "d": "M34.45,-349.76C34.45,-334.39 34.45,-312.08 34.45,-296.71"
        },
        {
            "source": "2561922343",
            "target": "2964458439",
            "d": "M2935.45,-340.9C2935.45,-310.41 2935.45,-259.85 2935.45,-225.66",
            "citation_context": "Previous work addressed visualization of Tokamak particle distributions through weighted, spatially organized velocity histograms [10]."
        },
        {
            "source": "2754406527",
            "target": "2944385809",
            "d": "M5094.49,-341.24C5091.96,-333.01 5089.11,-323.76 5086.41,-314.97",
            "citation_context": "As stated by a sociologist, xe2x80x9cintroducing too much noise can take away the validity of our resultsxe2x80x9d [5]."
        },
        {
            "source": "2754406527",
            "target": "2889118017",
            "d": "M5125.36,-342.33C5134.44,-331.54 5144.37,-318.37 5151.45,-305.22 5165.05,-279.94 5174.92,-248.92 5181.19,-225.38",
            "citation_context": null
        },
        {
            "source": "2760106839",
            "target": "2891789817",
            "d": "M855.97,-340.98C869.84,-292.87 899.43,-190.14 915.15,-135.61",
            "citation_context": "[48]."
        },
        {
            "source": "2018",
            "target": "2019",
            "d": "M34.45,-260.02C34.45,-244.65 34.45,-222.34 34.45,-206.97"
        },
        {
            "source": "2751731070",
            "target": "2941265453",
            "d": "M5327.45,-251.16C5327.45,-220.67 5327.45,-170.11 5327.45,-135.92",
            "citation_context": "Recently, several machine learning approaches have been introduced to different tasks in graph visualization, such as previewing large graphs [60], exploring large graphs [11], and evaluating visualizations [38, 54]."
        },
        {
            "source": "2019",
            "target": "2020",
            "d": "M34.45,-170.28C34.45,-154.91 34.45,-132.6 34.45,-117.23"
        },
        {
            "source": "2020",
            "target": "2021",
            "d": "M34.45,-80.76C34.45,-67.63 34.45,-49.59 34.45,-36.39"
        },
        {
            "source": "2891789817",
            "target": "2969683715",
            "d": "M1003.27,-98.87C1005.9,-98.87 1008.53,-98.87 1011.16,-98.87",
            "citation_context": null
        },
        {
            "source": "2943863288",
            "target": "2943864384",
            "d": "M291.06,-98.87C293.55,-98.87 296.04,-98.87 298.53,-98.87",
            "citation_context": "Similar to the classical PCA, cPCA has the xe2x80x9csign ambiguityxe2x80x9d problem [13, 23, 35]."
        }
    ],
    [
        "34.45,-2594.11 34.45,-2594.11 34.45,-2594.11 34.45,-2594.11",
        "361.95,-2613.12 358.45,-2603.12 354.95,-2613.12 361.95,-2613.12",
        "34.45,-2504.37 34.45,-2504.37 34.45,-2504.37 34.45,-2504.37",
        "304.74,-2516.62 295.19,-2512.04 299.8,-2521.58 304.74,-2516.62",
        "417.1,-2521.58 421.71,-2512.04 412.15,-2516.62 417.1,-2521.58",
        "34.45,-2423.58 34.45,-2423.58 34.45,-2423.58 34.45,-2423.58",
        "449.95,-2361.64 446.45,-2351.64 442.95,-2361.64 449.95,-2361.64",
        "368.42,-2271.7 370.58,-2261.33 362.42,-2268.09 368.42,-2271.7",
        "358.06,-928.36 347.53,-927.19 355.04,-934.67 358.06,-928.36",
        "34.45,-2342.71 34.45,-2342.71 34.45,-2342.71 34.45,-2342.71",
        "34.45,-2252.89 34.45,-2252.89 34.45,-2252.89 34.45,-2252.89",
        "414.48,-2268 406.09,-2261.52 408.61,-2271.81 414.48,-2268",
        "34.45,-2163.15 34.45,-2163.15 34.45,-2163.15 34.45,-2163.15",
        "1932.21,-1925.59 1923.18,-1920.06 1926.79,-1930.02 1932.21,-1925.59",
        "2256.89,-1834.21 2263.56,-1825.98 2253.21,-1828.25 2256.89,-1834.21",
        "1834.64,-1263.5 1824.49,-1266.57 1834.33,-1270.5 1834.64,-1263.5",
        "2627.79,-571.05 2617.27,-569.84 2624.74,-577.35 2627.79,-571.05",
        "439.86,-1751.69 438.74,-1741.15 433.04,-1750.09 439.86,-1751.69",
        "295.62,-943.91 295.34,-933.32 288.96,-941.78 295.62,-943.91",
        "34.45,-2082.36 34.45,-2082.36 34.45,-2082.36 34.45,-2082.36",
        "1339.67,-1197.06 1348.48,-1191.18 1337.92,-1190.29 1339.67,-1197.06",
        "34.45,-2001.49 34.45,-2001.49 34.45,-2001.49 34.45,-2001.49",
        "34.45,-1911.67 34.45,-1911.67 34.45,-1911.67 34.45,-1911.67",
        "3347.78,-1925.72 3353.33,-1916.7 3343.36,-1920.29 3347.78,-1925.72",
        "3544.6,-1916.21 3553.41,-1910.33 3542.86,-1909.43 3544.6,-1916.21",
        "3275.95,-1840.94 3272.45,-1830.94 3268.95,-1840.94 3275.95,-1840.94",
        "2663.31,-1733.27 2652.75,-1732.4 2660.46,-1739.66 2663.31,-1733.27",
        "2589.65,-1292.35 2596.46,-1284.24 2586.07,-1286.33 2589.65,-1292.35",
        "3540.82,-1212.58 3543.08,-1202.23 3534.86,-1208.91 3540.82,-1212.58",
        "3381.06,-1031.11 3385.72,-1021.59 3376.15,-1026.12 3381.06,-1031.11",
        "1421.28,-1661.9 1420.77,-1651.31 1414.57,-1659.9 1421.28,-1661.9",
        "1090.11,-1571.73 1086.92,-1561.63 1083.12,-1571.51 1090.11,-1571.73",
        "1358.6,-1571.07 1361,-1560.75 1352.69,-1567.32 1358.6,-1571.07",
        "1549.03,-1572.06 1548.73,-1561.47 1542.36,-1569.94 1549.03,-1572.06",
        "1242.12,-1482.18 1242.02,-1471.59 1235.49,-1479.94 1242.12,-1482.18",
        "1747.56,-1481.58 1750.32,-1471.35 1741.78,-1477.63 1747.56,-1481.58",
        "1489.26,-1379.82 1497.51,-1373.18 1486.92,-1373.23 1489.26,-1379.82",
        "1398.15,-1659.63 1402.91,-1650.16 1393.29,-1654.6 1398.15,-1659.63",
        "1379.45,-1210.2 1384.73,-1201.01 1374.88,-1204.9 1379.45,-1210.2",
        "34.45,-1821.93 34.45,-1821.93 34.45,-1821.93 34.45,-1821.93",
        "2314.77,-1840.85 2311.04,-1830.94 2307.77,-1841.01 2314.77,-1840.85",
        "3526.58,-1897.17 3536.58,-1893.67 3526.58,-1890.17 3526.58,-1897.17",
        "3311.7,-1832.31 3301.73,-1828.72 3307.28,-1837.74 3311.7,-1832.31",
        "3423.24,-1032.42 3418.11,-1023.15 3416.34,-1033.59 3423.24,-1032.42",
        "3629.13,-1841.42 3627.82,-1830.9 3622.29,-1839.93 3629.13,-1841.42",
        "3949.69,-1302.78 3947.52,-1292.41 3942.75,-1301.87 3949.69,-1302.78",
        "4147.26,-1302.06 4149.86,-1291.79 4141.42,-1298.2 4147.26,-1302.06",
        "3553.24,-1213.21 3552.54,-1202.63 3546.49,-1211.33 3553.24,-1213.21",
        "2242.29,-1827.73 2251.07,-1821.8 2240.5,-1820.96 2242.29,-1827.73",
        "1818.08,-1747.3 1809.89,-1740.57 1812.1,-1750.94 1818.08,-1747.3",
        "1994.42,-1750.92 1996.72,-1740.57 1988.47,-1747.23 1994.42,-1750.92",
        "2242.36,-1749.85 2246.65,-1740.16 2237.25,-1745.06 2242.36,-1749.85",
        "1449.54,-1658.09 1441.62,-1651.05 1443.43,-1661.49 1449.54,-1658.09",
        "1436.86,-1553.69 1426.28,-1553.23 1434.26,-1560.19 1436.86,-1553.69",
        "1576.67,-1568.62 1569.15,-1561.16 1570.38,-1571.68 1576.67,-1568.62",
        "1849.06,-1453.83 1838.58,-1455.38 1847.74,-1460.71 1849.06,-1453.83",
        "1644.38,-1356.37 1634.22,-1359.39 1644.05,-1363.36 1644.38,-1356.37",
        "1476.4,-1197.01 1465.84,-1196.23 1473.61,-1203.43 1476.4,-1197.01",
        "34.45,-1732.19 34.45,-1732.19 34.45,-1732.19 34.45,-1732.19",
        "1871.41,-1727.85 1860.91,-1729.3 1870.02,-1734.71 1871.41,-1727.85",
        "2082.69,-1732.23 2072.11,-1732.76 2080.71,-1738.94 2082.69,-1732.23",
        "2288.21,-1748.37 2280.73,-1740.86 2281.89,-1751.39 2288.21,-1748.37",
        "2956.62,-1660.96 2959.34,-1650.72 2950.83,-1657.03 2956.62,-1660.96",
        "2111.08,-1014.24 2100.51,-1014.92 2109.2,-1020.98 2111.08,-1014.24",
        "2301.12,-1016.33 2290.57,-1015.43 2298.26,-1022.71 2301.12,-1016.33",
        "2524.92,-1027.28 2515.8,-1021.89 2519.56,-1031.79 2524.92,-1027.28",
        "810.95,-1661.46 807.45,-1651.46 803.95,-1661.46 810.95,-1661.46",
        "3275.95,-1751.2 3272.45,-1741.2 3268.95,-1751.2 3275.95,-1751.2",
        "2663.36,-1732.52 2652.77,-1732.31 2660.92,-1739.08 2663.36,-1732.52",
        "2658.07,-1657.03 2649.55,-1650.72 2652.27,-1660.96 2658.07,-1657.03",
        "2692.67,-1265.95 2682.5,-1268.92 2692.3,-1272.94 2692.67,-1265.95",
        "3404.62,-1033.65 3404.34,-1023.06 3397.96,-1031.52 3404.62,-1033.65",
        "3667.47,-1022.82 3675.6,-1016.02 3665.01,-1016.26 3667.47,-1022.82",
        "34.45,-1642.45 34.45,-1642.45 34.45,-1642.45 34.45,-1642.45",
        "1704.52,-1717.69 1714.52,-1714.19 1704.52,-1710.69 1704.52,-1717.69",
        "474.04,-1481.44 469.1,-1472.07 467.12,-1482.48 474.04,-1481.44",
        "2628.95,-1661.9 2627.42,-1651.42 2622.08,-1660.57 2628.95,-1661.9",
        "2603.98,-1298.9 2608.33,-1289.24 2598.9,-1294.08 2603.98,-1298.9",
        "4167.83,-1190.13 4176.78,-1184.46 4166.24,-1183.31 4167.83,-1190.13",
        "540.13,-1445.42 530,-1448.52 539.85,-1452.42 540.13,-1445.42",
        "1992.01,-1480.85 1995.71,-1470.92 1986.62,-1476.37 1992.01,-1480.85",
        "2122.57,-1300.91 2127.12,-1291.34 2117.6,-1295.98 2122.57,-1300.91",
        "3907.99,-1731.65 3917.29,-1726.58 3906.86,-1724.74 3907.99,-1731.65",
        "2998,-1658.28 2990.2,-1651.12 2991.83,-1661.59 2998,-1658.28",
        "3237.95,-1033.43 3234.45,-1023.43 3230.95,-1033.43 3237.95,-1033.43",
        "2016.54,-1661.5 2013.15,-1651.46 2009.54,-1661.42 2016.54,-1661.5",
        "1511.9,-1631.68 1501.55,-1633.96 1511.06,-1638.63 1511.9,-1631.68",
        "1442.37,-1549.72 1431.79,-1550.39 1440.48,-1556.46 1442.37,-1549.72",
        "2806.77,-1661.37 2803.04,-1651.46 2799.77,-1661.53 2806.77,-1661.37",
        "2242.32,-1121.39 2236.07,-1112.84 2235.62,-1123.43 2242.32,-1121.39",
        "34.45,-1552.71 34.45,-1552.71 34.45,-1552.71 34.45,-1552.71",
        "811.85,-1302.85 808.37,-1292.84 804.85,-1302.83 811.85,-1302.85",
        "1147.86,-1547.43 1137.3,-1548.32 1146.11,-1554.21 1147.86,-1547.43",
        "1401.54,-1568.1 1393.61,-1561.08 1395.43,-1571.51 1401.54,-1568.1",
        "1518.69,-1565.83 1524.96,-1557.29 1514.73,-1560.06 1518.69,-1565.83",
        "1264.82,-1480.22 1258.38,-1471.81 1258.17,-1482.4 1264.82,-1480.22",
        "1717.8,-1475.44 1724.74,-1467.44 1714.32,-1469.37 1717.8,-1475.44",
        "2057.99,-1031.76 2051.91,-1023.08 2051.25,-1033.65 2057.99,-1031.76",
        "1659.42,-846.56 1667.04,-839.2 1656.49,-840.2 1659.42,-846.56",
        "2903.7,-1566.69 2910.47,-1558.54 2900.09,-1560.69 2903.7,-1566.69",
        "2652.02,-1299.45 2644.56,-1291.93 2645.7,-1302.46 2652.02,-1299.45",
        "3004.76,-1558.13 2994.22,-1557.08 3001.8,-1564.48 3004.76,-1558.13",
        "3096.63,-1391.63 3091.35,-1382.45 3089.75,-1392.92 3096.63,-1391.63",
        "2635.95,-1302.84 2632.45,-1292.84 2628.95,-1302.84 2635.95,-1302.84",
        "382.95,-1571.72 379.45,-1561.72 375.95,-1571.72 382.95,-1571.72",
        "34.45,-1462.97 34.45,-1462.97 34.45,-1462.97 34.45,-1462.97",
        "987.68,-1116.58 994.17,-1108.2 983.87,-1110.71 987.68,-1116.58",
        "1489.83,-1538.21 1499.83,-1534.71 1489.83,-1531.21 1489.83,-1538.21",
        "1292.92,-1470.16 1282.69,-1467.39 1288.96,-1475.93 1292.92,-1470.16",
        "4158.01,-1302.87 4158,-1292.27 4151.4,-1300.56 4158.01,-1302.87",
        "4271.76,-1209.63 4264.21,-1202.2 4265.48,-1212.72 4271.76,-1209.63",
        "3063.34,-1391.66 3066.71,-1381.61 3057.81,-1387.36 3063.34,-1391.66",
        "2681.48,-1283.94 2670.94,-1282.84 2678.5,-1290.27 2681.48,-1283.94",
        "1711.31,-1473.11 1719.2,-1466.03 1708.62,-1466.64 1711.31,-1473.11",
        "1559.95,-1392.24 1556.45,-1382.24 1552.95,-1392.24 1559.95,-1392.24",
        "852.01,-1293.22 841.79,-1290.42 848.03,-1298.98 852.01,-1293.22",
        "1409.33,-1213.16 1407.7,-1202.69 1402.45,-1211.89 1409.33,-1213.16",
        "1096.35,-1110.41 1085.91,-1108.62 1092.95,-1116.53 1096.35,-1110.41",
        "2025.8,-1033.04 2028.31,-1022.75 2019.93,-1029.23 2025.8,-1033.04",
        "4694.79,-1391.98 4697,-1381.61 4688.81,-1388.34 4694.79,-1391.98",
        "4514.14,-1211.24 4507.98,-1202.61 4507.42,-1213.19 4514.14,-1211.24",
        "4870.36,-1123.37 4867.53,-1113.16 4863.37,-1122.9 4870.36,-1123.37",
        "4745.92,-1115.79 4736.39,-1111.16 4740.95,-1120.72 4745.92,-1115.79",
        "4412.13,-1123.51 4410.42,-1113.06 4405.24,-1122.3 4412.13,-1123.51",
        "4609.11,-943.49 4605.57,-933.51 4602.11,-943.52 4609.11,-943.49",
        "436.4,-1479.95 440.84,-1470.34 431.37,-1475.08 436.4,-1479.95",
        "319.93,-941.78 313.55,-933.32 313.27,-943.91 319.93,-941.78",
        "4729.56,-1390.09 4722.64,-1382.07 4723.05,-1392.66 4729.56,-1390.09",
        "34.45,-1373.23 34.45,-1373.23 34.45,-1373.23 34.45,-1373.23",
        "3172.78,-1363.07 3162.44,-1365.35 3171.95,-1370.02 3172.78,-1363.07",
        "3693.33,-1379.23 3682.81,-1377.97 3690.24,-1385.52 3693.33,-1379.23",
        "3820.95,-1392.24 3817.45,-1382.24 3813.95,-1392.24 3820.95,-1392.24",
        "4117.53,-1296.16 4124.88,-1288.52 4114.38,-1289.91 4117.53,-1296.16",
        "3913.43,-1033.92 3913.03,-1023.33 3906.74,-1031.86 3913.43,-1033.92",
        "1395.7,-1212.78 1397.89,-1202.41 1389.71,-1209.15 1395.7,-1212.78",
        "1098.94,-1110.75 1088.65,-1108.24 1095.13,-1116.62 1098.94,-1110.75",
        "1269.31,-1123.5 1266.27,-1113.36 1262.32,-1123.19 1269.31,-1123.5",
        "2433.03,-465.02 2442.9,-461.18 2432.79,-458.03 2433.03,-465.02",
        "1833.92,-1463.01 1823.34,-1463.52 1831.93,-1469.72 1833.92,-1463.01",
        "4182.95,-1300.81 4176.6,-1292.33 4176.27,-1302.92 4182.95,-1300.81",
        "4261.37,-1212.01 4256.13,-1202.81 4254.49,-1213.27 4261.37,-1212.01",
        "1615.69,-1377.08 1605.11,-1376.47 1613,-1383.54 1615.69,-1377.08",
        "1755.78,-1302.07 1751.23,-1292.5 1748.82,-1302.81 1755.78,-1302.07",
        "3469.81,-1179.73 3479.83,-1176.27 3469.84,-1172.73 3469.81,-1179.73",
        "1943.58,-1212.14 1946.72,-1202.02 1937.96,-1207.97 1943.58,-1212.14",
        "1484.4,-1115.7 1474.63,-1111.61 1479.72,-1120.9 1484.4,-1115.7",
        "2409.95,-1013.82 2419.25,-1008.75 2408.81,-1006.92 2409.95,-1013.82",
        "34.45,-1283.49 34.45,-1283.49 34.45,-1283.49 34.45,-1283.49",
        "4539.04,-1204.5 4529.13,-1200.76 4534.55,-1209.87 4539.04,-1204.5",
        "34.45,-1193.75 34.45,-1193.75 34.45,-1193.75 34.45,-1193.75",
        "1485.36,-1191.97 1474.8,-1192.82 1483.59,-1198.74 1485.36,-1191.97",
        "1699.85,-1206.7 1690.5,-1201.72 1694.71,-1211.44 1699.85,-1206.7",
        "1336.14,-1103.88 1325.57,-1104.49 1334.21,-1110.61 1336.14,-1103.88",
        "1880.9,-941.38 1873.94,-933.39 1874.4,-943.98 1880.9,-941.38",
        "2439.49,-473.37 2448.86,-468.42 2438.45,-466.44 2439.49,-473.37",
        "1972.18,-832.3 1961.65,-833.42 1970.58,-839.12 1972.18,-832.3",
        "363.78,-924.97 353.19,-925.27 361.66,-931.64 363.78,-924.97",
        "855.95,-494.99 852.45,-484.99 848.95,-494.99 855.95,-494.99",
        "34.45,-1104.01 34.45,-1104.01 34.45,-1104.01 34.45,-1104.01",
        "4982.95,-494.99 4979.45,-484.99 4975.95,-494.99 4982.95,-494.99",
        "1044.95,-1123.02 1041.45,-1113.02 1037.95,-1123.02 1044.95,-1123.02",
        "1576.61,-1179.25 1586.61,-1175.75 1576.61,-1172.25 1576.61,-1179.25",
        "1687.48,-1110.44 1696.14,-1104.34 1685.56,-1103.71 1687.48,-1110.44",
        "1315.61,-1111.87 1305.24,-1109.72 1312,-1117.87 1315.61,-1111.87",
        "1120.54,-1099.32 1110.07,-1100.91 1119.25,-1106.2 1120.54,-1099.32",
        "1872.26,-942.68 1867.14,-933.41 1865.36,-943.85 1872.26,-942.68",
        "4812.89,-1111.03 4821.31,-1104.61 4810.72,-1104.37 4812.89,-1111.03",
        "4448.23,-1115.82 4438.76,-1111.07 4443.2,-1120.69 4448.23,-1115.82",
        "4594.9,-943.94 4595.3,-933.35 4588.39,-941.38 4594.9,-943.94",
        "34.45,-1014.27 34.45,-1014.27 34.45,-1014.27 34.45,-1014.27",
        "1579.55,-1030.34 1572.01,-1022.9 1573.26,-1033.42 1579.55,-1030.34",
        "1832.15,-844.41 1839.85,-837.13 1829.29,-838.02 1832.15,-844.41",
        "1606.4,-674.1 1602.17,-664.39 1599.42,-674.62 1606.4,-674.1",
        "3598.74,-727.68 3588.6,-730.75 3598.45,-734.67 3598.74,-727.68",
        "4836.94,-763.46 4832.34,-753.91 4829.98,-764.24 4836.94,-763.46",
        "1843.81,-943.57 1845.97,-933.2 1837.81,-939.96 1843.81,-943.57",
        "635.91,-494.9 632.17,-484.99 628.92,-495.07 635.91,-494.9",
        "906.21,-391.78 895.83,-389.65 902.62,-397.79 906.21,-391.78",
        "2563.04,-1011.17 2552.54,-1012.58 2561.63,-1018.02 2563.04,-1011.17",
        "4628.4,-939.77 4620.32,-932.91 4622.36,-943.31 4628.4,-939.77",
        "4820.88,-764.51 4820.75,-753.91 4814.25,-762.28 4820.88,-764.51",
        "2176.42,-1116.29 2184.11,-1109 2173.55,-1109.91 2176.42,-1116.29",
        "1382.23,-763.22 1376.79,-754.13 1375.37,-764.63 1382.23,-763.22",
        "2486.56,-555.63 2496.41,-551.72 2486.27,-548.64 2486.56,-555.63",
        "1952.71,-908.18 1942.53,-911.11 1952.32,-915.17 1952.71,-908.18",
        "2551.87,-584.06 2554.79,-573.87 2546.16,-580.02 2551.87,-584.06",
        "34.45,-924.53 34.45,-924.53 34.45,-924.53 34.45,-924.53",
        "1597.03,-674.89 1595.36,-664.43 1590.14,-673.65 1597.03,-674.89",
        "3285.82,-854.22 3285.71,-843.63 3279.19,-851.98 3285.82,-854.22",
        "3512.91,-764.61 3511.41,-754.13 3506.04,-763.26 3512.91,-764.61",
        "3455.5,-673.02 3459.2,-663.09 3450.12,-668.55 3455.5,-673.02",
        "1112.95,-943.54 1109.45,-933.54 1105.95,-943.54 1112.95,-943.54",
        "1507.62,-649.04 1517.23,-644.59 1506.94,-642.07 1507.62,-649.04",
        "1022.18,-405.59 1020.98,-395.06 1015.36,-404.04 1022.18,-405.59",
        "1782.46,-834.61 1771.89,-835.28 1780.57,-841.35 1782.46,-834.61",
        "3531.88,-1027.46 3538.66,-1019.32 3528.28,-1021.46 3531.88,-1027.46",
        "2790.21,-999.77 2800.21,-996.27 2790.21,-992.77 2790.21,-999.77",
        "3007.85,-1027.14 3015.3,-1019.6 3004.77,-1020.85 3007.85,-1027.14",
        "2650.43,-936.83 2640.91,-932.2 2645.46,-941.76 2650.43,-936.83",
        "1984.66,-1138.69 1981.84,-1148.9 1990.41,-1142.68 1984.66,-1138.69",
        "2286.79,-674.62 2285.03,-664.17 2279.89,-673.44 2286.79,-674.62",
        "3531.88,-1027.46 3538.66,-1019.32 3528.28,-1021.46 3531.88,-1027.46",
        "2831.85,-1027.14 2839.3,-1019.6 2828.77,-1020.85 2831.85,-1027.14",
        "3007.85,-1027.14 3015.3,-1019.6 3004.77,-1020.85 3007.85,-1027.14",
        "2576.08,-939.67 2582.32,-931.11 2572.1,-933.91 2576.08,-939.67",
        "3531.88,-1027.46 3538.66,-1019.32 3528.28,-1021.46 3531.88,-1027.46",
        "2621.92,-573.93 2611.69,-571.2 2617.98,-579.72 2621.92,-573.93",
        "34.45,-834.79 34.45,-834.79 34.45,-834.79 34.45,-834.79",
        "211.06,-755.2 200.94,-752.06 206.89,-760.82 211.06,-755.2",
        "2581.23,-583.94 2576.56,-574.43 2574.28,-584.78 2581.23,-583.94",
        "2502.13,-494.54 2504.01,-484.11 2496.04,-491.1 2502.13,-494.54",
        "4608.95,-764.06 4605.45,-754.06 4601.95,-764.06 4608.95,-764.06",
        "1112.95,-853.79 1109.45,-843.79 1105.95,-853.8 1112.95,-853.79",
        "2319.95,-668.83 2310.91,-663.31 2314.53,-673.26 2319.95,-668.83",
        "2757.66,-584.47 2754.14,-574.47 2750.66,-584.48 2757.66,-584.47",
        "34.45,-745.05 34.45,-745.05 34.45,-745.05 34.45,-745.05",
        "427.95,-764.05 424.45,-754.05 420.95,-764.05 427.95,-764.05",
        "235.36,-747.03 224.77,-747.09 233.09,-753.65 235.36,-747.03",
        "223.99,-583.22 218.12,-574.4 217.21,-584.95 223.99,-583.22",
        "628.01,-495.23 626.53,-484.74 621.14,-493.87 628.01,-495.23",
        "318.46,-494.93 315.73,-484.7 311.48,-494.41 318.46,-494.93",
        "1369.66,-379.72 1379.36,-375.44 1369.11,-372.74 1369.66,-379.72",
        "463.4,-576.63 453.48,-572.89 458.9,-582 463.4,-576.63",
        "3172.06,-465.94 3181.91,-462.06 3171.79,-458.95 3172.06,-465.94",
        "745.95,-136.03 742.45,-126.03 738.95,-136.03 745.95,-136.03",
        "1845.5,-847.52 1853.09,-840.13 1842.55,-841.17 1845.5,-847.52",
        "1141.95,-315.51 1138.45,-305.51 1134.95,-315.51 1141.95,-315.51",
        "3270.95,-494.36 3266.62,-484.69 3263.97,-494.95 3270.95,-494.36",
        "1550.46,-366.15 1540.43,-369.56 1550.4,-373.15 1550.46,-366.15",
        "3092.35,-100.9 3082.06,-103.43 3091.68,-107.87 3092.35,-100.9",
        "1897.22,-584.76 1893.64,-574.79 1890.22,-584.81 1897.22,-584.76",
        "1780.95,-315.51 1777.45,-305.51 1773.95,-315.51 1780.95,-315.51",
        "34.45,-655.31 34.45,-655.31 34.45,-655.31 34.45,-655.31",
        "3171,-673.25 3165.37,-664.28 3164.18,-674.81 3171,-673.25",
        "2821.52,-565.87 2810.96,-566.78 2819.78,-572.66 2821.52,-565.87",
        "3499.01,-672.41 3492.21,-664.28 3492.46,-674.87 3499.01,-672.41",
        "34.45,-565.57 34.45,-565.57 34.45,-565.57 34.45,-565.57",
        "3304.25,-486.73 3294.29,-483.13 3299.84,-492.15 3304.25,-486.73",
        "34.45,-475.83 34.45,-475.83 34.45,-475.83 34.45,-475.83",
        "427.95,-225.95 424.45,-215.95 420.95,-225.95 427.95,-225.95",
        "215.95,-136.03 212.45,-126.03 208.95,-136.03 215.95,-136.03",
        "2600.16,-468.48 2589.72,-470.23 2598.98,-475.38 2600.16,-468.48",
        "2938.95,-405.1 2935.45,-395.1 2931.95,-405.1 2938.95,-405.1",
        "2544.09,-491.21 2535.93,-484.46 2538.1,-494.82 2544.09,-491.21",
        "34.45,-386.09 34.45,-386.09 34.45,-386.09 34.45,-386.09",
        "5126.09,-401.47 5117.93,-394.72 5120.1,-405.08 5126.09,-401.47",
        "5198.26,-225.22 5193.53,-215.74 5191.31,-226.1 5198.26,-225.22",
        "2945.6,-121.48 2954.08,-115.13 2943.49,-114.81 2945.6,-121.48",
        "34.45,-296.35 34.45,-296.35 34.45,-296.35 34.45,-296.35",
        "2938.95,-225.62 2935.45,-215.62 2931.95,-225.62 2938.95,-225.62",
        "5089.72,-313.85 5083.44,-305.32 5083.03,-315.91 5089.72,-313.85",
        "5184.64,-226.02 5183.73,-215.46 5177.86,-224.28 5184.64,-226.02",
        "918.6,-136.27 918.01,-125.69 911.87,-134.33 918.6,-136.27",
        "34.45,-206.61 34.45,-206.61 34.45,-206.61 34.45,-206.61",
        "5330.95,-135.88 5327.45,-125.88 5323.95,-135.88 5330.95,-135.88",
        "34.45,-116.87 34.45,-116.87 34.45,-116.87 34.45,-116.87",
        "34.45,-36.08 34.45,-36.08 34.45,-36.08 34.45,-36.08",
        "1011.3,-102.37 1021.3,-98.87 1011.3,-95.37 1011.3,-102.37",
        "298.76,-102.37 308.76,-98.87 298.76,-95.37 298.76,-102.37"
    ]
]